{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:30:33.870419800Z",
     "start_time": "2023-11-20T15:30:31.545605Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_data = pd.read_json(\"./data/train.json\")\n",
    "test_data = pd.read_json(\"./data/test.json\")\n",
    "validation_data = pd.read_json(\"./data/validation.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:30:34.103814800Z",
     "start_time": "2023-11-20T15:30:33.871419200Z"
    }
   },
   "id": "c8c94a719b721fc9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "58114"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.iloc[:len(train_data)]\n",
    "len(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T15:30:34.594145600Z",
     "start_time": "2023-11-20T15:30:34.583639800Z"
    }
   },
   "id": "cd3b41aba73d8c55"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "train_data['combined_sentences'] = train_data['sentence1'] + \" \" + train_data['sentence2']\n",
    "test_data['combined_sentences'] = test_data['sentence1'] + \" \" + test_data['sentence2']\n",
    "validation_data['combined_sentences'] = validation_data['sentence1'] + \" \" + validation_data['sentence2']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:28:11.930973900Z",
     "start_time": "2023-11-20T11:28:11.887180500Z"
    }
   },
   "id": "49450a5d50349da6"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\allex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:55:05.532325200Z",
     "start_time": "2023-11-20T11:55:05.199409800Z"
    }
   },
   "id": "fe1caccaaec2ea94"
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "ss = SnowballStemmer(\"romanian\")\n",
    "sw = stopwords.words(\"romanian\")\n",
    "\n",
    "# 1.Lowercase everything\n",
    "# 2.Remove all symbols other than a-z@#.\n",
    "# 3.Split on spaces.\n",
    "# 4.Remove stopwords/empty tokens\n",
    "# 5.Apply snowball stemmer to remainder\n",
    "\n",
    "def text_preparetion(text):\n",
    "    list_text_tokens = [ss.stem(i) for i in  # 5\n",
    "                          re.split(r\" +\",  # 3\n",
    "                                   re.sub(r\"[^a-z@# ]\", \"\",  # 2\n",
    "                                          text.lower()))  # 1\n",
    "                          if (i not in sw) and len(i)]  # 4\n",
    "    return list_text_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T13:52:55.625031900Z",
     "start_time": "2023-11-20T13:52:55.608527200Z"
    }
   },
   "id": "8f9de8f2fd1af01e"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "train_data['all_tokens'] = train_data['combined_sentences'].apply(text_preparetion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T13:52:58.160486400Z",
     "start_time": "2023-11-20T13:52:56.487784500Z"
    }
   },
   "id": "11a650b5ec4ebb7e"
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           sentence1  \\\n0  Primul taragotist român a fost Nicolae Luță Io...   \n1  Lupta revoluționarilor este condusă de Avram I...   \n2  Locuitorii liberi au devenit „''iobagiones cas...   \n3  În anul 2002 are loc lansarea în domeniul turi...   \n4  Zillich a mijlocit, prin revista ''Klingsor'',...   \n\n                                           sentence2  label  \\\n0  Colegiul de arhitectură, artă și planificare (...      3   \n1  Schiul nordic face parte din programul olimpic...      3   \n2  În anii 1960, ea a apărut în drame realizate l...      3   \n3  Se lansează primul hotel al grupului în otopen...      2   \n4  Au apărut lucrări ale lui ion luca caragiale, ...      2   \n\n                                   guid  \\\n0  7cec5ac4-c115-4976-8d2a-9badfe9b63b9   \n1  bc2fa29f-cf22-4a7c-8b55-9b1ed019f6ac   \n2  8547b1ef-7bfe-43a9-aedf-bad0c0fbc049   \n3  0ad1ce19-7aa9-4ddd-b8d6-822072a723b0   \n4  50c44ffa-b0c1-4d98-bc6c-3bbf95f50896   \n\n                                  combined_sentences  \\\n0  Primul taragotist român a fost Nicolae Luță Io...   \n1  Lupta revoluționarilor este condusă de Avram I...   \n2  Locuitorii liberi au devenit „''iobagiones cas...   \n3  În anul 2002 are loc lansarea în domeniul turi...   \n4  Zillich a mijlocit, prin revista ''Klingsor'',...   \n\n                                          all_tokens  \\\n0  [taragotist, romn, nicola, lu, iov, originar, ...   \n1  [lupt, revoluionar, condus, avram, iancu, ioan...   \n2  [locuit, liber, deven, iobagiones, castr, ioba...   \n3  [n, an, loc, lans, n, domen, turistichotelier,...   \n4  [zillich, mijloc, revist, klingsor, debut, mul...   \n\n                                              tokens  \\\n0  [romn, nicola, banat, coleg, arhitectur, art, ...   \n1  [lupt, condus, ioan, frai, ioan, viitor, ioan,...   \n2  [locuit, liber, deven, cet, milit, n, aprar, m...   \n3  [n, an, loc, n, domen, grup, n, dat, august, c...   \n4  [mijloc, revist, debut, multor, tiner, autor, ...   \n\n                                       moving_window  \n0  [(0, 1), (0, 2), (0, 3), (1, 0), (1, 2), (1, 3...  \n1  [(13, 14), (13, 15), (13, 16), (14, 13), (14, ...  \n2  [(26, 27), (26, 28), (26, 29), (27, 26), (27, ...  \n3  [(31, 43), (31, 44), (31, 31), (43, 31), (43, ...  \n4  [(54, 55), (54, 56), (54, 57), (55, 54), (55, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence1</th>\n      <th>sentence2</th>\n      <th>label</th>\n      <th>guid</th>\n      <th>combined_sentences</th>\n      <th>all_tokens</th>\n      <th>tokens</th>\n      <th>moving_window</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Primul taragotist român a fost Nicolae Luță Io...</td>\n      <td>Colegiul de arhitectură, artă și planificare (...</td>\n      <td>3</td>\n      <td>7cec5ac4-c115-4976-8d2a-9badfe9b63b9</td>\n      <td>Primul taragotist român a fost Nicolae Luță Io...</td>\n      <td>[taragotist, romn, nicola, lu, iov, originar, ...</td>\n      <td>[romn, nicola, banat, coleg, arhitectur, art, ...</td>\n      <td>[(0, 1), (0, 2), (0, 3), (1, 0), (1, 2), (1, 3...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lupta revoluționarilor este condusă de Avram I...</td>\n      <td>Schiul nordic face parte din programul olimpic...</td>\n      <td>3</td>\n      <td>bc2fa29f-cf22-4a7c-8b55-9b1ed019f6ac</td>\n      <td>Lupta revoluționarilor este condusă de Avram I...</td>\n      <td>[lupt, revoluionar, condus, avram, iancu, ioan...</td>\n      <td>[lupt, condus, ioan, frai, ioan, viitor, ioan,...</td>\n      <td>[(13, 14), (13, 15), (13, 16), (14, 13), (14, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Locuitorii liberi au devenit „''iobagiones cas...</td>\n      <td>În anii 1960, ea a apărut în drame realizate l...</td>\n      <td>3</td>\n      <td>8547b1ef-7bfe-43a9-aedf-bad0c0fbc049</td>\n      <td>Locuitorii liberi au devenit „''iobagiones cas...</td>\n      <td>[locuit, liber, deven, iobagiones, castr, ioba...</td>\n      <td>[locuit, liber, deven, cet, milit, n, aprar, m...</td>\n      <td>[(26, 27), (26, 28), (26, 29), (27, 26), (27, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>În anul 2002 are loc lansarea în domeniul turi...</td>\n      <td>Se lansează primul hotel al grupului în otopen...</td>\n      <td>2</td>\n      <td>0ad1ce19-7aa9-4ddd-b8d6-822072a723b0</td>\n      <td>În anul 2002 are loc lansarea în domeniul turi...</td>\n      <td>[n, an, loc, lans, n, domen, turistichotelier,...</td>\n      <td>[n, an, loc, n, domen, grup, n, dat, august, c...</td>\n      <td>[(31, 43), (31, 44), (31, 31), (43, 31), (43, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Zillich a mijlocit, prin revista ''Klingsor'',...</td>\n      <td>Au apărut lucrări ale lui ion luca caragiale, ...</td>\n      <td>2</td>\n      <td>50c44ffa-b0c1-4d98-bc6c-3bbf95f50896</td>\n      <td>Zillich a mijlocit, prin revista ''Klingsor'',...</td>\n      <td>[zillich, mijloc, revist, klingsor, debut, mul...</td>\n      <td>[mijloc, revist, debut, multor, tiner, autor, ...</td>\n      <td>[(54, 55), (54, 56), (54, 57), (55, 54), (55, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T13:57:55.208560700Z",
     "start_time": "2023-11-20T13:57:55.190667100Z"
    }
   },
   "id": "8cbe67d175e6e42a"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter([token for sublist in train_data['all_tokens'] for token in sublist])\n",
    "counts = {k:v for k, v in counts.items() if v>10} # Filtering\n",
    "vocab = list(counts.keys())\n",
    "n_v = len(vocab)\n",
    "id2tok = dict(enumerate(vocab))\n",
    "tok2id = {token: id for id, token in id2tok.items()}\n",
    "# Now correct tokens\n",
    "def remove_rare_tokens(row):\n",
    "    row = [t for t in row if t in vocab]\n",
    "    return row\n",
    "\n",
    "train_data['tokens'] = train_data['all_tokens'].apply(remove_rare_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T13:55:57.667719700Z",
     "start_time": "2023-11-20T13:55:57.018586800Z"
    }
   },
   "id": "3576b78bfd6d5c23"
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "def windowizer(doc, wsize=3):\n",
    "    \"\"\"\n",
    "    Windowizer function for Word2Vec. Converts sentence to sliding-window pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "    out = []\n",
    "    for i, wd in enumerate(doc):\n",
    "        target = tok2id[wd]\n",
    "        window = [i+j for j in\n",
    "                  range(-wsize, wsize+1, 1)\n",
    "                  if (i+j>=0) &\n",
    "                     (i+j<len(doc)) &\n",
    "                     (j!=0)]\n",
    "\n",
    "        out+=[(target, tok2id[doc[w]]) for w in window]\n",
    "    return out\n",
    "\n",
    "train_data['moving_window'] = train_data['tokens'].apply(windowizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T13:57:53.122578200Z",
     "start_time": "2023-11-20T13:57:53.029625800Z"
    }
   },
   "id": "541882a5dd44db39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Word2VecDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Takes a HuggingFace dataset as an input, to be used for a Word2Vec dataloader.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, vocab_size, wsize=3):\n",
    "        self.dataset = dataset\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = [i for s in dataset['moving_window'] for i in s]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2fd0ae4083d1fdb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2**14\n",
    "N_LOADER_PROCS = 10\n",
    "\n",
    "dataloader = {}\n",
    "for key in train_data['moving_window'].keys():\n",
    "    dataloader = {key: DataLoader(Word2VecDataset(\n",
    "                                    dataset[key], vocab_size=n_v),\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=N_LOADER_PROCS)}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d06e8b63b640f7e"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "vector_size = 64\n",
    "word2vec_model = gensim.models.Word2Vec(sentences=train_data['all_tokens'], vector_size=vector_size, window=5, min_count=1,\n",
    "                                        workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:34:07.695216400Z",
     "start_time": "2023-11-20T11:34:07.262455600Z"
    }
   },
   "id": "e12512891aaf75ce"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "\"După Dunăre, Inn și Main, Isar este al patrulea râu, ca lungime, din Bavaria. Limes, Cluj, 2010) a fost achiziționată de către: Biblioteca Kubon & Sagner din Munchen, de către [ Biblioteca Academia de Științe] a Rep. Moldova, precum și de către [ Biblioteca „Lucian Blaga” din Madrid]\\n* Cartea ''[ Securitatea, Cezarul și sfoara de câlți a lui Elie\\xa0Wiesel]'' (Ed.\""
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2\n",
    "test_data['combined_sentences'][n]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:34:27.408632900Z",
     "start_time": "2023-11-20T11:34:27.401480200Z"
    }
   },
   "id": "3687a2ef785152eb"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "tensor(0.0007)\n",
      "tensor([[-0.0606, -0.0230, -0.2749,  0.1191,  0.8304,  0.5394, -0.8490, -0.1324,\n",
      "          0.5752, -0.4563, -0.7517,  0.2644,  0.6231,  0.0518, -0.5138, -0.5378,\n",
      "         -0.7700, -0.0088,  0.2464, -0.6010,  0.4204, -0.6892,  0.1346,  0.3070,\n",
      "         -0.0087,  0.4722,  0.6388, -0.3836,  0.4670, -0.1899,  0.5981, -0.2624,\n",
      "          0.7431,  0.3321,  0.3341,  0.2017, -0.2177, -0.0672, -0.1043, -0.2189,\n",
      "          0.5096, -0.2590, -0.9160,  0.2714,  0.3928, -0.6067, -0.2389, -0.0371,\n",
      "         -0.2111, -0.5222,  0.2207,  0.1477,  0.2344, -0.1478, -0.6726, -0.3229,\n",
      "          0.0460,  0.1142,  0.1018, -0.7688, -0.1168,  0.2117, -0.1168, -0.0970],\n",
      "        [ 0.2864, -0.2028,  0.7957, -0.3784, -0.3367, -1.5247,  1.3210,  0.7995,\n",
      "         -0.6488,  0.4206,  0.9565,  0.1348, -1.0504, -0.7567,  0.2591,  0.0052,\n",
      "          0.6355,  0.2421,  0.3406, -0.1324, -0.8410,  1.8654,  0.2153, -0.4081,\n",
      "          0.8646,  0.1761, -0.1320,  0.7988,  1.0315,  0.0773, -0.0338,  0.5530,\n",
      "         -0.6584, -0.9141,  0.6228, -0.5531,  0.7307,  0.4245, -0.3340,  0.0920,\n",
      "         -0.1317, -1.7974,  0.3169, -0.0682, -0.4974,  0.3186, -0.7516, -0.2366,\n",
      "          0.9571,  1.8596, -0.4561,  0.2671,  0.5883,  0.7851,  0.0753,  0.2210,\n",
      "          0.0246, -0.8379, -0.6135,  0.8842,  0.4019, -0.8478,  0.3234, -0.7949],\n",
      "        [ 0.1860, -0.3219,  0.6042, -0.0371, -0.5218, -1.0852,  0.5512,  0.4029,\n",
      "         -0.7326,  0.2248,  0.7590, -0.2751, -0.7953, -0.5561,  0.4102,  0.0793,\n",
      "          0.6711,  0.1031,  0.1038,  0.3438, -0.2535,  1.1194,  0.2653, -0.3991,\n",
      "          0.2811,  0.0895, -0.6266,  0.2860,  0.4677, -0.1313, -0.3297,  0.6081,\n",
      "         -0.6987, -0.5760, -0.0334, -0.5819,  0.4837,  0.2023,  0.5389, -0.0343,\n",
      "         -0.0624, -0.3262,  0.2707, -0.3069, -0.0050,  0.1353, -0.1261, -0.0603,\n",
      "          0.5089,  1.0547, -0.0932,  0.0133,  0.2381,  1.0134,  0.2618,  0.5930,\n",
      "          0.1154, -0.5909, -0.4040,  1.1739,  0.4437, -0.8380,  0.4376, -0.3131],\n",
      "        [-0.0606, -0.0230, -0.2749,  0.1191,  0.8304,  0.5394, -0.8490, -0.1324,\n",
      "          0.5752, -0.4563, -0.7517,  0.2644,  0.6231,  0.0518, -0.5138, -0.5378,\n",
      "         -0.7700, -0.0088,  0.2464, -0.6010,  0.4204, -0.6892,  0.1346,  0.3070,\n",
      "         -0.0087,  0.4722,  0.6388, -0.3836,  0.4670, -0.1899,  0.5981, -0.2624,\n",
      "          0.7431,  0.3321,  0.3341,  0.2017, -0.2177, -0.0672, -0.1043, -0.2189,\n",
      "          0.5096, -0.2590, -0.9160,  0.2714,  0.3928, -0.6067, -0.2389, -0.0371,\n",
      "         -0.2111, -0.5222,  0.2207,  0.1477,  0.2344, -0.1478, -0.6726, -0.3229,\n",
      "          0.0460,  0.1142,  0.1018, -0.7688, -0.1168,  0.2117, -0.1168, -0.0970],\n",
      "        [ 0.1860, -0.3219,  0.6042, -0.0371, -0.5218, -1.0852,  0.5512,  0.4029,\n",
      "         -0.7326,  0.2248,  0.7590, -0.2751, -0.7953, -0.5561,  0.4102,  0.0793,\n",
      "          0.6711,  0.1031,  0.1038,  0.3438, -0.2535,  1.1194,  0.2653, -0.3991,\n",
      "          0.2811,  0.0895, -0.6266,  0.2860,  0.4677, -0.1313, -0.3297,  0.6081,\n",
      "         -0.6987, -0.5760, -0.0334, -0.5819,  0.4837,  0.2023,  0.5389, -0.0343,\n",
      "         -0.0624, -0.3262,  0.2707, -0.3069, -0.0050,  0.1353, -0.1261, -0.0603,\n",
      "          0.5089,  1.0547, -0.0932,  0.0133,  0.2381,  1.0134,  0.2618,  0.5930,\n",
      "          0.1154, -0.5909, -0.4040,  1.1739,  0.4437, -0.8380,  0.4376, -0.3131],\n",
      "        [-0.5203, -0.9015, -0.6744,  1.0053, -2.1130, -2.0858,  2.6712,  0.2381,\n",
      "         -0.2149, -0.8860,  1.7668,  1.1554, -1.3193, -1.2251, -1.2513, -0.7141,\n",
      "         -1.2196, -2.1152,  1.5675,  1.8113, -0.7985, -1.6164,  1.0815, -1.4335,\n",
      "          1.0841,  2.4403, -1.9991,  0.2054, -1.0518,  0.7070, -0.4508,  0.1746,\n",
      "         -0.3368,  0.5617,  1.7719, -1.5310, -0.0079, -2.1023, -0.1484, -1.6307,\n",
      "         -1.1932,  0.9939, -0.6655, -0.2047,  1.3271,  0.8309,  0.0307,  1.8612,\n",
      "         -0.6020,  0.7674, -0.5095,  0.2466, -1.0918, -0.0396,  1.4961,  0.0684,\n",
      "         -0.9830, -1.2589,  1.4373,  1.6000, -1.2391, -1.2753,  1.0364,  1.2008],\n",
      "        [-0.0606, -0.0230, -0.2749,  0.1191,  0.8304,  0.5394, -0.8490, -0.1324,\n",
      "          0.5752, -0.4563, -0.7517,  0.2644,  0.6231,  0.0518, -0.5138, -0.5378,\n",
      "         -0.7700, -0.0088,  0.2464, -0.6010,  0.4204, -0.6892,  0.1346,  0.3070,\n",
      "         -0.0087,  0.4722,  0.6388, -0.3836,  0.4670, -0.1899,  0.5981, -0.2624,\n",
      "          0.7431,  0.3321,  0.3341,  0.2017, -0.2177, -0.0672, -0.1043, -0.2189,\n",
      "          0.5096, -0.2590, -0.9160,  0.2714,  0.3928, -0.6067, -0.2389, -0.0371,\n",
      "         -0.2111, -0.5222,  0.2207,  0.1477,  0.2344, -0.1478, -0.6726, -0.3229,\n",
      "          0.0460,  0.1142,  0.1018, -0.7688, -0.1168,  0.2117, -0.1168, -0.0970]])\n"
     ]
    }
   ],
   "source": [
    "embeddings = [word2vec_model.wv[word] for word in test_data['combined_sentences'][n].split() if\n",
    "              word in word2vec_model.wv]\n",
    "embeddings = torch.tensor(embeddings)\n",
    "print(len(test_data['combined_sentences'][n].split()))\n",
    "print(torch.mean(embeddings))\n",
    "print(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:38:50.799084700Z",
     "start_time": "2023-11-20T11:38:50.790069900Z"
    }
   },
   "id": "b2da04c63a31aaf5"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "train_dataset = SentencePairDataset(train_data, word2vec_model)\n",
    "test_dataset = SentencePairDataset(test_data, word2vec_model, train=False)\n",
    "validation_dataset = SentencePairDataset(validation_data, word2vec_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:28:13.160846400Z",
     "start_time": "2023-11-20T11:28:13.116380800Z"
    }
   },
   "id": "b61e890f2a2b3a28"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:28:13.168488100Z",
     "start_time": "2023-11-20T11:28:13.139834400Z"
    }
   },
   "id": "5b9a0776f9b5bfc1"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NN, self).__init__()\n",
    "        # self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        # self.dropout1 = nn.Dropout(0.5)\n",
    "        # self.fc2 = nn.Linear(1024, 256)\n",
    "        # self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(input_dim, 4)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.relu(self.fc1(x))\n",
    "        # x = self.dropout1(x)\n",
    "        # x = torch.relu(self.fc2(x))\n",
    "        # x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:28:13.168488100Z",
     "start_time": "2023-11-20T11:28:13.147339500Z"
    }
   },
   "id": "e3d27541c042d9ee"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:28:13.177690300Z",
     "start_time": "2023-11-20T11:28:13.162847300Z"
    }
   },
   "id": "888fa72cb8d28dc"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2, 1024] at entry 0 and [3, 1024] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     12\u001B[0m running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m     14\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     15\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001B[0m, in \u001B[0;36mdefault_collate\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[0;32m    205\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    139\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    139\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001B[0m, in \u001B[0;36mcollate\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[1;32m--> 119\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[0;32m    122\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001B[0m, in \u001B[0;36mcollate_tensor_fn\u001B[1;34m(batch, collate_fn_map)\u001B[0m\n\u001B[0;32m    160\u001B[0m     storage \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_new_shared(numel, device\u001B[38;5;241m=\u001B[39melem\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    161\u001B[0m     out \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;28mlen\u001B[39m(batch), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(elem\u001B[38;5;241m.\u001B[39msize()))\n\u001B[1;32m--> 162\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: stack expects each tensor to be equal size, but got [2, 1024] at entry 0 and [3, 1024] at entry 2"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = NN(input_dim=vector_size)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs.float())\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model(inputs.float())\n",
    "            val_loss = criterion(output, labels)\n",
    "            val_losses += val_loss.item()\n",
    "    end = time.time()\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {running_loss / len(train_loader):.4f} - \"\n",
    "          f\"Val Loss: {val_losses / len(validation_loader):.4f} - \"\n",
    "          f\"Time = {end - start:.1f}s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:30:19.390172500Z",
     "start_time": "2023-11-20T11:30:19.322694900Z"
    }
   },
   "id": "3325c633a49084b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.cpu()\n",
    "val_correct = 0\n",
    "total_val = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_loader:\n",
    "        # inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        val_correct += (predicted == labels).sum()\n",
    "        total_val += labels.size(0)\n",
    "\n",
    "accuracy = val_correct / total_val\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T11:28:13.974195Z"
    }
   },
   "id": "83bf79d61684eb8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models/nn2epochs\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T11:28:13.975194100Z"
    }
   },
   "id": "bef98f5a8fbf1fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "loaded_model = NN(input_dim=vectorizer_size)  # Create an instance of the model\n",
    "loaded_model.load_state_dict(torch.load('./models/nn2epochs'))  # Load the model state dictionary\n",
    "loaded_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T11:28:13.975194100Z"
    }
   },
   "id": "6eb7da8e97034207"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.cpu()\n",
    "val_correct = 0\n",
    "total_val = 0\n",
    "df = pd.DataFrame(columns=[\"guid\", \"label\"])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, guids in test_loader:\n",
    "        # inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        df_new = pd.DataFrame({'guid': guids, 'label': predicted.numpy()})\n",
    "        df = pd.concat([df, df_new], ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T11:28:13.976194600Z"
    }
   },
   "id": "3b6f0b4282130230"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/submission2.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T11:28:13.977338600Z"
    }
   },
   "id": "7f2d0e49d18ab544"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
