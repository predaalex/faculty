{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpoTZudv_LK5"
   },
   "source": [
    "## Straturi Noi\n",
    "\n",
    "In continuare o sa utilizam o parte din straturile prezentate in curs.\n",
    "\n",
    "Staturi noi:\n",
    "\n",
    "Layer Convolutional:\n",
    "* [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
    "\n",
    "Layere Pooling:\n",
    "* [torch.nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)(kernel_size, stride=None, padding=0)\n",
    "*  [torch.nn.AveragePool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html)(kernel_size, stride=None, padding=0)\n",
    "\n",
    "Layere Adaptive Pool, intalnit adesea si ca Global Pool:\n",
    "* [torch.nn.AdaptiveAvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)(output_size)\n",
    "* [torch.nn.AdaptiveMaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html)(output_size)\n",
    "\n",
    "Layer de liniarizare:\n",
    "\n",
    "* [torch.nn.Flatten()](https://pytorch.org/docs/stable/generated/torch.flatten.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Four **hyperparameters** control the size of the output volume:\n",
    "* **Depth**: number of filters, as each filter _looks_ at different areas of the input:\n",
    "* **Stride**: the step taken when _sliding_ the filter. (Usually 1 or 2, 3 - uncommon).\n",
    "* **Zero-Padding**: size of the number of 0s that surround the border of the input volume. Example: If you want to the same width and height for input and output.\n",
    "* **Dilation**: Distance between elements of the convolutional kernel.\n",
    "\n"
   ],
   "metadata": {
    "id": "muaF8nG2CNdm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why Pooling Layer?**\n",
    "\n",
    "1. Modifica volumul de input (input volume) in reprezentari _mai mici_ si mai usor de _manevrat_.\n",
    "2. Opereaza independent pe fiecare Activation Map.\n",
    "\n",
    "<img src=\"https://computersciencewiki.org/images/9/9e/MaxpoolSample.png\" width=\"425\" height=\"300\"/> <img src=\"https://miro.medium.com/v2/resize:fit:517/0*lIcR0gOMK0xzTr6_.png\" width=\"425\" height=\"300\"/> \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "EJUUhdghGKMF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why Adaptive Pooling Layer?**\n",
    "\n",
    "1. Folosite de regula in etapele finale de constructie a unei arhitecturi de tipul _ConvNet_ pentru a inlocui fully-connected layers.\n",
    "2. Incearca sa previna *overfitting phenomenon* fortand feature maps sa retina informatia **globala** care este relevanta pentru task-ul acestei _ConvNet_ (clasificare, identifcare etc.)\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/338079465/figure/fig4/AS:905983672987648@1593014748012/The-difference-of-max-pooling-and-global-max-pooling.ppm\" width=\"725\" height=\"300\"/>\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=11l7Xsh-iQmASvXTkgH2MgtA01XCW6CAC\">\n"
   ],
   "metadata": {
    "id": "W1xV1DWySMUk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Visualise them Here](https://github.com/vdumoulin/conv_arithmetic)."
   ],
   "metadata": {
    "id": "AoaES2H0SK6f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "from torchvision.transforms.functional import to_tensor, normalize\n",
    "import torch.optim as optim\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T12:36:59.836302200Z",
     "start_time": "2023-10-17T12:36:58.114634200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5HWqK9mqHxgB",
    "ExecuteTime": {
     "end_time": "2023-10-16T19:17:57.629205800Z",
     "start_time": "2023-10-16T19:17:57.584627Z"
    }
   },
   "source": [
    "\n",
    "dummy_input_tensor = torch.rand((1, 3, 100, 100))  # Input random de marime 100x100 cu 3 canale\n",
    "\n",
    "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3, 3), stride=(2, 2))\n",
    "print(\"Conv1 result shape\", layer(dummy_input_tensor).shape)\n",
    "\n",
    "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(13, 13), stride=(2, 2))\n",
    "print(\"Conv2 result shape\", layer(dummy_input_tensor).shape)\n",
    "\n",
    "layer = nn.MaxPool2d(kernel_size=(\n",
    "    3, 3))  # Stride este inferat din kernel size, ca fiind egal cu kernel size ca sa nu repete elementele luate\n",
    "print(\"Pool result shape\", layer(dummy_input_tensor).shape)\n",
    "\n",
    "# Utilizate pentru a reduce dimensiunea la una prestabilita, util cand marimea input ului este variabil\n",
    "layer = nn.AdaptiveAvgPool2d(output_size=(5, 5))\n",
    "print(\"Global Pool result shape\", layer(dummy_input_tensor).shape)\n",
    "\n",
    "layer = nn.Flatten()\n",
    "print(\"Flaten result shape\", layer(dummy_input_tensor).shape)"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 result shape torch.Size([1, 10, 49, 49])\n",
      "Conv2 result shape torch.Size([1, 10, 44, 44])\n",
      "Pool result shape torch.Size([1, 3, 33, 33])\n",
      "Global Pool result shape torch.Size([1, 3, 5, 5])\n",
      "Flaten result shape torch.Size([1, 30000])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOTmqyCxJ3fk"
   },
   "source": [
    "###Cerinte\n",
    "\n",
    "**(1p)** Utilizati o serie de Conv2D/Pool2D pentru a ajunge la urmatoarele marimi plecand de la input 3x100x100:\n",
    "*   [1, 10, 25, 25] # Stride & Padding\n",
    "*   [1, 10, 32, 32]\n",
    "*  [1, 3, 2, 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7HtEeXbeKeKu",
    "ExecuteTime": {
     "end_time": "2023-10-16T19:17:57.672377200Z",
     "start_time": "2023-10-16T19:17:57.599170400Z"
    }
   },
   "source": [
    "dummy_input_tensor = torch.rand((1, 3, 100, 100))  # Input random de marime 100x100 cu 3 canale\n",
    "\n",
    "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(2, 2), stride=(4, 4))\n",
    "print(layer(dummy_input_tensor).shape)"
   ],
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 25, 25])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvdPtetggm61"
   },
   "source": [
    "## Instantierea seturilor de date"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "czyIhYt5gmUQ",
    "ExecuteTime": {
     "end_time": "2023-10-17T12:37:01.234816400Z",
     "start_time": "2023-10-17T12:37:00.253895500Z"
    }
   },
   "source": [
    "cifar_train = torchvision.datasets.CIFAR10(\"./data\", download=True)\n",
    "cifar_test = torchvision.datasets.CIFAR10(\"./data\", train=False)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOA4ted_hHdB"
   },
   "source": [
    "## Crearea Dataloader-ului\n",
    "\n",
    "### Cerinte\n",
    " * **(2p)** Implementati functia de preprocesare a datelor, __collate_fn(examples)__.\n",
    "\n",
    "\n",
    "Atentie! Spre deosebire de intrarea pentru retelele fully-connected, pentru retelele convolutionale intrearea nu trebuie liniarizata, ci doar normalizata.\n",
    "\n",
    "#### Hint\n",
    "\n",
    "  * Amintiti-va folosirea functiei __normalize__ din torchvision.transforms.functional din laboratorul trecut.\n",
    "  * Modificati functia *collate_fn* din laboratorul trecut, pentru a normaliza datele in intervalul [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T07:36:47.354040700Z",
     "start_time": "2023-10-17T07:36:47.337044700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def collate_fn(examples):\n",
    "    ### Completati codul pentru cerinta aici\n",
    "    processed_images = []\n",
    "    processed_labels = []\n",
    "\n",
    "    for (image, label) in examples:\n",
    "        tensor_image = to_tensor(image)\n",
    "        normalized_tensor_image = normalize(tensor_image, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        normalized_tensor_image = normalized_tensor_image.unsqueeze(0)\n",
    "        processed_images.append(normalized_tensor_image)\n",
    "\n",
    "        label = np.array(label)\n",
    "        label = torch.tensor(label).to(torch.int64)\n",
    "        label = label.unsqueeze(0)\n",
    "        processed_labels.append(label)\n",
    "\n",
    "    torch_images = torch.cat(processed_images, dim=0)\n",
    "    torch_labels = torch.cat(processed_labels, dim=0)\n",
    "\n",
    "    return torch_images, torch_labels\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = data.DataLoader(cifar_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = data.DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ],
   "metadata": {
    "id": "Jf4CRtpGHz2o",
    "ExecuteTime": {
     "end_time": "2023-10-17T07:37:11.635953800Z",
     "start_time": "2023-10-17T07:37:11.609446900Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_loader))[1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T07:37:13.670764900Z",
     "start_time": "2023-10-17T07:37:13.605257100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnV6PIC1kQMi"
   },
   "source": [
    "## Crearea unei retele neurale convolutionale\n",
    "\n",
    "### Cerinte\n",
    " * **(1p)** Creati o clasa care mosteneste clasa nn.Module. Ea va reprezenta o retea neurala convolutionala pentru clasificare ale celor 10 clase din datasetul CIFAR10.\n",
    "    * Reteaua trebuie sa aiba 2 straturi convolutionale care sa reduca dimensiunea spatiala a imaginii de 2 ori (0.25 p).\n",
    "    * Liniarizati iesirea din cel de-al doilea strat convolutional (0.25 p).\n",
    "    * Adaugat stratul final de tipul `fully-connected` (0.25 p).\n",
    "    * Folositi o functie de activare la alegere (Exemplu [RELU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)) (0.25 p).\n",
    "\n",
    "#### Hint\n",
    "\n",
    "Pentru a liniariza iesirea din cel de-al doilea feature map puteti adopta mai multe strategii:\n",
    "  * Liniarizare prin schimbarea shape-ului la [batch_size, -1]\n",
    "  * Global Max Pooling si apoi liniarizare la [batch_size, -1]\n",
    "  * Average Max Pooling si apoi liniarizare la [batch_size, -1]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u1Ddc7D-lAEN",
    "ExecuteTime": {
     "end_time": "2023-10-17T07:59:46.235084800Z",
     "start_time": "2023-10-17T07:59:46.221084900Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3, 3))\n",
    "        self.layer2 = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3))\n",
    "\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.activation2 = nn.Softmax(dim = 1)\n",
    "\n",
    "        self.dropout = nn.AvgPool2d(kernel_size=(3, 3))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Linear(in_features=810, out_features=10, bias=True)\n",
    "        # self.linear2 = nn.Linear(in_features=256, out_features=10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        # x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "\n",
    "        return x"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "dummy_input_tensor = torch.rand((1, 3, 32, 32))  # Input random de marime 100x100 cu 3 canale\n",
    "net = Net()\n",
    "print(net(dummy_input_tensor).shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T07:58:15.608247800Z",
     "start_time": "2023-10-17T07:58:15.570248300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK0Z9NeYTghv"
   },
   "source": [
    "## Definirea obiectelor folosite in timpul antrenarii\n",
    "\n",
    "### Cerinte **(1p)**\n",
    "  * Numarul de epoci (0.25 p)\n",
    "  * Retea (0.25 p)\n",
    "  * Optimizator (0.25 p)\n",
    "  * Alegeti functia de cost (0.25 p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Definiti numarul de epoci\n",
    "epochs = 20\n",
    "\n",
    "# Definiti reteaua\n",
    "network = Net().to(device)\n",
    "\n",
    "# Definiti optimizatorul\n",
    "optimizer = optim.SGD(network.parameters(), lr=1e-1)\n",
    "\"\"\"\n",
    "Dupa definirea optimizatorului si dupa fiecare iteratie de antrenare, trebuie \n",
    "apelata functia zero_grad() pentru a seta valoare tuturor gradientilor la zero.\n",
    "\"\"\"\n",
    "# Completati aici codul pentru seta valoare tuturor gradientilor la zero\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Definiti functia cost pentru clasificare Cross-Entropy\n",
    "# https://neptune.ai/blog/pytorch-loss-functions\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Az3WKQdpod34",
    "ExecuteTime": {
     "end_time": "2023-10-17T07:59:47.170836300Z",
     "start_time": "2023-10-17T07:59:47.153805700Z"
    }
   },
   "source": [
    "def test_acc(net: nn.Module, test_loader: DataLoader):\n",
    "    net.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for test_images, test_labels in test_loader:\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "        total += len(test_images)\n",
    "        out_class = torch.argmax(net(test_images))\n",
    "        correct += torch.sum(out_class == test_labels)\n",
    "\n",
    "    return correct / total * 100\n",
    "\n",
    "def train_fn(epochs: int, train_loader: data.DataLoader, test_loader: data.DataLoader,\n",
    "             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n",
    "    # Iteram prin numarul de epoci\n",
    "    for e in range(epochs):\n",
    "        start = time.time()\n",
    "        net.train()\n",
    "        # Iteram prin fiecare exemplu din dataset\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Aplicam reteaua neurala pe imaginile de intrare\n",
    "            out = net(images)\n",
    "            # Aplicam functia cost pe iesirea retelei neurale si pe adnotarile imaginilor \n",
    "            loss = loss_fn(out, labels)\n",
    "            # Aplicam algoritmul de back-propagation\n",
    "            loss.backward()\n",
    "            # Facem pasul de optimizare, pentru a aplica gradientii pe parametrii retelei\n",
    "            optimizer.step()\n",
    "            # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n",
    "            optimizer.zero_grad()\n",
    "        end = time.time()\n",
    "        print(f\"Loss-ul la finalul epocii {e + 1} are valoarea {loss.item()} si a durat: {(end - start):.1f}s antrenarea\")\n",
    "\n",
    "        # Calculul acuratetii\n",
    "        start = time.time()\n",
    "        acc = test_acc(net, test_loader)\n",
    "        end = time.time()\n",
    "        print(f\"Acuratetea la finalul epocii {e + 1} este {acc:.2f}% si a durat {(end - start):.1f}s evaluarea\")"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss-ul la finalul epocii 1 are valoarea 2.1408135890960693 si a durat: 4.8s antrenarea\n",
      "Acuratetea la finalul epocii 1 este 32.57% si a durat 5.8s evaluarea\n",
      "Loss-ul la finalul epocii 2 are valoarea 2.1431009769439697 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 2 este 37.19% si a durat 5.2s evaluarea\n",
      "Loss-ul la finalul epocii 3 are valoarea 2.0217864513397217 si a durat: 4.4s antrenarea\n",
      "Acuratetea la finalul epocii 3 este 40.09% si a durat 5.0s evaluarea\n",
      "Loss-ul la finalul epocii 4 are valoarea 2.1191790103912354 si a durat: 4.4s antrenarea\n",
      "Acuratetea la finalul epocii 4 este 41.43% si a durat 5.1s evaluarea\n",
      "Loss-ul la finalul epocii 5 are valoarea 2.125805139541626 si a durat: 4.5s antrenarea\n",
      "Acuratetea la finalul epocii 5 este 42.07% si a durat 5.5s evaluarea\n",
      "Loss-ul la finalul epocii 6 are valoarea 1.9608795642852783 si a durat: 4.4s antrenarea\n",
      "Acuratetea la finalul epocii 6 este 43.67% si a durat 5.6s evaluarea\n",
      "Loss-ul la finalul epocii 7 are valoarea 2.0961949825286865 si a durat: 4.3s antrenarea\n",
      "Acuratetea la finalul epocii 7 este 44.96% si a durat 5.6s evaluarea\n",
      "Loss-ul la finalul epocii 8 are valoarea 2.0381669998168945 si a durat: 4.2s antrenarea\n",
      "Acuratetea la finalul epocii 8 este 45.36% si a durat 5.0s evaluarea\n",
      "Loss-ul la finalul epocii 9 are valoarea 1.936802625656128 si a durat: 4.3s antrenarea\n",
      "Acuratetea la finalul epocii 9 este 46.73% si a durat 5.2s evaluarea\n",
      "Loss-ul la finalul epocii 10 are valoarea 1.968825340270996 si a durat: 4.2s antrenarea\n",
      "Acuratetea la finalul epocii 10 este 47.49% si a durat 5.1s evaluarea\n",
      "Loss-ul la finalul epocii 11 are valoarea 2.0722014904022217 si a durat: 4.4s antrenarea\n",
      "Acuratetea la finalul epocii 11 este 47.25% si a durat 5.6s evaluarea\n",
      "Loss-ul la finalul epocii 12 are valoarea 2.016458034515381 si a durat: 4.5s antrenarea\n",
      "Acuratetea la finalul epocii 12 este 49.23% si a durat 5.6s evaluarea\n",
      "Loss-ul la finalul epocii 13 are valoarea 1.8594889640808105 si a durat: 4.5s antrenarea\n",
      "Acuratetea la finalul epocii 13 este 51.13% si a durat 5.5s evaluarea\n",
      "Loss-ul la finalul epocii 14 are valoarea 1.9680688381195068 si a durat: 4.3s antrenarea\n",
      "Acuratetea la finalul epocii 14 este 49.92% si a durat 4.8s evaluarea\n",
      "Loss-ul la finalul epocii 15 are valoarea 1.9461010694503784 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 15 este 51.64% si a durat 5.4s evaluarea\n",
      "Loss-ul la finalul epocii 16 are valoarea 1.9217413663864136 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 16 este 51.12% si a durat 5.1s evaluarea\n",
      "Loss-ul la finalul epocii 17 are valoarea 1.9478158950805664 si a durat: 4.3s antrenarea\n",
      "Acuratetea la finalul epocii 17 este 51.58% si a durat 5.2s evaluarea\n",
      "Loss-ul la finalul epocii 18 are valoarea 1.9031542539596558 si a durat: 4.3s antrenarea\n",
      "Acuratetea la finalul epocii 18 este 52.01% si a durat 4.7s evaluarea\n",
      "Loss-ul la finalul epocii 19 are valoarea 1.93153715133667 si a durat: 4.3s antrenarea\n",
      "Acuratetea la finalul epocii 19 este 53.38% si a durat 4.8s evaluarea\n",
      "Loss-ul la finalul epocii 20 are valoarea 1.906058669090271 si a durat: 4.3s antrenarea\n",
      "Acuratetea la finalul epocii 20 este 52.93% si a durat 4.5s evaluarea\n"
     ]
    }
   ],
   "source": [
    "train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T08:03:01.509937700Z",
     "start_time": "2023-10-17T07:59:48.736981Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmVavwztTZkz"
   },
   "source": [
    "## Reteaua LeNet\n",
    "\n",
    "### Cerinte\n",
    "  * **(3p)** Implementati reteaua LeNet dupa figura de mai jos si antrenati-o.\n",
    "\n",
    "\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1OVancUyIViMRMZdULFSVCvXJHQP0NGUV)\n",
    "\n",
    "Figura arhitectura LeNet\n",
    "\n",
    "![alt text](https://debuggercafe.com/wp-content/uploads/2019/07/Layers-in-LeNet.png)\n",
    "\n",
    "Tabel arhitectura LeNet\n",
    "\n",
    "_Question:_ Care este diferenta dintre `tanh` si `softmax`? De ce credeti ca peste ultimul layer (cel de output) a fost aplicata functia `softmax`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def collate_fn_lenet(examples):\n",
    "    ### Completati codul pentru cerinta aici\n",
    "    processed_images = []\n",
    "    processed_labels = []\n",
    "\n",
    "    for (image, label) in examples:\n",
    "        image = image.convert(\"L\")\n",
    "        tensor_image = to_tensor(image)\n",
    "        normalized_tensor_image = normalize(tensor_image, [0.5], [0.5])\n",
    "        normalized_tensor_image = normalized_tensor_image.unsqueeze(0)\n",
    "        processed_images.append(normalized_tensor_image)\n",
    "\n",
    "        label = np.array(label)\n",
    "        label = torch.tensor(label).to(torch.int64)\n",
    "        label = label.unsqueeze(0)\n",
    "        processed_labels.append(label)\n",
    "\n",
    "    torch_images = torch.cat(processed_images, dim=0)\n",
    "    torch_labels = torch.cat(processed_labels, dim=0)\n",
    "\n",
    "    return torch_images, torch_labels\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = data.DataLoader(cifar_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_lenet)\n",
    "test_loader = data.DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=collate_fn_lenet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T12:37:11.055649200Z",
     "start_time": "2023-10-17T12:37:11.032623300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zoe1vbggO-4U",
    "ExecuteTime": {
     "end_time": "2023-10-17T12:37:13.456373200Z",
     "start_time": "2023-10-17T12:37:13.431839200Z"
    }
   },
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5), stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5, 5), stride=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=6)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=16)\n",
    "                \n",
    "        self.activation1 = nn.Tanh()\n",
    "        self.activation2 = nn.Softmax()\n",
    "        \n",
    "        self.pooling = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features=120, out_features=84, bias=False)\n",
    "        self.linear2 = nn.Linear(in_features=84, out_features=10, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation1(x)\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        x = self.activation1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation1(x)\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        x = self.activation1(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        \n",
    "        return x"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0978, 0.1080, 0.1041, 0.0986, 0.1022, 0.0951, 0.0995, 0.0977, 0.0969,\n",
      "         0.1000]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allex\\miniconda3\\envs\\PyTorchTest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dummy_input_tensor = torch.rand((1, 1, 32, 32))  # Input random de marime 100x100 cu 3 canale\n",
    "net = LeNet()\n",
    "print(net(dummy_input_tensor))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T12:37:56.991861200Z",
     "start_time": "2023-10-17T12:37:56.956357500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Definiti numarul de epoci\n",
    "epochs = 20\n",
    "\n",
    "# Definiti reteaua\n",
    "network = LeNet().to(device)\n",
    "\n",
    "# Definiti optimizatorul\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.01)\n",
    "\"\"\"\n",
    "Dupa definirea optimizatorului si dupa fiecare iteratie de antrenare, trebuie \n",
    "apelata functia zero_grad() pentru a seta valoare tuturor gradientilor la zero.\n",
    "\"\"\"\n",
    "# Completati aici codul pentru seta valoare tuturor gradientilor la zero\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Definiti functia cost pentru clasificare Cross-Entropy\n",
    "# https://neptune.ai/blog/pytorch-loss-functions\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T08:26:20.077162Z",
     "start_time": "2023-10-17T08:26:20.055161800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss-ul la finalul epocii 1 are valoarea 2.297699213027954 si a durat: 5.0s antrenarea\n",
      "Acuratetea la finalul epocii 1 este 15.56% si a durat 7.0s evaluarea\n",
      "Loss-ul la finalul epocii 2 are valoarea 2.296234369277954 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 2 este 18.64% si a durat 7.2s evaluarea\n",
      "Loss-ul la finalul epocii 3 are valoarea 2.2819275856018066 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 3 este 19.61% si a durat 7.4s evaluarea\n",
      "Loss-ul la finalul epocii 4 are valoarea 2.2804677486419678 si a durat: 4.5s antrenarea\n",
      "Acuratetea la finalul epocii 4 este 20.63% si a durat 7.4s evaluarea\n",
      "Loss-ul la finalul epocii 5 are valoarea 2.2528905868530273 si a durat: 4.7s antrenarea\n",
      "Acuratetea la finalul epocii 5 este 21.28% si a durat 7.3s evaluarea\n",
      "Loss-ul la finalul epocii 6 are valoarea 2.251143455505371 si a durat: 4.5s antrenarea\n",
      "Acuratetea la finalul epocii 6 este 21.91% si a durat 7.6s evaluarea\n",
      "Loss-ul la finalul epocii 7 are valoarea 2.2298991680145264 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 7 este 22.32% si a durat 7.5s evaluarea\n",
      "Loss-ul la finalul epocii 8 are valoarea 2.234610080718994 si a durat: 4.7s antrenarea\n",
      "Acuratetea la finalul epocii 8 este 22.86% si a durat 7.8s evaluarea\n",
      "Loss-ul la finalul epocii 9 are valoarea 2.224959373474121 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 9 este 23.87% si a durat 7.3s evaluarea\n",
      "Loss-ul la finalul epocii 10 are valoarea 2.236640691757202 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 10 este 25.04% si a durat 7.3s evaluarea\n",
      "Loss-ul la finalul epocii 11 are valoarea 2.2256860733032227 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 11 este 25.80% si a durat 7.2s evaluarea\n",
      "Loss-ul la finalul epocii 12 are valoarea 2.1494672298431396 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 12 este 26.23% si a durat 7.3s evaluarea\n",
      "Loss-ul la finalul epocii 13 are valoarea 2.17551326751709 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 13 este 26.52% si a durat 7.6s evaluarea\n",
      "Loss-ul la finalul epocii 14 are valoarea 2.2340199947357178 si a durat: 4.5s antrenarea\n",
      "Acuratetea la finalul epocii 14 este 27.16% si a durat 7.4s evaluarea\n",
      "Loss-ul la finalul epocii 15 are valoarea 2.1750917434692383 si a durat: 4.8s antrenarea\n",
      "Acuratetea la finalul epocii 15 este 27.36% si a durat 7.6s evaluarea\n",
      "Loss-ul la finalul epocii 16 are valoarea 2.189601421356201 si a durat: 4.4s antrenarea\n",
      "Acuratetea la finalul epocii 16 este 27.72% si a durat 7.9s evaluarea\n",
      "Loss-ul la finalul epocii 17 are valoarea 2.207704544067383 si a durat: 5.1s antrenarea\n",
      "Acuratetea la finalul epocii 17 este 28.15% si a durat 7.6s evaluarea\n",
      "Loss-ul la finalul epocii 18 are valoarea 2.1806681156158447 si a durat: 4.9s antrenarea\n",
      "Acuratetea la finalul epocii 18 este 28.60% si a durat 7.9s evaluarea\n",
      "Loss-ul la finalul epocii 19 are valoarea 2.2271103858947754 si a durat: 4.4s antrenarea\n",
      "Acuratetea la finalul epocii 19 este 29.58% si a durat 6.6s evaluarea\n",
      "Loss-ul la finalul epocii 20 are valoarea 2.1571762561798096 si a durat: 4.6s antrenarea\n",
      "Acuratetea la finalul epocii 20 este 29.99% si a durat 7.0s evaluarea\n"
     ]
    }
   ],
   "source": [
    "train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T08:30:22.607749800Z",
     "start_time": "2023-10-17T08:26:21.978249600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optional: Reteaua AlexNet ❤️\n",
    "\n",
    "❗Daca alegeti aceasta retea veti continua sa rezolvati exercitiile urmatoare pentru reteaua AlexNet.\n",
    "\n",
    "Pentru a usura volumul de munca si obtine o retea AlexNet comparabila in dificultate cu LeNet, urmati acesti pasi:\n",
    "\n",
    "✔️ Includeti functii de activare intre layere (exemplu ReLU).\n",
    "\n",
    "✔️ Va folositi doar de prima subsectiune din schema figurii arhitecturii AlexNet (adica doar Conv1 si Conv2 blocks).\n",
    "\n",
    "✔️ Inputul vostru se opreste la un minimum size de 8x8.\n",
    "\n",
    "✔️ Modificati output-ul retelei sa prezica 10 clase in loc de 1000 de clase.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![alt text](https://anhreynolds.com/img/alexnet.png)\n",
    "\n",
    "Figura arhitectura AlexNet.\n",
    "\n",
    "![alt text](https://anhreynolds.com/img/alexnet-parameters.png)\n",
    "\n",
    "Tabel arhitectura AlexNet\n"
   ],
   "metadata": {
    "id": "nMaWPS1gXslS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Punctaj: 2.5p\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Punctaj: 0.5p\n",
    "        \"\"\"\n",
    "        return x"
   ],
   "metadata": {
    "id": "irXGsufhCiuG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0XPmGrEol9M"
   },
   "source": [
    "## Redefinirea obiectelor folosite in timpul antrenarii pentru reteaua LeNet\n",
    "\n",
    "### Cerinta\n",
    " * Redefiniti obiectele pentru a antrena reteaua LeNet"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jhqNoDmQo66c"
   },
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Definiti numarul de epoci\n",
    "epochs = None\n",
    "\n",
    "# Definiti reteaua\n",
    "lenet = None\n",
    "\n",
    "# Definiti optimizatorul\n",
    "lenet_optimizer = None\n",
    "# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n",
    "# Aceasta face toti gradientii zero.\n",
    "# Completati codul pentru a face gradientii zero aici\n",
    "\n",
    "\n",
    "# Definiti functia cost pentru clasificare Cross-Entropy\n",
    "loss_fn = None"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwIQwUQpo_eR"
   },
   "source": [
    "## Antrenarea retelei LeNet"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UUl8W42do_sL"
   },
   "source": [
    "train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OspDtfFnTodr"
   },
   "source": [
    "###Augmentare retea\n",
    "\n",
    "Reteaua de mai devreme duce lipsa de regularizare. O forma foarte puternica de regularizare este normalizarea, iar pentru acest lucru exista straturi speciale.\n",
    "\n",
    "Astfel de straturi:\n",
    "\n",
    "* [torch.nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) (num_features)\n",
    "* [torch.nn.InstanceNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html) (num_features)\n",
    "\n",
    "Un alt element important il reprezinta functiile de activare, care pot influenta convergenta si puterea retelei. Cateva exemple de alte functii de activare:\n",
    "\n",
    "* ReLU\n",
    "* Sigmoid\n",
    "* Tanh\n",
    "* LeakyRelu\n",
    "* GELU\n",
    "\n",
    "## Cerinta\n",
    "\n",
    "**(2p)** Experimentati cu aceste elemente in cadrul retelei LeNet definita mai devreme, pentru a obtine o acuratete mai buna. Observati viteza de convergenta si performanta retelei pentru 3 configuratii diferite.\n",
    "\n",
    "**Punctaj:** 0.6p / configuratie.\n",
    "\n",
    "0.6p din care:\n",
    "- 0.4p modificarea retelei\n",
    "- 0.1p obtinerea rezultatelor\n",
    "- 0.1p afisarea acestora si explicatie.\n",
    "\n",
    "\n",
    "###Bonus\n",
    "**(1p)** Antrenati reteaua folosind GPU (Graphics processing unit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "8bROgHAlKYRv"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
