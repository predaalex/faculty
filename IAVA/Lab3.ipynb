{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpoTZudv_LK5"
   },
   "source": [
    "## Straturi Noi\n",
    "\n",
    "In continuare o sa utilizam o parte din straturile prezentate in curs.\n",
    "\n",
    "Staturi noi:\n",
    "\n",
    "Layer Convolutional:\n",
    "* [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
    "\n",
    "Layere Pooling:\n",
    "* [torch.nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)(kernel_size, stride=None, padding=0)\n",
    "*  [torch.nn.AveragePool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html)(kernel_size, stride=None, padding=0)\n",
    "\n",
    "Layere Adaptive Pool, intalnit adesea si ca Global Pool:\n",
    "* [torch.nn.AdaptiveAvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)(output_size)\n",
    "* [torch.nn.AdaptiveMaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html)(output_size)\n",
    "\n",
    "Layer de liniarizare:\n",
    "\n",
    "* [torch.nn.Flatten()](https://pytorch.org/docs/stable/generated/torch.flatten.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muaF8nG2CNdm"
   },
   "source": [
    "Four **hyperparameters** control the size of the output volume:\n",
    "* **Depth**: number of filters, as each filter _looks_ at different areas of the input:\n",
    "* **Stride**: the step taken when _sliding_ the filter. (Usually 1 or 2, 3 - uncommon).\n",
    "* **Zero-Padding**: size of the number of 0s that surround the border of the input volume. Example: If you want to the same width and height for input and output.\n",
    "* **Dilation**: Distance between elements of the convolutional kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJUUhdghGKMF"
   },
   "source": [
    "**Why Pooling Layer?**\n",
    "\n",
    "1. Modifica volumul de input (input volume) in reprezentari _mai mici_ si mai usor de _manevrat_.\n",
    "2. Opereaza independent pe fiecare Activation Map.\n",
    "\n",
    "<img src=\"https://computersciencewiki.org/images/9/9e/MaxpoolSample.png\" width=\"425\" height=\"300\"/> <img src=\"https://miro.medium.com/v2/resize:fit:517/0*lIcR0gOMK0xzTr6_.png\" width=\"425\" height=\"300\"/> \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1xV1DWySMUk"
   },
   "source": [
    "**Why Adaptive Pooling Layer?**\n",
    "\n",
    "1. Folosite de regula in etapele finale de constructie a unei arhitecturi de tipul _ConvNet_ pentru a inlocui fully-connected layers.\n",
    "2. Incearca sa previna *overfitting phenomenon* fortand feature maps sa retina informatia **globala** care este relevanta pentru task-ul acestei _ConvNet_ (clasificare, identifcare etc.)\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/338079465/figure/fig4/AS:905983672987648@1593014748012/The-difference-of-max-pooling-and-global-max-pooling.ppm\" width=\"725\" height=\"300\"/>\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=11l7Xsh-iQmASvXTkgH2MgtA01XCW6CAC\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoaES2H0SK6f"
   },
   "source": [
    "[Visualise them Here](https://github.com/vdumoulin/conv_arithmetic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1678873756046,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     },
     "user_tz": -120
    },
    "id": "5HWqK9mqHxgB",
    "outputId": "590ce389-4c79-4e1e-adbb-0d0e83f846a3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conv1 result shape torch.Size([1, 10, 49, 49])\n",
      "Conv2 result shape torch.Size([1, 10, 44, 44])\n",
      "Pool result shape torch.Size([1, 3, 33, 33])\n",
      "Global Pool result shape torch.Size([1, 3, 5, 5])\n",
      "Flaten result shape torch.Size([1, 30000])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n",
    "\n",
    "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(2,2))\n",
    "print(\"Conv1 result shape\",layer(dummy_input_tensor).shape)\n",
    "\n",
    "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(13,13), stride=(2,2))\n",
    "print(\"Conv2 result shape\",layer(dummy_input_tensor).shape)\n",
    "\n",
    "layer = nn.MaxPool2d(kernel_size=(3,3)) # Stride este inferat din kernel size, ca fiind egal cu kernel size ca sa nu repete elementele luate\n",
    "print(\"Pool result shape\",layer(dummy_input_tensor).shape)\n",
    "\n",
    "# Utilizate pentru a reduce dimensiunea la una prestabilita, util cand marimea input ului este variabil\n",
    "layer = nn.AdaptiveAvgPool2d(output_size=(5,5))\n",
    "print(\"Global Pool result shape\",layer(dummy_input_tensor).shape)\n",
    "\n",
    "layer = nn.Flatten()\n",
    "print(\"Flaten result shape\",layer(dummy_input_tensor).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOTmqyCxJ3fk"
   },
   "source": [
    "###Cerinte\n",
    "\n",
    "**(1p)** Utilizati o serie de Conv2D/Pool2D pentru a ajunge la urmatoarele marimi plecand de la input 3x100x100:\n",
    "*   [1, 10, 25, 25] # Stride & Padding\n",
    "*   [1, 10, 32, 32]\n",
    "*  [1, 3, 2, 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3471,
     "status": "ok",
     "timestamp": 1678878738367,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     },
     "user_tz": -120
    },
    "id": "7HtEeXbeKeKu",
    "outputId": "9b47341f-cc7d-41bb-ffb9-e37b2e50c597"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 10, 25, 25])\n",
      "torch.Size([1, 10, 32, 32])\n",
      "torch.Size([1, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n",
    "\n",
    "\n",
    "# [1, 10, 25, 25]\n",
    "layer1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(6, 6), padding = 25)\n",
    "print(layer1(dummy_input_tensor).shape)\n",
    "\n",
    "# [1, 10, 32, 32]\n",
    "layer2 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(4, 4), padding = 14)\n",
    "print(layer2(dummy_input_tensor).shape)\n",
    "\n",
    "# [1, 3, 2, 2]\n",
    "layer3 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(25, 25), stride=(50, 50))\n",
    "print(layer3(dummy_input_tensor).shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvdPtetggm61"
   },
   "source": [
    "## Instantierea seturilor de date"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "c62addee9b62473abbfe1f66274ab98a",
      "020ab6ba04974b33ab5aca25f5502250",
      "de1540a97ea949ea9b00daf93309ff1f",
      "ab9fcdcdeb584fd68d1734237d11419f",
      "ad627174b9f2491dbabcc2468fa52acd",
      "b866d589f07f47d5a1ea7944f02d985b",
      "d36d8466c85a46d396e5e5597868e067",
      "8fd5970f67e0413c9e6934142b9b1124",
      "0f0956001a2d4ca58d72fa2ee6ce7382",
      "0feb90fcaf9d4abd8d0448498331095b",
      "e2bb586c72bd4211bf3a6e39b27b370f"
     ]
    },
    "outputId": "66ec0c1f-24c2-4b0c-8999-1193994b3dd2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678878778652,
     "user_tz": -120,
     "elapsed": 36131,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "id": "ucm2gySilcyV"
   },
   "source": [
    "import torchvision\n",
    "\n",
    "cifar_train = torchvision.datasets.CIFAR10(\"./data\", download=True)\n",
    "cifar_test = torchvision.datasets.CIFAR10(\"./data\", train=False)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c62addee9b62473abbfe1f66274ab98a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOA4ted_hHdB"
   },
   "source": [
    "## Crearea Dataloader-ului\n",
    "\n",
    "### Cerinte\n",
    " * **(2p)** Implementati functia de preprocesare a datelor, __collate_fn(examples)__.\n",
    "\n",
    "\n",
    "Atentie! Spre deosebire de intrarea pentru retelele fully-connected, pentru retelele convolutionale intrearea nu trebuie liniarizata, ci doar normalizata.\n",
    "\n",
    "#### Hint\n",
    "\n",
    "  * Amintiti-va folosirea functiei __normalize__ din torchvision.transforms.functional din laboratorul trecut.\n",
    "  * Modificati functia *collate_fn* din laboratorul trecut, pentru a normaliza datele in intervalul [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import to_tensor, normalize\n",
    "\n",
    "def collate_fn(examples):\n",
    "  ### Completati codul pentru cerinta aici\n",
    "  processed_images = []\n",
    "  processed_labels = []\n",
    "\n",
    "  for example in examples:\n",
    "    tensor_image = to_tensor(example[0])\n",
    "    # In linia de mai jos imaginea este normalizata astfel incat sa aiba toate valorile in \n",
    "    # [-1, 1] in loc de [0, 255]\n",
    "    normalized_tensor_image = normalize(tensor_image, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    normalized_tensor_image = normalized_tensor_image.unsqueeze(0)\n",
    "\n",
    "    processed_images.append(normalized_tensor_image)\n",
    "    \n",
    "    label = np.array(example[1])\n",
    "    tensor_label = torch.tensor(label)\n",
    "    tensor_label = tensor_label.unsqueeze(0)\n",
    "    processed_labels.append(tensor_label)\n",
    "\n",
    "  torch_images = torch.cat(processed_images, dim=0)\n",
    "  torch_labels = torch.cat(processed_labels, dim=0)\n",
    "\n",
    "  return torch_images, torch_labels\n",
    "\n",
    "train_loader = DataLoader(cifar_train, batch_size=500, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ],
   "metadata": {
    "id": "Jf4CRtpGHz2o",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678878778652,
     "user_tz": -120,
     "elapsed": 2,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnV6PIC1kQMi"
   },
   "source": [
    "## Crearea unei retele neurale convolutionale\n",
    "\n",
    "### Cerinte\n",
    " * **(1p)** Creati o clasa care mosteneste clasa nn.Module. Ea va reprezenta o retea neurala convolutionala pentru clasificare ale celor 10 clase din datasetul CIFAR10.\n",
    "    * Reteaua trebuie sa aiba 2 straturi convolutionale care sa reduca dimensiunea spatiala a imaginii de 2 ori (0.25 p).\n",
    "    * Liniarizati iesirea din cel de-al doilea strat convolutional (0.25 p).\n",
    "    * Adaugat stratul final de tipul `fully-connected` (0.25 p).\n",
    "    * Folositi o functie de activare la alegere (Exemplu [RELU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)) (0.25 p).\n",
    "\n",
    "#### Hint\n",
    "\n",
    "Pentru a liniariza iesirea din cel de-al doilea feature map puteti adopta mai multe strategii:\n",
    "  * Liniarizare prin schimbarea shape-ului la [batch_size, -1]\n",
    "  * Global Max Pooling si apoi liniarizare la [batch_size, -1]\n",
    "  * Average Max Pooling si apoi liniarizare la [batch_size, -1]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    ## din 32x32x3 -> layer1 -> activation1 -> 3x16x16\n",
    "    self.layer1 = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = (3, 3), stride = (2, 2), padding=1)\n",
    "    ## din 16x16x3 -> layer2 -> activation2 -> 3x8x8\n",
    "    self.layer2 = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = (3, 3), stride = (2, 2), padding=1)\n",
    "\n",
    "    self.fully_connected_layer = nn.Linear(8*8*3, 10, bias=False) \n",
    "    self.activation = nn.ReLU()\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.activation(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.activation(x)\n",
    "    x = x.reshape((-1, 8*8*3))\n",
    "    x = self.fully_connected_layer(x)\n",
    "    x = self.activation(x)\n",
    "    return x"
   ],
   "metadata": {
    "id": "hzeGn41vbbVG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678878779716,
     "user_tz": -120,
     "elapsed": 1066,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK0Z9NeYTghv"
   },
   "source": [
    "## Definirea obiectelor folosite in timpul antrenarii\n",
    "\n",
    "### Cerinte **(1p)**\n",
    "  * Numarul de epoci (0.25 p)\n",
    "  * Retea (0.25 p)\n",
    "  * Optimizator (0.25 p)\n",
    "  * Alegeti functia de cost (0.25 p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Az3WKQdpod34",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678878779716,
     "user_tz": -120,
     "elapsed": 2,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Definiti numarul de epoci\n",
    "epochs = 10\n",
    "\n",
    "# Definiti reteaua\n",
    "network = Net()\n",
    "\n",
    "# Definiti optimizatorul\n",
    "optimizer = optim.SGD(network.parameters(), lr=1e-2)\n",
    "\"\"\"\n",
    "Dupa definirea optimizatorului si dupa fiecare iteratie de antrenare, trebuie \n",
    "apelata functia zero_grad() pentru a seta valoare tuturor gradientilor la zero.\n",
    "\"\"\"\n",
    "# Completati aici codul pentru seta valoare tuturor gradientilor la zero\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Definiti functia cost pentru clasificare Cross-Entropy\n",
    "# https://neptune.ai/blog/pytorch-loss-functions\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAnUsWYWodb4"
   },
   "source": [
    "## Definirea functiei de antrenare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dlBJUj_7GPjA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678878779717,
     "user_tz": -120,
     "elapsed": 3,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "K9MTYanoMZ8H",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678880184160,
     "user_tz": -120,
     "elapsed": 2,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    }
   },
   "outputs": [],
   "source": [
    "def test_acc(net: nn.Module, test_loader: DataLoader):\n",
    "  net.eval()\n",
    "\n",
    "  total = 0\n",
    "  correct = 0\n",
    "\n",
    "  for test_images, test_labels in test_loader:\n",
    "    total += len(test_images)\n",
    "    out_class = torch.argmax(net(test_images))\n",
    "    correct += torch.sum(out_class == test_labels)\n",
    "\n",
    "  return correct / total * 100\n",
    "\n",
    "\n",
    "def train_fn(epochs: int, train_loader: DataLoader, test_loader: DataLoader, \n",
    "             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n",
    "  # Iteram prin numarul de epoci\n",
    "  for e in range(epochs):\n",
    "    net.train()\n",
    "\n",
    "    # Iteram prin fiecare batch din dataloader\n",
    "    for images, labels in train_loader:\n",
    "      # Aplicam reteaua neurala pe imaginile din batch-ul curent\n",
    "      out = net(images)\n",
    "      # Aplicam functia cost pe iesirea retelei neurale si pe etichetele imaginilor \n",
    "      loss = loss_fn(out, labels)\n",
    "      # Aplicam algoritmul de back-propagation\n",
    "      loss.backward()\n",
    "      # Facem pasul de optimizare, pentru a actualiza parametrii retelei\n",
    "      optimizer.step()\n",
    "      # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n",
    "      optimizer.zero_grad()\n",
    "    \n",
    "    print(\"Loss-ul la finalul epocii {} are valoarea {}\".format(e, loss.item()))\n",
    "\n",
    "    # Calculam acuratetea\n",
    "    acc = test_acc(net, test_loader)\n",
    "    print(\"Acuratetea la finalul epocii {} este {:.2f}%\".format(e, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWvb00A-TkJq"
   },
   "source": [
    "\n",
    "## Antrenarea\n",
    "\n",
    "### Cerinte\n",
    "  * Antrenati reteaua definita mai sus (clasa Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZqUwOWmDMpqQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678872522717,
     "user_tz": -120,
     "elapsed": 212475,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "outputId": "46a1e1fd-337a-4931-c3be-1a730b763310"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss-ul la finalul epocii 0 are valoarea 2.3024702072143555\n",
      "Acuratetea la finalul epocii 1 este 9.93%\n",
      "Loss-ul la finalul epocii 1 are valoarea 2.301344633102417\n",
      "Acuratetea la finalul epocii 2 este 10.49%\n",
      "Loss-ul la finalul epocii 2 are valoarea 2.3025829792022705\n",
      "Acuratetea la finalul epocii 3 este 10.72%\n",
      "Loss-ul la finalul epocii 3 are valoarea 2.2998664379119873\n",
      "Acuratetea la finalul epocii 4 este 11.03%\n",
      "Loss-ul la finalul epocii 4 are valoarea 2.3001582622528076\n",
      "Acuratetea la finalul epocii 5 este 11.03%\n",
      "Loss-ul la finalul epocii 5 are valoarea 2.2987558841705322\n",
      "Acuratetea la finalul epocii 6 este 10.91%\n",
      "Loss-ul la finalul epocii 6 are valoarea 2.301168918609619\n",
      "Acuratetea la finalul epocii 7 este 10.91%\n",
      "Loss-ul la finalul epocii 7 are valoarea 2.2974815368652344\n",
      "Acuratetea la finalul epocii 8 este 10.68%\n",
      "Loss-ul la finalul epocii 8 are valoarea 2.292241096496582\n",
      "Acuratetea la finalul epocii 9 este 10.66%\n",
      "Loss-ul la finalul epocii 9 are valoarea 2.296569585800171\n",
      "Acuratetea la finalul epocii 10 este 10.55%\n"
     ]
    }
   ],
   "source": [
    "train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmVavwztTZkz"
   },
   "source": [
    "## Reteaua LeNet\n",
    "\n",
    "### Cerinte\n",
    "  * **(3p)** Implementati reteaua LeNet dupa figura de mai jos si antrenati-o.\n",
    "\n",
    "\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1OVancUyIViMRMZdULFSVCvXJHQP0NGUV)\n",
    "\n",
    "Figura arhitectura LeNet\n",
    "\n",
    "![alt text](https://debuggercafe.com/wp-content/uploads/2019/07/Layers-in-LeNet.png)\n",
    "\n",
    "Tabel arhitectura LeNet\n",
    "\n",
    "_Question:_ Care este diferenta dintre `tanh` si `softmax`? De ce credeti ca peste ultimul layer (cel de output) a fost aplicata functia `softmax`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zoe1vbggO-4U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678878779717,
     "user_tz": -120,
     "elapsed": 2,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \"\"\"\n",
    "    Punctaj: 2.5p\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Completati codul pentru cerinta aici\n",
    "    # input -> 1x1x32x32\n",
    "    # input -> layer1 ->  1x6x28x28\n",
    "    self.layer1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = (5, 5), stride = (1, 1))\n",
    "    # 1x6x28x28 -> layer2 -> 1x6x14x14\n",
    "    self.layer2 = nn.AvgPool2d(kernel_size = (2, 2), stride = (2, 2))\n",
    "    # 1x6x14x14 -> layer3 -> 1x16x10x10\n",
    "    self.layer3 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = (5, 5), stride = (1, 1))\n",
    "    # 1x16x10x10 -> layer4 -> 1x16x5x5\n",
    "    self.layer4 = nn.AvgPool2d(kernel_size = (2, 2), stride = (2, 2))\n",
    "    # 1x16x5x5 -> layer5 -> 1x120x1x1\n",
    "    self.layer5 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = (5, 5), stride = (1, 1))\n",
    "\n",
    "    self.fully_connected_layer1 = nn.Linear(120, 84, bias=False) \n",
    "    self.fully_connected_layer2 = nn.Linear(84, 10, bias=False) \n",
    "\n",
    "    self.activation1 = nn.Tanh()\n",
    "    self.activation2 = nn.Softmax()\n",
    "\n",
    "  def forward(self,x):\n",
    "    \"\"\"\n",
    "    Punctaj: 0.5p\n",
    "    \"\"\"\n",
    "    ### Completati codul pentru cerinta aici\n",
    "    x = self.layer1(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer2(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer3(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer4(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer5(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = x.reshape((-1, 120))\n",
    "\n",
    "    x = self.fully_connected_layer1(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.fully_connected_layer2(x)\n",
    "    x = self.activation2(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMaWPS1gXslS"
   },
   "source": [
    "## Optional: Reteaua AlexNet ❤️\n",
    "\n",
    "❗Daca alegeti aceasta retea veti continua sa rezolvati exercitiile urmatoare pentru reteaua AlexNet.\n",
    "\n",
    "Pentru a usura volumul de munca si obtine o retea AlexNet comparabila in dificultate cu LeNet, urmati acesti pasi:\n",
    "\n",
    "✔️ Includeti functii de activare intre layere (exemplu ReLU).\n",
    "\n",
    "✔️ Va folositi doar de prima subsectiune din schema figurii arhitecturii AlexNet (adica doar Conv1 si Conv2 blocks).\n",
    "\n",
    "✔️ Inputul vostru se opreste la un minimum size de 8x8.\n",
    "\n",
    "✔️ Modificati output-ul retelei sa prezica 10 clase in loc de 1000 de clase.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![alt text](https://anhreynolds.com/img/alexnet.png)\n",
    "\n",
    "Figura arhitectura AlexNet.\n",
    "\n",
    "![alt text](https://anhreynolds.com/img/alexnet-parameters.png)\n",
    "\n",
    "Tabel arhitectura AlexNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irXGsufhCiuG"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \"\"\"\n",
    "    Punctaj: 2.5p\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "  def forward(self,x):\n",
    "    \"\"\"\n",
    "    Punctaj: 0.5p\n",
    "    \"\"\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0XPmGrEol9M"
   },
   "source": [
    "## Redefinirea obiectelor folosite in timpul antrenarii pentru reteaua LeNet\n",
    "\n",
    "### Cerinta\n",
    " * Redefiniti obiectele pentru a antrena reteaua LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jhqNoDmQo66c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678878780754,
     "user_tz": -120,
     "elapsed": 1,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Definiti numarul de epoci\n",
    "epochs = 10\n",
    "\n",
    "# Definiti reteaua\n",
    "lenet = LeNet()\n",
    "\n",
    "# Definiti optimizatorul\n",
    "lenet_optimizer = optim.SGD(lenet.parameters(), lr=1e-2)\n",
    "# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n",
    "# Aceasta face toti gradientii zero.\n",
    "# Completati codul pentru a face gradientii zero aici\n",
    "lenet_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "# Definiti functia cost pentru clasificare Cross-Entropy\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwIQwUQpo_eR"
   },
   "source": [
    "## Antrenarea retelei LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UUl8W42do_sL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678874475294,
     "user_tz": -120,
     "elapsed": 294779,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "outputId": "81de1fd6-98e1-48fa-fd3a-01089b32303f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-20-421d6b342faf>:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.activation2(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss-ul la finalul epocii 0 are valoarea 2.302060604095459\n",
      "Acuratetea la finalul epocii 1 este 12.38%\n",
      "Loss-ul la finalul epocii 1 are valoarea 2.3019416332244873\n",
      "Acuratetea la finalul epocii 2 este 12.96%\n",
      "Loss-ul la finalul epocii 2 are valoarea 2.3018908500671387\n",
      "Acuratetea la finalul epocii 3 este 13.61%\n",
      "Loss-ul la finalul epocii 3 are valoarea 2.301589250564575\n",
      "Acuratetea la finalul epocii 4 este 14.32%\n",
      "Loss-ul la finalul epocii 4 are valoarea 2.3017125129699707\n",
      "Acuratetea la finalul epocii 5 este 14.78%\n",
      "Loss-ul la finalul epocii 5 are valoarea 2.301441192626953\n",
      "Acuratetea la finalul epocii 6 este 15.45%\n",
      "Loss-ul la finalul epocii 6 are valoarea 2.301663875579834\n",
      "Acuratetea la finalul epocii 7 este 15.99%\n",
      "Loss-ul la finalul epocii 7 are valoarea 2.3011982440948486\n",
      "Acuratetea la finalul epocii 8 este 16.20%\n",
      "Loss-ul la finalul epocii 8 are valoarea 2.3015010356903076\n",
      "Acuratetea la finalul epocii 9 este 16.56%\n",
      "Loss-ul la finalul epocii 9 are valoarea 2.3010897636413574\n",
      "Acuratetea la finalul epocii 10 este 16.82%\n"
     ]
    }
   ],
   "source": [
    "train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OspDtfFnTodr"
   },
   "source": [
    "###Augmentare retea\n",
    "\n",
    "Reteaua de mai devreme duce lipsa de regularizare. O forma foarte puternica de regularizare este normalizarea, iar pentru acest lucru exista straturi speciale.\n",
    "\n",
    "Astfel de straturi:\n",
    "\n",
    "* [torch.nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) (num_features)\n",
    "* [torch.nn.InstanceNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html) (num_features)\n",
    "\n",
    "Un alt element important il reprezinta functiile de activare, care pot influenta convergenta si puterea retelei. Cateva exemple de alte functii de activare:\n",
    "\n",
    "* ReLU\n",
    "* Sigmoid\n",
    "* Tanh\n",
    "* LeakyRelu\n",
    "* GELU\n",
    "\n",
    "## Cerinta\n",
    "\n",
    "**(2p)** Experimentati cu aceste elemente in cadrul retelei LeNet definita mai devreme, pentru a obtine o acuratete mai buna. Observati viteza de convergenta si performanta retelei pentru 3 configuratii diferite.\n",
    "\n",
    "**Punctaj:** 0.6p / configuratie.\n",
    "\n",
    "0.6p din care:\n",
    "- 0.4p modificarea retelei\n",
    "- 0.1p obtinerea rezultatelor\n",
    "- 0.1p afisarea acestora si explicatie.\n",
    "\n",
    "\n",
    "###Bonus\n",
    "**(1p)** Antrenati reteaua folosind GPU (Graphics processing unit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678880608498,
     "user_tz": -120,
     "elapsed": 2,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "id": "VrxMnKPk-nyI"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# DEFAULT\n",
    "class LeNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \"\"\"\n",
    "    Punctaj: 2.5p\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Completati codul pentru cerinta aici\n",
    "    # input -> 1x1x32x32\n",
    "    # input -> layer1 ->  1x6x28x28\n",
    "    self.layer1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = (5, 5), stride = (1, 1))\n",
    "    # 1x6x28x28 -> layer2 -> 1x6x14x14\n",
    "    self.layer2 = nn.AvgPool2d(kernel_size = (2, 2), stride = (2, 2))\n",
    "    # 1x6x14x14 -> layer3 -> 1x16x10x10\n",
    "    self.layer3 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = (5, 5), stride = (1, 1))\n",
    "    # 1x16x10x10 -> layer4 -> 1x16x5x5\n",
    "    self.layer4 = nn.AvgPool2d(kernel_size = (2, 2), stride = (2, 2))\n",
    "    # 1x16x5x5 -> layer5 -> 1x120x1x1\n",
    "    self.layer5 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = (5, 5), stride = (1, 1))\n",
    "\n",
    "    self.fully_connected_layer1 = nn.Linear(120, 84, bias=False) \n",
    "    self.fully_connected_layer2 = nn.Linear(84, 10, bias=False) \n",
    "\n",
    "    self.activation1 = nn.Tanh()\n",
    "    self.activation2 = nn.Softmax()\n",
    "\n",
    "  def forward(self,x):\n",
    "    \"\"\"\n",
    "    Punctaj: 0.5p\n",
    "    \"\"\"\n",
    "    ### Completati codul pentru cerinta aici\n",
    "    x = self.layer1(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer2(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer3(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer4(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer5(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = x.reshape((-1, 120))\n",
    "\n",
    "    x = self.fully_connected_layer1(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.fully_connected_layer2(x)\n",
    "    x = self.activation2(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678880610575,
     "user_tz": -120,
     "elapsed": 1,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "id": "ek1EmU9H-rgb"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Definiti numarul de epoci\n",
    "epochs = 10\n",
    "\n",
    "# Definiti reteaua\n",
    "lenet = LeNet()\n",
    "\n",
    "# Definiti optimizatorul\n",
    "lenet_optimizer = optim.SGD(lenet.parameters(), lr=1e-2)\n",
    "# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n",
    "# Aceasta face toti gradientii zero.\n",
    "# Completati codul pentru a face gradientii zero aici\n",
    "lenet_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "# Definiti functia cost pentru clasificare Cross-Entropy\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hg5AJgyE-uET",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678880935052,
     "user_tz": -120,
     "elapsed": 323475,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "outputId": "f3234bad-2c3e-4366-ed9d-0d790f8f7900"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-22-8e9e11e1e750>:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.activation2(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss-ul la finalul epocii 0 are valoarea 2.302436113357544\n",
      "Acuratetea la finalul epocii 0 este 11.59%\n",
      "Loss-ul la finalul epocii 1 are valoarea 2.302324056625366\n",
      "Acuratetea la finalul epocii 1 este 12.38%\n",
      "Loss-ul la finalul epocii 2 are valoarea 2.3023316860198975\n",
      "Acuratetea la finalul epocii 2 este 13.08%\n",
      "Loss-ul la finalul epocii 3 are valoarea 2.3020753860473633\n",
      "Acuratetea la finalul epocii 3 este 13.68%\n",
      "Loss-ul la finalul epocii 4 are valoarea 2.302049160003662\n",
      "Acuratetea la finalul epocii 4 este 14.25%\n",
      "Loss-ul la finalul epocii 5 are valoarea 2.301835060119629\n",
      "Acuratetea la finalul epocii 5 este 14.58%\n",
      "Loss-ul la finalul epocii 6 are valoarea 2.3020224571228027\n",
      "Acuratetea la finalul epocii 6 este 15.12%\n",
      "Loss-ul la finalul epocii 7 are valoarea 2.3015427589416504\n",
      "Acuratetea la finalul epocii 7 este 15.72%\n",
      "Loss-ul la finalul epocii 8 are valoarea 2.3017613887786865\n",
      "Acuratetea la finalul epocii 8 este 15.94%\n",
      "Loss-ul la finalul epocii 9 are valoarea 2.3014843463897705\n",
      "Acuratetea la finalul epocii 9 este 16.76%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678881044636,
     "user_tz": -120,
     "elapsed": 1,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "id": "sA26fBbvA2HU"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# DEFAULT + NORMALIZARE\n",
    "class LeNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \"\"\"\n",
    "    Punctaj: 2.5p\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Completati codul pentru cerinta aici\n",
    "    # input -> 1x1x32x32\n",
    "    # input -> layer1 ->  1x6x28x28\n",
    "    self.layer1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = (5, 5), stride = (1, 1))\n",
    "    # 1x6x28x28 -> layer2 -> 1x6x14x14\n",
    "    self.layer2 = nn.AvgPool2d(kernel_size = (2, 2), stride = (2, 2))\n",
    "    # 1x6x14x14 -> layer3 -> 1x16x10x10\n",
    "    self.layer3 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = (5, 5), stride = (1, 1))\n",
    "    # 1x16x10x10 -> layer4 -> 1x16x5x5\n",
    "    self.layer4 = nn.AvgPool2d(kernel_size = (2, 2), stride = (2, 2))\n",
    "    # 1x16x5x5 -> layer5 -> 1x120x1x1\n",
    "    self.layer5 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = (5, 5), stride = (1, 1))\n",
    "\n",
    "    self.fully_connected_layer1 = nn.Linear(120, 84, bias=False) \n",
    "    self.fully_connected_layer2 = nn.Linear(84, 10, bias=False) \n",
    "\n",
    "    self.activation1 = nn.Tanh()\n",
    "    self.activation2 = nn.Softmax()\n",
    "\n",
    "    self.normalization1 = nn.BatchNorm2d(num_features=6)\n",
    "    self.normalization2 = nn.BatchNorm2d(num_features=16)\n",
    "    self.normalization3 = nn.BatchNorm2d(num_features=120)\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    \"\"\"\n",
    "    Punctaj: 0.5p\n",
    "    \"\"\"\n",
    "    ### Completati codul pentru cerinta aici\n",
    "    x = self.layer1(x)\n",
    "    x = self.normalization1(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer2(x)\n",
    "    # x = self.activation1(x)\n",
    "\n",
    "    x = self.layer3(x)\n",
    "    x = self.normalization2(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer4(x)\n",
    "    # x = self.activation1(x)\n",
    "\n",
    "    x = self.layer5(x)\n",
    "    x = self.normalization3(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = x.reshape((-1, 120))\n",
    "\n",
    "    x = self.fully_connected_layer1(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.fully_connected_layer2(x)\n",
    "    x = self.activation2(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678881046045,
     "user_tz": -120,
     "elapsed": 977,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "id": "GWu24KSDCRj3"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Definiti numarul de epoci\n",
    "epochs = 10\n",
    "\n",
    "# Definiti reteaua\n",
    "lenet = LeNet()\n",
    "\n",
    "# Definiti optimizatorul\n",
    "lenet_optimizer = optim.SGD(lenet.parameters(), lr=1e-2)\n",
    "# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n",
    "# Aceasta face toti gradientii zero.\n",
    "# Completati codul pentru a face gradientii zero aici\n",
    "lenet_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "# Definiti functia cost pentru clasificare Cross-Entropy\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678881396210,
     "user_tz": -120,
     "elapsed": 347719,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "outputId": "cda86276-38c6-425a-eddf-93af93b62990",
    "id": "yLA4dv4TCToF"
   },
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-31-1b3d9746ce56>:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.activation2(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss-ul la finalul epocii 0 are valoarea 2.2963500022888184\n",
      "Acuratetea la finalul epocii 0 este 15.13%\n",
      "Loss-ul la finalul epocii 1 are valoarea 2.28709077835083\n",
      "Acuratetea la finalul epocii 1 este 18.33%\n",
      "Loss-ul la finalul epocii 2 are valoarea 2.276447057723999\n",
      "Acuratetea la finalul epocii 2 este 20.19%\n",
      "Loss-ul la finalul epocii 3 are valoarea 2.2688655853271484\n",
      "Acuratetea la finalul epocii 3 este 20.17%\n",
      "Loss-ul la finalul epocii 4 are valoarea 2.254565715789795\n",
      "Acuratetea la finalul epocii 4 este 20.30%\n",
      "Loss-ul la finalul epocii 5 are valoarea 2.2562661170959473\n",
      "Acuratetea la finalul epocii 5 este 20.37%\n",
      "Loss-ul la finalul epocii 6 are valoarea 2.243040084838867\n",
      "Acuratetea la finalul epocii 6 este 20.71%\n",
      "Loss-ul la finalul epocii 7 are valoarea 2.2277400493621826\n",
      "Acuratetea la finalul epocii 7 este 20.94%\n",
      "Loss-ul la finalul epocii 8 are valoarea 2.2499380111694336\n",
      "Acuratetea la finalul epocii 8 este 21.52%\n",
      "Loss-ul la finalul epocii 9 are valoarea 2.2439651489257812\n",
      "Acuratetea la finalul epocii 9 este 22.35%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import to_tensor, normalize\n",
    "\n",
    "def collate_fn(examples):\n",
    "  ### Completati codul pentru cerinta aici\n",
    "  processed_images = []\n",
    "  processed_labels = []\n",
    "\n",
    "  for example in examples:\n",
    "    tensor_image = to_tensor(example[0].convert('L'))\n",
    "    # In linia de mai jos imaginea este normalizata astfel incat sa aiba toate valorile in \n",
    "    # [-1, 1] in loc de [0, 255]\n",
    "    normalized_tensor_image = normalize(tensor_image, [0.5], [0.5])\n",
    "    normalized_tensor_image = normalized_tensor_image.unsqueeze(0)\n",
    "\n",
    "    processed_images.append(normalized_tensor_image)\n",
    "    \n",
    "    label = np.array(example[1])\n",
    "    tensor_label = torch.tensor(label)\n",
    "    tensor_label = tensor_label.unsqueeze(0)\n",
    "    processed_labels.append(tensor_label)\n",
    "\n",
    "  torch_images = torch.cat(processed_images, dim=0)\n",
    "  torch_labels = torch.cat(processed_labels, dim=0)\n",
    "\n",
    "  return torch_images, torch_labels\n",
    "\n",
    "train_loader = DataLoader(cifar_train, batch_size=500, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ],
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678882367535,
     "user_tz": -120,
     "elapsed": 9754,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "id": "58vkWrW-JkSB"
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678882367536,
     "user_tz": -120,
     "elapsed": 2,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "id": "xKqnXQ3vEDf1"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# DEFAULT + NORMALIZARE + ALTE FUNCTII ACTIVARE\n",
    "class LeNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \"\"\"\n",
    "    Punctaj: 2.5p\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Completati codul pentru cerinta aici\n",
    "    # input -> 1x1x32x32\n",
    "    # input -> layer1 ->  1x6x28x28\n",
    "    self.layer1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = (5, 5), stride = (1, 1))\n",
    "    # 1x6x28x28 -> layer2 -> 1x6x14x14\n",
    "    self.layer2 = nn.AvgPool2d(kernel_size = (2, 2), stride = (2, 2))\n",
    "    # 1x6x14x14 -> layer3 -> 1x16x10x10\n",
    "    self.layer3 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = (5, 5), stride = (1, 1))\n",
    "    # 1x16x10x10 -> layer4 -> 1x16x5x5\n",
    "    self.layer4 = nn.AvgPool2d(kernel_size = (2, 2), stride = (2, 2))\n",
    "    # 1x16x5x5 -> layer5 -> 1x120x1x1\n",
    "    self.layer5 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = (5, 5), stride = (1, 1))\n",
    "\n",
    "    self.fully_connected_layer1 = nn.Linear(120, 84, bias=False) \n",
    "    self.fully_connected_layer2 = nn.Linear(84, 10, bias=False) \n",
    "\n",
    "    self.activation1 = nn.SELU()\n",
    "    self.activation2 = nn.Softmax()\n",
    "\n",
    "    self.normalization1 = nn.BatchNorm2d(num_features=6)\n",
    "    self.normalization2 = nn.BatchNorm2d(num_features=16)\n",
    "    self.normalization3 = nn.BatchNorm2d(num_features=120)\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    \"\"\"\n",
    "    Punctaj: 0.5p\n",
    "    \"\"\"\n",
    "    ### Completati codul pentru cerinta aici\n",
    "    x = self.layer1(x)\n",
    "    x = self.normalization1(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer2(x)\n",
    "    # x = self.activation1(x)\n",
    "\n",
    "    x = self.layer3(x)\n",
    "    x = self.normalization2(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.layer4(x)\n",
    "    # x = self.activation1(x)\n",
    "\n",
    "    x = self.layer5(x)\n",
    "    x = self.normalization3(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = x.reshape((-1, 120))\n",
    "\n",
    "    x = self.fully_connected_layer1(x)\n",
    "    x = self.activation1(x)\n",
    "\n",
    "    x = self.fully_connected_layer2(x)\n",
    "    x = self.activation2(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678882728774,
     "user_tz": -120,
     "elapsed": 418,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "id": "vESjjZuCEK3z"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Definiti numarul de epoci\n",
    "epochs = 10\n",
    "\n",
    "# Definiti reteaua\n",
    "lenet = LeNet()\n",
    "\n",
    "# Definiti optimizatorul\n",
    "lenet_optimizer = optim.SGD(lenet.parameters(), lr=0.1)\n",
    "# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n",
    "# Aceasta face toti gradientii zero.\n",
    "# Completati codul pentru a face gradientii zero aici\n",
    "lenet_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "# Definiti functia cost pentru clasificare Cross-Entropy\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678881968229,
     "user_tz": -120,
     "elapsed": 351285,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "outputId": "e3a9db4b-b727-4e22-83dc-30146201099a",
    "id": "1TJZlsa8EM2x"
   },
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-43-75e2d6dc5693>:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.activation2(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss-ul la finalul epocii 0 are valoarea 2.278597354888916\n",
      "Acuratetea la finalul epocii 0 este 22.89%\n",
      "Loss-ul la finalul epocii 1 are valoarea 2.252464771270752\n",
      "Acuratetea la finalul epocii 1 este 24.54%\n",
      "Loss-ul la finalul epocii 2 are valoarea 2.2264788150787354\n",
      "Acuratetea la finalul epocii 2 este 26.19%\n",
      "Loss-ul la finalul epocii 3 are valoarea 2.221421003341675\n",
      "Acuratetea la finalul epocii 3 este 27.64%\n",
      "Loss-ul la finalul epocii 4 are valoarea 2.1977717876434326\n",
      "Acuratetea la finalul epocii 4 este 29.76%\n",
      "Loss-ul la finalul epocii 5 are valoarea 2.1969754695892334\n",
      "Acuratetea la finalul epocii 5 este 31.43%\n",
      "Loss-ul la finalul epocii 6 are valoarea 2.1907174587249756\n",
      "Acuratetea la finalul epocii 6 este 32.48%\n",
      "Loss-ul la finalul epocii 7 are valoarea 2.169053554534912\n",
      "Acuratetea la finalul epocii 7 este 33.46%\n",
      "Loss-ul la finalul epocii 8 are valoarea 2.1550779342651367\n",
      "Acuratetea la finalul epocii 8 este 34.21%\n",
      "Loss-ul la finalul epocii 9 are valoarea 2.1410598754882812\n",
      "Acuratetea la finalul epocii 9 este 34.89%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1678883057185,
     "user_tz": -120,
     "elapsed": 326237,
     "user": {
      "displayName": "Alex Preda",
      "userId": "00237785018849252219"
     }
    },
    "outputId": "951c4305-3732-4e83-adc0-64daca237b50",
    "id": "VWUjMqpVK_u-"
   },
   "execution_count": 61,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-52-979baae17cd3>:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.activation2(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss-ul la finalul epocii 0 are valoarea 2.216125011444092\n",
      "Acuratetea la finalul epocii 0 este 26.84%\n",
      "Loss-ul la finalul epocii 1 are valoarea 2.1785318851470947\n",
      "Acuratetea la finalul epocii 1 este 30.31%\n",
      "Loss-ul la finalul epocii 2 are valoarea 2.1264913082122803\n",
      "Acuratetea la finalul epocii 2 este 31.97%\n",
      "Loss-ul la finalul epocii 3 are valoarea 2.113781213760376\n",
      "Acuratetea la finalul epocii 3 este 34.31%\n",
      "Loss-ul la finalul epocii 4 are valoarea 2.097304105758667\n",
      "Acuratetea la finalul epocii 4 este 32.34%\n",
      "Loss-ul la finalul epocii 5 are valoarea 2.0740599632263184\n",
      "Acuratetea la finalul epocii 5 este 37.17%\n",
      "Loss-ul la finalul epocii 6 are valoarea 2.064319133758545\n",
      "Acuratetea la finalul epocii 6 este 37.01%\n",
      "Loss-ul la finalul epocii 7 are valoarea 2.0350029468536377\n",
      "Acuratetea la finalul epocii 7 este 41.25%\n",
      "Loss-ul la finalul epocii 8 are valoarea 2.037080764770508\n",
      "Acuratetea la finalul epocii 8 este 39.82%\n",
      "Loss-ul la finalul epocii 9 are valoarea 2.0257980823516846\n",
      "Acuratetea la finalul epocii 9 este 42.63%\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "c62addee9b62473abbfe1f66274ab98a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_020ab6ba04974b33ab5aca25f5502250",
       "IPY_MODEL_de1540a97ea949ea9b00daf93309ff1f",
       "IPY_MODEL_ab9fcdcdeb584fd68d1734237d11419f"
      ],
      "layout": "IPY_MODEL_ad627174b9f2491dbabcc2468fa52acd"
     }
    },
    "020ab6ba04974b33ab5aca25f5502250": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b866d589f07f47d5a1ea7944f02d985b",
      "placeholder": "​",
      "style": "IPY_MODEL_d36d8466c85a46d396e5e5597868e067",
      "value": "100%"
     }
    },
    "de1540a97ea949ea9b00daf93309ff1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fd5970f67e0413c9e6934142b9b1124",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f0956001a2d4ca58d72fa2ee6ce7382",
      "value": 170498071
     }
    },
    "ab9fcdcdeb584fd68d1734237d11419f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0feb90fcaf9d4abd8d0448498331095b",
      "placeholder": "​",
      "style": "IPY_MODEL_e2bb586c72bd4211bf3a6e39b27b370f",
      "value": " 170498071/170498071 [00:32&lt;00:00, 32498384.19it/s]"
     }
    },
    "ad627174b9f2491dbabcc2468fa52acd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b866d589f07f47d5a1ea7944f02d985b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d36d8466c85a46d396e5e5597868e067": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8fd5970f67e0413c9e6934142b9b1124": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f0956001a2d4ca58d72fa2ee6ce7382": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0feb90fcaf9d4abd8d0448498331095b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2bb586c72bd4211bf3a6e39b27b370f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
