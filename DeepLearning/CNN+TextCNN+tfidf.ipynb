{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.113029Z",
     "start_time": "2025-01-09T20:29:45.109490Z"
    }
   },
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "from torchvision import transforms\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from textblob import TextBlob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Disable UserWarnings\n",
    "tqdm.pandas()"
   ],
   "outputs": [],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.202306Z",
     "start_time": "2025-01-09T20:29:45.180472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(\"./dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"./dataset/test.csv\")\n",
    "validation_df = pd.read_csv(\"./dataset/val.csv\")"
   ],
   "id": "68a1a9efa01eeb80",
   "outputs": [],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.255949Z",
     "start_time": "2025-01-09T20:29:45.217545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import text_preprocessing\n",
    "\n",
    "train_df['preprocessed_text'] = train_df['caption'].progress_apply(text_preprocessing.text_preparetion_simple)\n",
    "validation_df['preprocessed_text'] = validation_df['caption'].progress_apply(text_preprocessing.text_preparetion_simple)\n",
    "test_df['preprocessed_text'] = test_df['caption'].progress_apply(text_preprocessing.text_preparetion_simple)"
   ],
   "id": "decdaddece6dce3d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 548576.21it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 497308.99it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 283016.46it/s]\n"
     ]
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.261495Z",
     "start_time": "2025-01-09T20:29:45.256457Z"
    }
   },
   "cell_type": "code",
   "source": "train_df",
   "id": "348bb7544ec995b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                        id  \\\n",
       "0     417812c5-0ce4-499d-b97d-4d28827239bc   \n",
       "1     5ac91fa3-55f2-4cb3-8c8f-ad84f78e6b36   \n",
       "2     d2705b90-8347-4cab-a7a6-654540d9a489   \n",
       "3     a3b33fe7-3085-4433-9c18-8814803891b4   \n",
       "4     1514b0e4-0665-45bc-ab32-52fce326cc29   \n",
       "...                                    ...   \n",
       "9995  1d1df243-485d-4b29-82c8-7e34c0de1f5c   \n",
       "9996  f7dfa883-e524-4974-b5ba-6b3c3db49087   \n",
       "9997  602e83dc-6539-4c1a-8d19-c1481b5c24bf   \n",
       "9998  d9ce2e8c-0831-466a-8756-4c40d772b1ce   \n",
       "9999  b22cdca0-79b3-4b37-a173-5176a32096f6   \n",
       "\n",
       "                                                caption  image_id  label  \\\n",
       "0     Wet elephants shake water onto people bathing ...    394330      0   \n",
       "1          Two men holding tennis racquets on the court    130849      0   \n",
       "2     A bird on a tree limb with mountains in the ba...    514790      0   \n",
       "3     A kitchen and dining room are featured along w...    182096      0   \n",
       "4        A fruit stand has various fruits on the table.     68788      1   \n",
       "...                                                 ...       ...    ...   \n",
       "9995     Several people stand in a field flying a kite.    522702      0   \n",
       "9996       A batter hitting a pitch at a baseball game.    441874      1   \n",
       "9997  A person on white surfboard next to group in a...    166716      0   \n",
       "9998  A baseball player getting ready to swing at th...    517601      0   \n",
       "9999                    a black cat is laying in a sink    394115      1   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "0     wet elephants shake water onto people bathing ...  \n",
       "1          two men holding tennis racquets on the court  \n",
       "2     a bird on a tree limb with mountains in the ba...  \n",
       "3     a kitchen and dining room are featured along w...  \n",
       "4         a fruit stand has various fruits on the table  \n",
       "...                                                 ...  \n",
       "9995      several people stand in a field flying a kite  \n",
       "9996        a batter hitting a pitch at a baseball game  \n",
       "9997  a person on white surfboard next to group in a...  \n",
       "9998  a baseball player getting ready to swing at th...  \n",
       "9999                    a black cat is laying in a sink  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>caption</th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>417812c5-0ce4-499d-b97d-4d28827239bc</td>\n",
       "      <td>Wet elephants shake water onto people bathing ...</td>\n",
       "      <td>394330</td>\n",
       "      <td>0</td>\n",
       "      <td>wet elephants shake water onto people bathing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ac91fa3-55f2-4cb3-8c8f-ad84f78e6b36</td>\n",
       "      <td>Two men holding tennis racquets on the court</td>\n",
       "      <td>130849</td>\n",
       "      <td>0</td>\n",
       "      <td>two men holding tennis racquets on the court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d2705b90-8347-4cab-a7a6-654540d9a489</td>\n",
       "      <td>A bird on a tree limb with mountains in the ba...</td>\n",
       "      <td>514790</td>\n",
       "      <td>0</td>\n",
       "      <td>a bird on a tree limb with mountains in the ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a3b33fe7-3085-4433-9c18-8814803891b4</td>\n",
       "      <td>A kitchen and dining room are featured along w...</td>\n",
       "      <td>182096</td>\n",
       "      <td>0</td>\n",
       "      <td>a kitchen and dining room are featured along w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1514b0e4-0665-45bc-ab32-52fce326cc29</td>\n",
       "      <td>A fruit stand has various fruits on the table.</td>\n",
       "      <td>68788</td>\n",
       "      <td>1</td>\n",
       "      <td>a fruit stand has various fruits on the table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1d1df243-485d-4b29-82c8-7e34c0de1f5c</td>\n",
       "      <td>Several people stand in a field flying a kite.</td>\n",
       "      <td>522702</td>\n",
       "      <td>0</td>\n",
       "      <td>several people stand in a field flying a kite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>f7dfa883-e524-4974-b5ba-6b3c3db49087</td>\n",
       "      <td>A batter hitting a pitch at a baseball game.</td>\n",
       "      <td>441874</td>\n",
       "      <td>1</td>\n",
       "      <td>a batter hitting a pitch at a baseball game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>602e83dc-6539-4c1a-8d19-c1481b5c24bf</td>\n",
       "      <td>A person on white surfboard next to group in a...</td>\n",
       "      <td>166716</td>\n",
       "      <td>0</td>\n",
       "      <td>a person on white surfboard next to group in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>d9ce2e8c-0831-466a-8756-4c40d772b1ce</td>\n",
       "      <td>A baseball player getting ready to swing at th...</td>\n",
       "      <td>517601</td>\n",
       "      <td>0</td>\n",
       "      <td>a baseball player getting ready to swing at th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>b22cdca0-79b3-4b37-a173-5176a32096f6</td>\n",
       "      <td>a black cat is laying in a sink</td>\n",
       "      <td>394115</td>\n",
       "      <td>1</td>\n",
       "      <td>a black cat is laying in a sink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.271109Z",
     "start_time": "2025-01-09T20:29:45.261999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_tfidf(sentences, max_features=None):\n",
    "    \"\"\"\n",
    "    Initialize and fit a TF-IDF vectorizer with given sentences.\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of str): Sentences to vectorize.\n",
    "        max_features (int): Maximum number of features (vocabulary size).\n",
    "    \n",
    "    Returns:\n",
    "        TfidfVectorizer: A fitted TF-IDF vectorizer.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=max_features,\n",
    "        ngram_range=(1, 3),  # Include unigrams, bigrams, and trigrams for richer context\n",
    "        max_df=0.9,  # Ignore terms that appear in more than 90% of documents (common words)\n",
    "        min_df=3,  # Include terms appearing in at least 3 documents (remove rare noise))\n",
    "    )\n",
    "    vectorizer.fit(sentences)\n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "# Vectorize a sentence using the TF-IDF vectorizer\n",
    "def vectorize_sentence(sentence, vectorizer):\n",
    "    \"\"\"\n",
    "    Converts a sentence into a sparse tensor of TF-IDF values using a given vectorizer.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): Input sentence.\n",
    "        vectorizer (TfidfVectorizer): TF-IDF vectorizer.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Vectorized sentence as a tensor.\n",
    "    \"\"\"\n",
    "    vector = vectorizer.transform([sentence])\n",
    "    return torch.tensor(vector.toarray(), dtype=torch.float32).squeeze(0)\n",
    "\n",
    "\n",
    "# Custom Dataset Class\n",
    "class TFIDFDataset(Dataset):\n",
    "    def __init__(self, dataframe, vectorizer, images_path, train=True, augmentation_prob=0.3):\n",
    "        \"\"\"\n",
    "        Dataset for preprocessing image-text pairs with TF-IDF vectorization.\n",
    "\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame containing 'image_id', 'sentence', and optionally 'label'.\n",
    "            vectorizer (TfidfVectorizer): TF-IDF vectorizer for text.\n",
    "            images_path (str): Base path to the images.\n",
    "            train (bool): Whether this is a training dataset.\n",
    "            max_len (int): Maximum length for sentences in terms of features. Truncation isn't typical with TF-IDF.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dataframe = dataframe\n",
    "        self.vectorizer = vectorizer\n",
    "        self.train = train\n",
    "        self.images_path = images_path\n",
    "        self.augmentation_prob = augmentation_prob\n",
    "        # Define image transformations\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(100, scale=(0.8, 1.0)),\n",
    "            # transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        sentence = row['caption']\n",
    "\n",
    "        if random.random() < self.augmentation_prob:\n",
    "            # sentence = self.augment_text(sentence)\n",
    "            sentence = self.synonym_replacement(sentence)\n",
    "\n",
    "        vectorized_sentence = vectorize_sentence(sentence, self.vectorizer)\n",
    "\n",
    "        # Process image\n",
    "        image_path = f\"{self.images_path}{row['image_id']}.jpg\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")  # Convert to RGB\n",
    "            image = self.image_transform(image)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
    "\n",
    "        # Handle labels (for training)\n",
    "        if self.train:\n",
    "            label = row['label']\n",
    "            return {\n",
    "                'images': image,\n",
    "                'captions': vectorized_sentence,\n",
    "                'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'images': image,\n",
    "                'captions': vectorized_sentence,\n",
    "                'id': row['id']\n",
    "            }\n",
    "\n",
    "    def augment_text(self, text):\n",
    "        \"\"\" Augment text using synonym replacement and rephrasing. \"\"\"\n",
    "        if random.random() < 0.5:\n",
    "            return self.synonym_replacement(text)\n",
    "        else:\n",
    "            return self.rephrase_text(text)\n",
    "\n",
    "\n",
    "    def synonym_replacement(self, text):\n",
    "        # Tokenize the sentence\n",
    "        words = nltk.word_tokenize(text)\n",
    "        new_words = words.copy()\n",
    "    \n",
    "        # Find indices of words that can be replaced\n",
    "        replaceable = [i for i, word in enumerate(words) if wordnet.synsets(word)]\n",
    "        \n",
    "        # Randomly choose half of these words to replace\n",
    "        num_to_replace = len(replaceable) // 2\n",
    "        chosen_indices = random.sample(replaceable, num_to_replace)\n",
    "    \n",
    "        # Replace chosen words with synonyms\n",
    "        for i in chosen_indices:\n",
    "            synsets = wordnet.synsets(words[i])\n",
    "            if synsets:\n",
    "                # Choose a random synonym from the first synset\n",
    "                synonyms = list(set([lemma.name() for lemma in synsets[0].lemmas() if lemma.name() != words[i]]))\n",
    "                if synonyms:\n",
    "                    new_words[i] = random.choice(synonyms).replace('_', ' ')\n",
    "\n",
    "        # Reconstruct the sentence\n",
    "        return ' '.join(new_words)\n",
    "\n",
    "\n",
    "    def rephrase_text(self, text):\n",
    "        blob = TextBlob(text)\n",
    "        return str(blob.correct())"
   ],
   "id": "b120e5be81dc41aa",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.424361Z",
     "start_time": "2025-01-09T20:29:45.272110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorizer = initialize_tfidf(train_df['preprocessed_text'], max_features=None)\n",
    "max_len = len(vectorizer.get_feature_names_out())  # max_features\n",
    "max_len"
   ],
   "id": "434eac424e669b66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15447"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.427919Z",
     "start_time": "2025-01-09T20:29:45.425385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TFIDFDataset(train_df, vectorizer, images_path=\"./dataset/train_images/\", train=True)\n",
    "test_dataset = TFIDFDataset(test_df, vectorizer, images_path=\"./dataset/test_images/\", train=False)\n",
    "val_dataset = TFIDFDataset(validation_df, vectorizer, images_path=\"./dataset/val_images/\", train=True)"
   ],
   "id": "f6a9c5515a874c53",
   "outputs": [],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.432020Z",
     "start_time": "2025-01-09T20:29:45.428427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ],
   "id": "ef7e8ef05ced1727",
   "outputs": [],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.478257Z",
     "start_time": "2025-01-09T20:29:45.433541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "images = batch['images']\n",
    "captions = batch['captions']\n",
    "print(images.shape)\n",
    "print(captions.shape)\n",
    "print(captions[0])"
   ],
   "id": "c15ef9418428fccb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 100, 100])\n",
      "torch.Size([16, 15447])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.481785Z",
     "start_time": "2025-01-09T20:29:45.478766Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "51c0d07bf84fb724",
   "outputs": [],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.485329Z",
     "start_time": "2025-01-09T20:29:45.482290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ],
   "id": "2d2cc743de7dbeb2",
   "outputs": [],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.490387Z",
     "start_time": "2025-01-09T20:29:45.486344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, cnn_dropout_value):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.CNN_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(cnn_dropout_value),\n",
    "            SEBlock(16),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(cnn_dropout_value),\n",
    "            SEBlock(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=7, stride=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(cnn_dropout_value),\n",
    "            SEBlock(32),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, images):\n",
    "        img_features = self.CNN_block(images)  # (Batch, 128, 1, 1)\n",
    "        img_features = self.flatten(img_features)  # (Batch, 128)\n",
    "        return img_features"
   ],
   "id": "f0cf44b7b652262c",
   "outputs": [],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.494477Z",
     "start_time": "2025-01-09T20:29:45.491388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SEBlock1D(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock1D, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)"
   ],
   "id": "d3b9361117eb34",
   "outputs": [],
   "execution_count": 220
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.519816Z",
     "start_time": "2025-01-09T20:29:45.514761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextModule(nn.Module):\n",
    "    def __init__(self, cnn_dropout_value, text_features_size):\n",
    "        super(TextModule, self).__init__()\n",
    "\n",
    "        self.tfidf_feature_extract = nn.Sequential(\n",
    "            nn.Linear(text_features_size, 1028),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(cnn_dropout_value),\n",
    "            nn.Linear(1028, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(cnn_dropout_value),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.CNN1d = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Dropout(cnn_dropout_value),\n",
    "            SEBlock1D(16),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(cnn_dropout_value),\n",
    "            SEBlock1D(32),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=32, out_channels=32, kernel_size=7, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(cnn_dropout_value),\n",
    "            SEBlock1D(32),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, captions):\n",
    "        captions = captions.unsqueeze(1)\n",
    "        text_features = self.tfidf_feature_extract(captions)\n",
    "        text_features = self.CNN1d(text_features)  # \n",
    "        text_features = self.flatten(text_features)  # \n",
    "        return text_features"
   ],
   "id": "e6ea631b4226a0d8",
   "outputs": [],
   "execution_count": 221
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.538057Z",
     "start_time": "2025-01-09T20:29:45.534498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, image_feature_dim, text_feature_dim, head_dropout_value, num_classes):\n",
    "        super(Head, self).__init__()\n",
    "        # self.one_linear_head = nn.Linear(image_feature_dim + text_feature_dim, num_classes)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(image_feature_dim + text_feature_dim, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(head_dropout_value),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, img_features, text_features):\n",
    "        combined_features = torch.cat((img_features, text_features), dim=1)  # (Batch, 128 + EmbeddingDim)\n",
    "        features = self.head(combined_features)\n",
    "        # features = self.one_linear_head(combined_features)\n",
    "        return features.squeeze(1)  # Logits (not probabilities)"
   ],
   "id": "5366b540a2446756",
   "outputs": [],
   "execution_count": 222
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.553756Z",
     "start_time": "2025-01-09T20:29:45.550720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ImageTextClassifier(nn.Module):\n",
    "    def __init__(self, cnn_dropout_value, head_dropout_value, text_features_size, num_classes=1):\n",
    "        super(ImageTextClassifier, self).__init__()\n",
    "        self.cnn = CNN(cnn_dropout_value)\n",
    "        self.text_module = TextModule(cnn_dropout_value, text_features_size)\n",
    "        self.head = Head(image_feature_dim=32, text_feature_dim=32, head_dropout_value=head_dropout_value,\n",
    "                         num_classes=num_classes)\n",
    "\n",
    "    def forward(self, images, captions):\n",
    "        img_features = self.cnn(images)  # Image feature extraction\n",
    "        text_features = self.text_module(captions)  # Text feature extraction\n",
    "        return self.head(img_features, text_features)  # Classification"
   ],
   "id": "7c2f52a2b797846b",
   "outputs": [],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.590194Z",
     "start_time": "2025-01-09T20:29:45.586664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv1d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Embedding):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.TransformerEncoderLayer):\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"weight\" in name:\n",
    "                if param.dim() > 1:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                else:\n",
    "                    nn.init.ones_(param)\n",
    "            elif \"bias\" in name:\n",
    "                nn.init.zeros_(param)"
   ],
   "id": "340278a77ea962ef",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:29:45.721643Z",
     "start_time": "2025-01-09T20:29:45.603332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test model code\n",
    "#  , num_heads, transformer_hidden_dim, num_transformer_layers\n",
    "model = ImageTextClassifier(\n",
    "    cnn_dropout_value=0.25,\n",
    "    head_dropout_value=0.25,\n",
    "    text_features_size=max_len\n",
    ")\n",
    "\n",
    "# Apply weight initialization recursively\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "# Dummy input data\n",
    "images = torch.randn(16, 3, 100, 100)  # Batch of 16 RGB images of size 224x224\n",
    "captions = torch.randn(16, max_len)  # Batch of 16 captions with max_len tokens each\n",
    "\n",
    "output = model(images, captions)\n",
    "print(output.shape)  # Should be (16) "
   ],
   "id": "61d242071b2bf57d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    }
   ],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:38:09.636572Z",
     "start_time": "2025-01-09T20:38:09.569918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model_config = {\n",
    "    \"cnn_dropout_value\": 0.2,\n",
    "    \"head_dropout_value\": 0.4,\n",
    "    \"text_features_size\": max_len,\n",
    "}\n",
    "model = ImageTextClassifier(**model_config)\n",
    "model.to(device)\n",
    "model.apply(initialize_weights)"
   ],
   "id": "b8e49cebdfb0724c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageTextClassifier(\n",
       "  (cnn): CNN(\n",
       "    (CNN_block): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): Dropout(p=0.2, inplace=False)\n",
       "      (10): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (12): Conv2d(32, 32, kernel_size=(7, 7), stride=(3, 3), padding=(1, 1))\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (15): Dropout(p=0.2, inplace=False)\n",
       "      (16): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (17): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (text_module): TextModule(\n",
       "    (tfidf_feature_extract): Sequential(\n",
       "      (0): Linear(in_features=15447, out_features=1028, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=1028, out_features=256, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (CNN1d): Sequential(\n",
       "      (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): SEBlock1D(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv1d(16, 32, kernel_size=(5,), stride=(2,), padding=(1,))\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): Dropout(p=0.2, inplace=False)\n",
       "      (10): SEBlock1D(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (12): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(1,))\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (15): Dropout(p=0.2, inplace=False)\n",
       "      (16): SEBlock1D(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.01)\n",
       "          (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (17): AdaptiveAvgPool1d(output_size=1)\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (head): Head(\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.4, inplace=False)\n",
       "      (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 236
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:38:09.773902Z",
     "start_time": "2025-01-09T20:38:09.770853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.BCEWithLogitsLoss()  # Use logits directly\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "# T_0 -> Number of iterations until the first restart\n",
    "# T_mult -> Double the cycle le ngth after every restart\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,  # Number of epochs before the first restart\n",
    "    T_mult=1,  # Multiplicative factor for increasing restart period\n",
    "    eta_min=5e-6  # Minimum learning rate\n",
    ")\n",
    "# lambda1 = lambda epoch: 0.95 ** epoch\n",
    "# scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)"
   ],
   "id": "2fd4fe8235fc725d",
   "outputs": [],
   "execution_count": 237
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:38:10.350157Z",
     "start_time": "2025-01-09T20:38:10.339486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def training_method(model, criterion, optimizer, scheduler, num_epochs, train_loader, val_loader, patience=4, delta=0.05, loss_procentage_improvement=10):\n",
    "    train_losses = []  # List to store training losses\n",
    "    val_losses = []  # List to store validation losses\n",
    "    val_accuracies = []  # List to store validation accuracies\n",
    "    val_precisions = []  # List to store validation precisions\n",
    "    val_recalls = []  # List to store validation recalls\n",
    "    val_f1s = []  # List to store validation F1-scores\n",
    "    learning_rates = []  # List to store learning rate progression\n",
    "\n",
    "    best_val_loss = float('inf')  # Initialize the best validation loss\n",
    "    initial_loss = float('inf')\n",
    "    best_model = None  # Store the best model\n",
    "    epochs_without_improvement = 0  # Track epochs without improvement\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        ### TRAINING\n",
    "        model.train()\n",
    "        training_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            images = batch['images'].to(device)  # Images from batch\n",
    "            captions = batch['captions'].to(device)  # Captions from batch\n",
    "            labels = batch['labels'].to(device).float()  # Binary labels (0/1), converted to float\n",
    "\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            output = model(images, captions)  # Forward pass (logits)\n",
    "            loss = criterion(output, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "\n",
    "            optimizer.step()  # Update weights\n",
    "            training_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        train_loss = training_loss / len(train_loader)  # Average training loss\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        ### VALIDATING\n",
    "        model.eval()\n",
    "        validation_loss = 0.0\n",
    "        all_labels = []  # Ground truth labels for validation\n",
    "        all_preds = []  # Predictions for validation\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['images'].to(device)\n",
    "                captions = batch['captions'].to(device)\n",
    "                labels = batch['labels'].to(device).float()\n",
    "\n",
    "                output = model(images, captions)  # Forward pass (logits)\n",
    "                loss = criterion(output, labels)  # Compute validation loss\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                # Convert logits to probabilities and apply threshold\n",
    "                preds = (torch.sigmoid(output) > 0.5).float()\n",
    "\n",
    "                # Store for statistics\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        val_loss = validation_loss / len(val_loader)  # Average validation loss\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Compute validation statistics\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "        val_recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "        val_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_precisions.append(val_precision)\n",
    "        val_recalls.append(val_recall)\n",
    "        val_f1s.append(val_f1)\n",
    "\n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']  # Get the current learning rate\n",
    "        learning_rates.append(current_lr)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs} - \"\n",
    "              f\"Training Loss: {train_loss:.4f} - \"\n",
    "              f\"Validation Loss: {val_loss:.4f} - \"\n",
    "              f\"Accuracy: {val_accuracy:.4f} - \"\n",
    "              f\"Precision: {val_precision:.4f} - \"\n",
    "              f\"Recall: {val_recall:.4f} - \"\n",
    "              f\"F1 Score: {val_f1:.4f} - \"\n",
    "              f\"Time: {end_time - start_time:.2f} - \"\n",
    "              f\"Lr: {current_lr:.2e}\")\n",
    "\n",
    "        if epoch == 1:\n",
    "            initial_loss = val_loss\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)  # Save the best model\n",
    "            epochs_without_improvement = 0  # Reset counter\n",
    "            print(f\"New best model with Loss: {val_loss:.4f} at epoch {epoch + 1}\")\n",
    "        elif val_loss < best_val_loss + delta:\n",
    "            print(f\"Validation loss did not improve significantly\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"Validation loss did not improve for {epochs_without_improvement} epoch(s).\")\n",
    "            # Stop training if validation loss does not improve for 'patience' epochs\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}. Best Loss: {best_val_loss:.4f}\")\n",
    "                break  # Exit training loop\n",
    "\n",
    "    print('Training finished!')\n",
    "\n",
    "    # save the model only if the best loss is lower than the first initial loss ( to see that the model actually improved with 10% loss )\n",
    "    if best_val_loss < (100 - loss_procentage_improvement) * initial_loss:\n",
    "        # Init plot&model save path\n",
    "        plt_save_path = \"models/\"\n",
    "        model_config['eval_loss'] = best_val_loss\n",
    "        for key, value in model_config.items():\n",
    "            plt_save_path += key + \"=\" + str(value) + \"+\"\n",
    "        plt_save_path = plt_save_path[:-1] + \".png\"\n",
    "        model_path = plt_save_path[:-4] + \".pt\"\n",
    "        torch.save(best_model.state_dict(), model_path)\n",
    "        print(f\"Best model with Loss: {best_val_loss:.4f} saved.\")\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "\n",
    "        # Plotting the losses and validation metrics over epochs\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.plot(val_accuracies, label='Accuracy')\n",
    "        plt.plot(val_precisions, label='Precision')\n",
    "        plt.plot(val_recalls, label='Recall')\n",
    "        plt.plot(val_f1s, label='F1 Score')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Metric')\n",
    "        plt.title('Validation Metrics')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(3, 1, 3)\n",
    "        plt.plot(learning_rates, label='Learning Rate')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Learning Rate\")\n",
    "        plt.title(\"Learning Rate Progression\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plt_save_path)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"Model wasn't saved because it didn't improve: {loss_procentage_improvement}%\")"
   ],
   "id": "6280acf86aa228a2",
   "outputs": [],
   "execution_count": 238
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-09T20:38:10.801825Z"
    }
   },
   "cell_type": "code",
   "source": "training_method(model, criterion, optimizer, scheduler, num_epochs=100, train_loader=train_dataloader, val_loader=val_dataloader)",
   "id": "ee2f8b5c78457e56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:37:55.991015Z",
     "start_time": "2025-01-09T20:37:55.986975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ids = []\n",
    "predictions = []\n",
    "\n",
    "\n",
    "def make_submission(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            images = batch['images'].to(device)\n",
    "            captions = batch['captions'].to(device)\n",
    "            id = batch['id']\n",
    "\n",
    "            output = model(images, captions)\n",
    "            preds = (torch.sigmoid(output) > 0.5).int()\n",
    "\n",
    "            ids.extend(id)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "    df = pd.DataFrame({'id': ids, 'label': predictions})\n",
    "    df.to_csv('submission3.csv', index=False)"
   ],
   "id": "95402ff5c7357c82",
   "outputs": [],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:37:55.994045Z",
     "start_time": "2025-01-09T20:37:55.991015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # LOAD MODEL FROM PATH\n",
    "# model_config = {\n",
    "#     \"vocab_size\": len(vocab),\n",
    "#     \"embedding_dim\": 128,\n",
    "#     \"num_filters\": 128,\n",
    "#     \"filter_sizes\": [3, 4, 5, 6, 7, 8],\n",
    "#     \"seq_len\": max_len,\n",
    "#     \"cnn_text_drop_value\": 0.5,\n",
    "#     \"cnn_dropout_value\": 0.4,\n",
    "#     \"head_dropout_value\": 0.5,\n",
    "#     \"num_classes\": 1,\n",
    "# }\n",
    "# model = ImageTextClassifier(**model_config)\n",
    "# model_path = \"vocab_size=3733+embedding_dim=128+num_filters=128+filter_sizes=[3, 4, 5, 6, 7, 8]+seq_len=53+cnn_text_drop_value=0.5+cnn_dropout_value=0.4+head_dropout_value=0.5+num_classes=1+eval_loss=0.6202353974606128.pt\"\n",
    "# model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "# model.to(device)"
   ],
   "id": "595baf65e18e78cd",
   "outputs": [],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:38:00.431008Z",
     "start_time": "2025-01-09T20:37:55.994552Z"
    }
   },
   "cell_type": "code",
   "source": "make_submission(model, test_dataloader)",
   "id": "6cc9a81e05125a1d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:04<00:00, 28.21it/s]\n"
     ]
    }
   ],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:38:00.436101Z",
     "start_time": "2025-01-09T20:38:00.431515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def hyperparameter_tuning(vocab_size, max_len, train_loader, val_loader, param_grid, training_method, num_epochs=200):\n",
    "    # Create all combinations of hyperparameters\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "    for params in tqdm(param_combinations):\n",
    "        print(f\"Testing configuration: {params}\")\n",
    "\n",
    "        try:\n",
    "            # Update model configuration\n",
    "            model_config = {\n",
    "                \"vocab_size\": vocab_size,\n",
    "                \"embedding_dim\": params[\"embedding_dim\"],\n",
    "                \"num_filters\": params[\"num_filters\"],\n",
    "                \"filter_sizes\": params[\"filter_sizes\"],\n",
    "                \"seq_len\": max_len,\n",
    "                \"cnn_text_drop_value\": params[\"cnn_text_drop_value\"],\n",
    "                \"cnn_dropout_value\": params[\"cnn_dropout_value\"],\n",
    "                \"head_dropout_value\": params[\"head_dropout_value\"],\n",
    "            }\n",
    "\n",
    "            # Initialize model\n",
    "            model = ImageTextClassifier(**model_config)\n",
    "            model.to(device)\n",
    "            model.apply(initialize_weights)\n",
    "\n",
    "            # Define criterion, optimizer, and scheduler\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            optimizer = optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=params[\"lr\"],\n",
    "                weight_decay=params[\"weight_decay\"]\n",
    "            )\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                optimizer,\n",
    "                T_0=params[\"T_0\"],\n",
    "                eta_min=params[\"eta_min\"],\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            training_method(\n",
    "                model, criterion, optimizer, scheduler,\n",
    "                num_epochs=num_epochs,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader\n",
    "            )\n",
    "            print(f\"Completed configuration: {params}\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error with configuration: {params}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "\n",
    "        finally:\n",
    "            # Reset GPU memory\n",
    "            print(\"Resetting GPU memory...\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()"
   ],
   "id": "cf6ef0fe03c73deb",
   "outputs": [],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:38:00.441173Z",
     "start_time": "2025-01-09T20:38:00.437619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    \"embedding_dim\": [128],\n",
    "    \"num_filters\": [16],\n",
    "    \"filter_sizes\": [[3, 4, 5], [3, 4, 5, 6, 7, 8, 9]],\n",
    "    \"head_dropout_value\": [0.5],\n",
    "    \"cnn_text_drop_value\": [0.5],\n",
    "    \"cnn_dropout_value\": [0.5],\n",
    "    \"lr\": [1e-5, 1e-4, 5e-4, 1e-3, 5e-3],  # Learning rate candidates\n",
    "    \"weight_decay\": [1e-6, 1e-5, 1e-4, 1e-3],  # Weight decay candidates\n",
    "    \"T_0\": [10],  # Number of epochs for the first cycle\n",
    "    \"T_mult\": [1],  # Cycle multiplier\n",
    "    \"eta_min\": [1e-6, 1e-5, 1e-4],  # Minimum learning rate\n",
    "}\n",
    "\n",
    "total_combinations = math.prod(len(values) for values in param_grid.values())\n",
    "print(f\"Total combinations: {total_combinations}\")\n",
    "\n",
    "time_per_epoch = 23  # seconds\n",
    "num_epochs = 100  # epochs per configuration\n",
    "total_time_seconds = total_combinations * time_per_epoch * num_epochs\n",
    "\n",
    "# Convert to hours\n",
    "total_time_hours = total_time_seconds / 3600\n",
    "print(f\"Total time to hyper tune: {total_time_hours} hours\")"
   ],
   "id": "b9f5a5e907d2c63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations: 120\n",
      "Total time to hyper tune: 76.66666666666667 hours\n"
     ]
    }
   ],
   "execution_count": 234
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:38:00.454825Z",
     "start_time": "2025-01-09T20:38:00.441682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = hyperparameter_tuning(\n",
    "    vocab_size=len(vocab),\n",
    "    max_len=max_len,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    param_grid=param_grid,\n",
    "    training_method=training_method,\n",
    "    num_epochs=100\n",
    ")"
   ],
   "id": "2b980f756d58665b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[235], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m results \u001B[38;5;241m=\u001B[39m hyperparameter_tuning(\n\u001B[1;32m----> 2\u001B[0m     vocab_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(vocab),\n\u001B[0;32m      3\u001B[0m     max_len\u001B[38;5;241m=\u001B[39mmax_len,\n\u001B[0;32m      4\u001B[0m     train_loader\u001B[38;5;241m=\u001B[39mtrain_dataloader,\n\u001B[0;32m      5\u001B[0m     val_loader\u001B[38;5;241m=\u001B[39mval_dataloader,\n\u001B[0;32m      6\u001B[0m     param_grid\u001B[38;5;241m=\u001B[39mparam_grid,\n\u001B[0;32m      7\u001B[0m     training_method\u001B[38;5;241m=\u001B[39mtraining_method,\n\u001B[0;32m      8\u001B[0m     num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m\n\u001B[0;32m      9\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "execution_count": 235
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dir_models = os.listdir(\"./models\")",
   "id": "b13f77f45721bd1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_models = [path[:-3] for path in dir_models if path.endswith(\".pt\")]",
   "id": "d4641d6ec9100cd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_val_loss = [float(str(best_model.split(\"+\")[-1:]).split(\"=\")[1][:8]) for best_model in best_models]",
   "id": "b66b0b18ddd45eaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_val_loss.sort()\n",
    "best_val_loss[:100]"
   ],
   "id": "f8072a414588fe28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "db3c79d743aaea6a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
