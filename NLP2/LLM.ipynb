{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-28T13:13:32.920052Z",
     "start_time": "2025-01-28T13:13:32.333912Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"melzohbi/metaphor-detection-vua-wsd-augmented\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n",
      "Path to dataset files: C:\\Users\\allex\\.cache\\kagglehub\\datasets\\melzohbi\\metaphor-detection-vua-wsd-augmented\\versions\\1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T13:13:33.811789Z",
     "start_time": "2025-01-28T13:13:32.920052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(path, \"data/VUA20/train.tsv\"), sep='\\t')\n",
    "test_df = pd.read_csv(os.path.join(path, \"data/VUA20/test.tsv\"), sep='\\t')"
   ],
   "id": "9b476223ceb3b57b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get only 617 elements because testing would take too long with the whole dataset",
   "id": "e41b9a691407f6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T13:13:33.842863Z",
     "start_time": "2025-01-28T13:13:33.812296Z"
    }
   },
   "cell_type": "code",
   "source": "tmp_train_df = train_df[train_df['index'].str.contains(\"a1e-fragment01\")]",
   "id": "9511859875a322f9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T13:13:33.855036Z",
     "start_time": "2025-01-28T13:13:33.843374Z"
    }
   },
   "cell_type": "code",
   "source": "tmp_train_df",
   "id": "86fd0218c44a493b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 index  label  \\\n",
       "0     a1e-fragment01 1      0   \n",
       "1     a1e-fragment01 1      0   \n",
       "2     a1e-fragment01 1      0   \n",
       "3     a1e-fragment01 1      1   \n",
       "4     a1e-fragment01 1      0   \n",
       "..                 ...    ...   \n",
       "612  a1e-fragment01 30      0   \n",
       "613  a1e-fragment01 30      0   \n",
       "614  a1e-fragment01 30      0   \n",
       "615  a1e-fragment01 30      0   \n",
       "616  a1e-fragment01 30      0   \n",
       "\n",
       "                                              sentence    POS FGPOS  w_index  \\\n",
       "0    Latest corporate unbundler reveals laid-back a...    ADJ   JJS        0   \n",
       "1    Latest corporate unbundler reveals laid-back a...    ADJ    JJ        1   \n",
       "2    Latest corporate unbundler reveals laid-back a...  PROPN   NNP        2   \n",
       "3    Latest corporate unbundler reveals laid-back a...   VERB   VBZ        3   \n",
       "4    Latest corporate unbundler reveals laid-back a...   VERB   VBN        4   \n",
       "..                                                 ...    ...   ...      ...   \n",
       "612  It would be a criticism if I was doing it to i...   PRON   PRP        9   \n",
       "613  It would be a criticism if I was doing it to i...    ADP    IN       10   \n",
       "614  It would be a criticism if I was doing it to i...   VERB    VB       11   \n",
       "615  It would be a criticism if I was doing it to i...   PRON   PRP       12   \n",
       "616  It would be a criticism if I was doing it to i...  PUNCT    ''       13   \n",
       "\n",
       "         target                                         word_sense  \\\n",
       "0        Latest  up to the immediate present; most recent or mo...   \n",
       "1     corporate                   of or belonging to a corporation   \n",
       "2     unbundler                                          unbundler   \n",
       "3       reveals                                       make visible   \n",
       "4     laid-back                                          laid-back   \n",
       "..          ...                                                ...   \n",
       "612          it                                                 it   \n",
       "613          to                                                 to   \n",
       "614  impoverish                                          make poor   \n",
       "615      myself                                             myself   \n",
       "616           ’                                                  ’   \n",
       "\n",
       "                                            definition  \n",
       "0                    Near the end of a period of time.  \n",
       "1                     Of or relating to a corporation.  \n",
       "2                                            unbundler  \n",
       "3    To uncover; to show and display that which was...  \n",
       "4                                            laid-back  \n",
       "..                                                 ...  \n",
       "612                                                 it  \n",
       "613                                                 to  \n",
       "614                                      To make poor.  \n",
       "615                                             myself  \n",
       "616                                                  ’  \n",
       "\n",
       "[617 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>FGPOS</th>\n",
       "      <th>w_index</th>\n",
       "      <th>target</th>\n",
       "      <th>word_sense</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1e-fragment01 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Latest corporate unbundler reveals laid-back a...</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJS</td>\n",
       "      <td>0</td>\n",
       "      <td>Latest</td>\n",
       "      <td>up to the immediate present; most recent or mo...</td>\n",
       "      <td>Near the end of a period of time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1e-fragment01 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Latest corporate unbundler reveals laid-back a...</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1</td>\n",
       "      <td>corporate</td>\n",
       "      <td>of or belonging to a corporation</td>\n",
       "      <td>Of or relating to a corporation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1e-fragment01 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Latest corporate unbundler reveals laid-back a...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>2</td>\n",
       "      <td>unbundler</td>\n",
       "      <td>unbundler</td>\n",
       "      <td>unbundler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1e-fragment01 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Latest corporate unbundler reveals laid-back a...</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>3</td>\n",
       "      <td>reveals</td>\n",
       "      <td>make visible</td>\n",
       "      <td>To uncover; to show and display that which was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1e-fragment01 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Latest corporate unbundler reveals laid-back a...</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>4</td>\n",
       "      <td>laid-back</td>\n",
       "      <td>laid-back</td>\n",
       "      <td>laid-back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>a1e-fragment01 30</td>\n",
       "      <td>0</td>\n",
       "      <td>It would be a criticism if I was doing it to i...</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>9</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>a1e-fragment01 30</td>\n",
       "      <td>0</td>\n",
       "      <td>It would be a criticism if I was doing it to i...</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>10</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>a1e-fragment01 30</td>\n",
       "      <td>0</td>\n",
       "      <td>It would be a criticism if I was doing it to i...</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>11</td>\n",
       "      <td>impoverish</td>\n",
       "      <td>make poor</td>\n",
       "      <td>To make poor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>a1e-fragment01 30</td>\n",
       "      <td>0</td>\n",
       "      <td>It would be a criticism if I was doing it to i...</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>12</td>\n",
       "      <td>myself</td>\n",
       "      <td>myself</td>\n",
       "      <td>myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>a1e-fragment01 30</td>\n",
       "      <td>0</td>\n",
       "      <td>It would be a criticism if I was doing it to i...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>''</td>\n",
       "      <td>13</td>\n",
       "      <td>’</td>\n",
       "      <td>’</td>\n",
       "      <td>’</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# import the model using Ollama - I am using deepseek-r1 with 14B (using all VRAM resources)",
   "id": "1b7210a9f8d7cf03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T13:13:34.519389Z",
     "start_time": "2025-01-28T13:13:33.856053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "ollama = Ollama(\n",
    "    base_url='http://localhost:11434',\n",
    "    # model=\"llama3.2:1b\"\n",
    "    model=\"llama3.2:3b\"\n",
    "    # model=\"deepseek-r1:14b\"    \n",
    ") "
   ],
   "id": "657e6d64b3f68a4f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allex\\AppData\\Local\\Temp\\ipykernel_21856\\698949853.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  ollama = Ollama(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T13:13:39.944568Z",
     "start_time": "2025-01-28T13:13:34.519896Z"
    }
   },
   "cell_type": "code",
   "source": "print(ollama.invoke(\"why is the sky blue\")) # TEST",
   "id": "3d2eebb35961e5b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create prompt for each row from dataset",
   "id": "a2cee03852a9b7c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_prompt(row):\n",
    "    return (\n",
    "        f\"Sentence: {row['sentence']}\\n\"\n",
    "        f\"Target Word: {row['target']} (POS: {row['POS']}, Word Index: {row['w_index']}, Word Sense: {row['word_sense']}, definition: {row['definition']})\\n\"\n",
    "        \"Is the target word used metaphorically? Provide a yes or no answer without explanation.\"\n",
    "    )\n",
    "\n",
    "tmp_train_df.loc[:, 'prompt'] = tmp_train_df.apply(create_prompt, axis=1)"
   ],
   "id": "dd7ce3cfe063e745",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get predictions",
   "id": "ebc193720d30450a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp_train_df['prediction'] = None",
   "id": "7cec507287219df0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "row = tmp_train_df.iloc[451]\n",
    "print(ollama.invoke(row['prompt']))"
   ],
   "id": "4e80b24b49d206f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp_train_df",
   "id": "de4de409d8c61da0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T14:49:16.353910Z",
     "start_time": "2025-01-27T14:38:09.897236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm_progress_bar = tqdm(tmp_train_df.index)\n",
    "for row_idx in tqdm_progress_bar:\n",
    "    try:\n",
    "        prompt = tmp_train_df.loc[row_idx, 'prompt']\n",
    "        response = ollama.invoke(prompt)\n",
    "        # print(response)\n",
    "        # prediction = response.split(\"</think>\")[1].strip() # Yes / No answer\n",
    "        prediction = response.strip()\n",
    "        tmp_train_df.loc[row_idx, 'prediction'] = prediction\n",
    "        tqdm_progress_bar.update(1)\n",
    "        tqdm_progress_bar.set_description(prediction)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break"
   ],
   "id": "96d30251655dbc7d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@:  50%|█████     | 311/617 [11:06<10:55,  2.14s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     72\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[1;32m---> 73\u001B[0m sock\u001B[38;5;241m.\u001B[39mconnect(sa)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[1;31mConnectionRefusedError\u001B[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[63], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      6\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m tmp_train_df\u001B[38;5;241m.\u001B[39mloc[row_idx, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 7\u001B[0m     response \u001B[38;5;241m=\u001B[39m ollama\u001B[38;5;241m.\u001B[39minvoke(prompt)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# print(response)\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# prediction = response.split(\"</think>\")[1].strip() # Yes / No answer\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mstrip()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:390\u001B[0m, in \u001B[0;36mBaseLLM.invoke\u001B[1;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    382\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    386\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    387\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m    388\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[0;32m    389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m--> 390\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_prompt(\n\u001B[0;32m    391\u001B[0m             [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_input(\u001B[38;5;28minput\u001B[39m)],\n\u001B[0;32m    392\u001B[0m             stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    393\u001B[0m             callbacks\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    394\u001B[0m             tags\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    395\u001B[0m             metadata\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    396\u001B[0m             run_name\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    397\u001B[0m             run_id\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    398\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    399\u001B[0m         )\n\u001B[0;32m    400\u001B[0m         \u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    401\u001B[0m         \u001B[38;5;241m.\u001B[39mtext\n\u001B[0;32m    402\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:759\u001B[0m, in \u001B[0;36mBaseLLM.generate_prompt\u001B[1;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    751\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[0;32m    752\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    753\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[PromptValue],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    756\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    757\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    758\u001B[0m     prompt_strings \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_string() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m--> 759\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(prompt_strings, stop\u001B[38;5;241m=\u001B[39mstop, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:962\u001B[0m, in \u001B[0;36mBaseLLM.generate\u001B[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    947\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m get_llm_cache() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m    948\u001B[0m     run_managers \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    949\u001B[0m         callback_manager\u001B[38;5;241m.\u001B[39mon_llm_start(\n\u001B[0;32m    950\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_serialized,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    960\u001B[0m         )\n\u001B[0;32m    961\u001B[0m     ]\n\u001B[1;32m--> 962\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_helper(\n\u001B[0;32m    963\u001B[0m         prompts, stop, run_managers, \u001B[38;5;28mbool\u001B[39m(new_arg_supported), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    964\u001B[0m     )\n\u001B[0;32m    965\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n\u001B[0;32m    966\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(missing_prompts) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:796\u001B[0m, in \u001B[0;36mBaseLLM._generate_helper\u001B[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[0m\n\u001B[0;32m    794\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n\u001B[0;32m    795\u001B[0m         run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e, response\u001B[38;5;241m=\u001B[39mLLMResult(generations\u001B[38;5;241m=\u001B[39m[]))\n\u001B[1;32m--> 796\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    797\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m    798\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m manager, flattened_output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(run_managers, flattened_outputs):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:783\u001B[0m, in \u001B[0;36mBaseLLM._generate_helper\u001B[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[0m\n\u001B[0;32m    773\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_generate_helper\u001B[39m(\n\u001B[0;32m    774\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    775\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    779\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    780\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    781\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    782\u001B[0m         output \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 783\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[0;32m    784\u001B[0m                 prompts,\n\u001B[0;32m    785\u001B[0m                 stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    786\u001B[0m                 \u001B[38;5;66;03m# TODO: support multiple run managers\u001B[39;00m\n\u001B[0;32m    787\u001B[0m                 run_manager\u001B[38;5;241m=\u001B[39mrun_managers[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m run_managers \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    788\u001B[0m                 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    789\u001B[0m             )\n\u001B[0;32m    790\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    791\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(prompts, stop\u001B[38;5;241m=\u001B[39mstop)\n\u001B[0;32m    792\u001B[0m         )\n\u001B[0;32m    793\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    794\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:437\u001B[0m, in \u001B[0;36mOllama._generate\u001B[1;34m(self, prompts, stop, images, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    435\u001B[0m generations \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    436\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m prompt \u001B[38;5;129;01min\u001B[39;00m prompts:\n\u001B[1;32m--> 437\u001B[0m     final_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m_stream_with_aggregation(\n\u001B[0;32m    438\u001B[0m         prompt,\n\u001B[0;32m    439\u001B[0m         stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    440\u001B[0m         images\u001B[38;5;241m=\u001B[39mimages,\n\u001B[0;32m    441\u001B[0m         run_manager\u001B[38;5;241m=\u001B[39mrun_manager,\n\u001B[0;32m    442\u001B[0m         verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[0;32m    443\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    444\u001B[0m     )\n\u001B[0;32m    445\u001B[0m     generations\u001B[38;5;241m.\u001B[39mappend([final_chunk])\n\u001B[0;32m    446\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m LLMResult(generations\u001B[38;5;241m=\u001B[39mgenerations)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:349\u001B[0m, in \u001B[0;36m_OllamaCommon._stream_with_aggregation\u001B[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_stream_with_aggregation\u001B[39m(\n\u001B[0;32m    341\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    342\u001B[0m     prompt: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    346\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    347\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m GenerationChunk:\n\u001B[0;32m    348\u001B[0m     final_chunk: Optional[GenerationChunk] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 349\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m stream_resp \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_generate_stream(prompt, stop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    350\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m stream_resp:\n\u001B[0;32m    351\u001B[0m             chunk \u001B[38;5;241m=\u001B[39m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:194\u001B[0m, in \u001B[0;36m_OllamaCommon._create_generate_stream\u001B[1;34m(self, prompt, stop, images, **kwargs)\u001B[0m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_create_generate_stream\u001B[39m(\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    188\u001B[0m     prompt: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    191\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    192\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m    193\u001B[0m     payload \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m: prompt, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m: images}\n\u001B[1;32m--> 194\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_stream(\n\u001B[0;32m    195\u001B[0m         payload\u001B[38;5;241m=\u001B[39mpayload,\n\u001B[0;32m    196\u001B[0m         stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    197\u001B[0m         api_url\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/api/generate\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    198\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    199\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:252\u001B[0m, in \u001B[0;36m_OllamaCommon._create_stream\u001B[1;34m(self, api_url, payload, stop, **kwargs)\u001B[0m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    247\u001B[0m     request_payload \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    248\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m: payload\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    249\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m: payload\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m, []),\n\u001B[0;32m    250\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    251\u001B[0m     }\n\u001B[1;32m--> 252\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(\n\u001B[0;32m    253\u001B[0m     url\u001B[38;5;241m=\u001B[39mapi_url,\n\u001B[0;32m    254\u001B[0m     headers\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m    255\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapplication/json\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    256\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheaders \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheaders, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m {}),\n\u001B[0;32m    257\u001B[0m     },\n\u001B[0;32m    258\u001B[0m     auth\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauth,\n\u001B[0;32m    259\u001B[0m     json\u001B[38;5;241m=\u001B[39mrequest_payload,\n\u001B[0;32m    260\u001B[0m     stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    261\u001B[0m     timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout,\n\u001B[0;32m    262\u001B[0m )\n\u001B[0;32m    263\u001B[0m response\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\requests\\api.py:115\u001B[0m, in \u001B[0;36mpost\u001B[1;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[0;32m    105\u001B[0m \n\u001B[0;32m    106\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m request(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, data\u001B[38;5;241m=\u001B[39mdata, json\u001B[38;5;241m=\u001B[39mjson, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m session\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(\n\u001B[0;32m    668\u001B[0m         method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    669\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m    670\u001B[0m         body\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mbody,\n\u001B[0;32m    671\u001B[0m         headers\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m    672\u001B[0m         redirect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    673\u001B[0m         assert_same_host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    674\u001B[0m         preload_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    675\u001B[0m         decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    676\u001B[0m         retries\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries,\n\u001B[0;32m    677\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    678\u001B[0m         chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    679\u001B[0m     )\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    786\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    788\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[0;32m    790\u001B[0m     conn,\n\u001B[0;32m    791\u001B[0m     method,\n\u001B[0;32m    792\u001B[0m     url,\n\u001B[0;32m    793\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[0;32m    794\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[0;32m    795\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m    796\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    797\u001B[0m     retries\u001B[38;5;241m=\u001B[39mretries,\n\u001B[0;32m    798\u001B[0m     response_conn\u001B[38;5;241m=\u001B[39mresponse_conn,\n\u001B[0;32m    799\u001B[0m     preload_content\u001B[38;5;241m=\u001B[39mpreload_content,\n\u001B[0;32m    800\u001B[0m     decode_content\u001B[38;5;241m=\u001B[39mdecode_content,\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse_kw,\n\u001B[0;32m    802\u001B[0m )\n\u001B[0;32m    804\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[0;32m    805\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\urllib3\\connectionpool.py:495\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001B[39;00m\n\u001B[0;32m    493\u001B[0m \u001B[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001B[39;00m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 495\u001B[0m     conn\u001B[38;5;241m.\u001B[39mrequest(\n\u001B[0;32m    496\u001B[0m         method,\n\u001B[0;32m    497\u001B[0m         url,\n\u001B[0;32m    498\u001B[0m         body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[0;32m    499\u001B[0m         headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m    500\u001B[0m         chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    501\u001B[0m         preload_content\u001B[38;5;241m=\u001B[39mpreload_content,\n\u001B[0;32m    502\u001B[0m         decode_content\u001B[38;5;241m=\u001B[39mdecode_content,\n\u001B[0;32m    503\u001B[0m         enforce_content_length\u001B[38;5;241m=\u001B[39menforce_content_length,\n\u001B[0;32m    504\u001B[0m     )\n\u001B[0;32m    506\u001B[0m \u001B[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001B[39;00m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001B[39;00m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;66;03m# With this behaviour, the received response is still readable.\u001B[39;00m\n\u001B[0;32m    509\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBrokenPipeError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\urllib3\\connection.py:441\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    439\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m header, value \u001B[38;5;129;01min\u001B[39;00m headers\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    440\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mputheader(header, value)\n\u001B[1;32m--> 441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendheaders()\n\u001B[0;32m    443\u001B[0m \u001B[38;5;66;03m# If we're given a body we start sending that in chunks.\u001B[39;00m\n\u001B[0;32m    444\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunks \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\http\\client.py:1331\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[1;32m-> 1331\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_output(message_body, encode_chunked\u001B[38;5;241m=\u001B[39mencode_chunked)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\http\\client.py:1091\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1089\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer)\n\u001B[0;32m   1090\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[1;32m-> 1091\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(msg)\n\u001B[0;32m   1093\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1094\u001B[0m \n\u001B[0;32m   1095\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n\u001B[0;32m   1096\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(message_body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m   1097\u001B[0m         \u001B[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001B[39;00m\n\u001B[0;32m   1098\u001B[0m         \u001B[38;5;66;03m# is needed to allow the current position of mmap'ed\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m         \u001B[38;5;66;03m# files to be taken into account.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\http\\client.py:1035\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[1;32m-> 1035\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnect()\n\u001B[0;32m   1036\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1037\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m NotConnected()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\urllib3\\connection.py:279\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconnect\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 279\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new_conn()\n\u001B[0;32m    280\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tunnel_host:\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001B[39;00m\n\u001B[0;32m    282\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_connected_to_proxy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\urllib3\\connection.py:199\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \n\u001B[0;32m    196\u001B[0m \u001B[38;5;124;03m:return: New socket connection.\u001B[39;00m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 199\u001B[0m     sock \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[0;32m    200\u001B[0m         (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dns_host, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport),\n\u001B[0;32m    201\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout,\n\u001B[0;32m    202\u001B[0m         source_address\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_address,\n\u001B[0;32m    203\u001B[0m         socket_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket_options,\n\u001B[0;32m    204\u001B[0m     )\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mgaierror \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NameResolutionError(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m, e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\site-packages\\urllib3\\util\\connection.py:81\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     79\u001B[0m         err \u001B[38;5;241m=\u001B[39m _\n\u001B[0;32m     80\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m sock \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 81\u001B[0m             sock\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\AI\\Lib\\socket.py:501\u001B[0m, in \u001B[0;36msocket.close\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_real_close\u001B[39m(\u001B[38;5;28mself\u001B[39m, _ss\u001B[38;5;241m=\u001B[39m_socket\u001B[38;5;241m.\u001B[39msocket):\n\u001B[0;32m    498\u001B[0m     \u001B[38;5;66;03m# This function should not reference any globals. See issue #808164.\u001B[39;00m\n\u001B[0;32m    499\u001B[0m     _ss\u001B[38;5;241m.\u001B[39mclose(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 501\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclose\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    502\u001B[0m     \u001B[38;5;66;03m# This function should not reference any globals. See issue #808164.\u001B[39;00m\n\u001B[0;32m    503\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    504\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_io_refs \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# some predictions are @@@@@@@@@@@@@@@@@@@@@@@@@ Can't understand why, so we rerun those",
   "id": "34c502056a6f7fa6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert Yes/No to labels",
   "id": "c072e6b240ff4252"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp_train_df['predictionIdx'] = None",
   "id": "6a395ed9a44f1f3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for row_idx in tmp_train_df.index:\n",
    "    prediction = tmp_train_df.loc[row_idx, 'prediction']\n",
    "    \n",
    "    if prediction is None:\n",
    "        continue\n",
    "    # convert to 1 or 0\n",
    "    if \"yes\" in prediction.lower():\n",
    "        predictionIdx = 1\n",
    "    if \"no\" in prediction.lower():\n",
    "        predictionIdx = 0\n",
    "    tmp_train_df.loc[row_idx, 'predictionIdx'] = predictionIdx"
   ],
   "id": "1e49b1cd1501b166",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tmp_train_df",
   "id": "9acb10b795cb743",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate counts for each class\n",
    "label_counts = tmp_train_df['label'].value_counts()\n",
    "prediction_counts = tmp_train_df['predictionIdx'].value_counts()\n",
    "\n",
    "# Confusion matrix components\n",
    "TP = ((tmp_train_df['label'] == 1) & (tmp_train_df['predictionIdx'] == 1)).sum()\n",
    "TN = ((tmp_train_df['label'] == 0) & (tmp_train_df['predictionIdx'] == 0)).sum()\n",
    "FP = ((tmp_train_df['label'] == 0) & (tmp_train_df['predictionIdx'] == 1)).sum()\n",
    "FN = ((tmp_train_df['label'] == 1) & (tmp_train_df['predictionIdx'] == 0)).sum()\n",
    "\n",
    "# Accuracy\n",
    "accuracy = (TP + TN) / len(tmp_train_df)\n",
    "\n",
    "# Precision, Recall, F1-Score\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    \"Label Counts\": label_counts.to_dict(),\n",
    "    \"Prediction Counts\": prediction_counts.to_dict(),\n",
    "    \"True Positives\": TP,\n",
    "    \"True Negatives\": TN,\n",
    "    \"False Positives\": FP,\n",
    "    \"False Negatives\": FN,\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1-Score\": f1_score\n",
    "}\n",
    "\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ],
   "id": "6ddf473e46693aee",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
