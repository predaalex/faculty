{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.base_dir = '../resources'\n",
    "        self.dir_pos_examples = os.path.join(self.base_dir, 'antrenare/andy')\n",
    "        self.dir_neg_examples = os.path.join(self.base_dir, 'antrenare/andy')\n",
    "        self.dir_test_examples = os.path.join(self.base_dir,\n",
    "                                              'validare/Validare')  # 'exempleTest/CursVA'   'exempleTest/CMU+MIT'\n",
    "        self.path_annotations = os.path.join(self.base_dir, 'validare/task1_gt_validare.txt')\n",
    "        self.dir_save_files = os.path.join(self.base_dir, 'salveazaFisiere')\n",
    "        if not os.path.exists(self.dir_save_files):\n",
    "            os.makedirs(self.dir_save_files)\n",
    "            print('directory created: {} '.format(self.dir_save_files))\n",
    "        else:\n",
    "            print('directory {} exists '.format(self.dir_save_files))\n",
    "\n",
    "        # set the parameters\n",
    "        # self.dim_window = 120\n",
    "        self.dim_window_x = 120\n",
    "        self.dim_window_y = 105\n",
    "        self.dim_hog_cell = 8  # dimensiunea celulei\n",
    "        self.crop_distance = 60\n",
    "        self.threshold = 4  # toate ferestrele cu scorul > threshold si maxime locale devin detectii\n",
    "        self.dim_descriptor_cell = 36  # dimensiunea descriptorului unei celule\n",
    "        self.overlap = 0.3\n",
    "        self.number_positive_examples = 0  # numarul exemplelor pozitive\n",
    "        self.number_negative_examples = 0  # numarul exemplelor negative\n",
    "        self.overlap = 0.3\n",
    "        self.has_annotations = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functii luate de la laborator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def intersection_over_union(bbox_a, bbox_b):\n",
    "    x_a = max(bbox_a[0], bbox_b[0])\n",
    "    y_a = max(bbox_a[1], bbox_b[1])\n",
    "    x_b = min(bbox_a[2], bbox_b[2])\n",
    "    y_b = min(bbox_a[3], bbox_b[3])\n",
    "\n",
    "    inter_area = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
    "\n",
    "    box_a_area = (bbox_a[2] - bbox_a[0] + 1) * (bbox_a[3] - bbox_a[1] + 1)\n",
    "    box_b_area = (bbox_b[2] - bbox_b[0] + 1) * (bbox_b[3] - bbox_b[1] + 1)\n",
    "\n",
    "    iou = inter_area / float(box_a_area + box_b_area - inter_area)\n",
    "\n",
    "    return iou"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Redimensionez fetele din imaginile de antrenare la aceeasi dimensiune si le transform in tonuri gri pentru a putea antrena clasificatorul liniar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# ### Am cautat o medie de w si h in setul de date al lui louie pentru a sti la ce masura sa redimensionez fete fara sa pierd foarte mult continut si o sa iau dimensiunea unui patrat scalat la ratia 4:3\n",
    "#\n",
    "# path = \"resources/antrenare/louie/\"\n",
    "# f = open(\"resources/antrenare/louie_annotations.txt\")\n",
    "# lines = f.readlines()\n",
    "#\n",
    "# vector_w_fete = []\n",
    "# vector_h_fete = []\n",
    "#\n",
    "# for line in lines:\n",
    "#     info = line.split(\" \")\n",
    "#     nume_imagine = info[0]\n",
    "#     xmin = int(info[1])\n",
    "#     ymin = int(info[2])\n",
    "#     xmax = int(info[3])\n",
    "#     ymax = int(info[4])\n",
    "#     nume_personaj = info[5][:-1]\n",
    "#\n",
    "#     img = cv.imread(path + nume_imagine)\n",
    "#     if nume_personaj == \"louie\":\n",
    "#         w = xmax - xmin\n",
    "#         h = ymax - ymin\n",
    "#\n",
    "#         vector_w_fete.append(w)\n",
    "#         vector_h_fete.append(h)\n",
    "#\n",
    "# vector_w_fete = np.array(vector_w_fete)\n",
    "# print(f\"medie{vector_w_fete.mean()}\\n\"\n",
    "#       f\"min{vector_w_fete.min()}\\n\"\n",
    "#       f\"max{vector_w_fete.max()}\")\n",
    "#\n",
    "# vector_h_fete = np.array(vector_h_fete)\n",
    "# print(f\"medie{vector_h_fete.mean()}\\n\"\n",
    "#       f\"min{vector_h_fete.min()}\\n\"\n",
    "#       f\"max{vector_h_fete.max()}\")\n",
    "#\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculez descriptorii pt imaginile pozitive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def line_info(line):\n",
    "    info = line.split(\" \")\n",
    "    nume_imagine = info[0]\n",
    "    xmin = int(info[1])\n",
    "    ymin = int(info[2])\n",
    "    xmax = int(info[3])\n",
    "    ymax = int(info[4])\n",
    "    nume_personaj = info[5][:-1]\n",
    "    return nume_imagine, xmin, ymin, xmax, ymax, nume_personaj"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "def get_descriptors_of_image(nume_imagine_anterioara, faces_of_image, path):\n",
    "    img = cv.imread(path + nume_imagine_anterioara, cv.IMREAD_GRAYSCALE)\n",
    "    pos_descriptors = []\n",
    "    neg_descriptors = []\n",
    "    # print(nume_imagine_anterioara)\n",
    "    # print(faces_of_image)\n",
    "    for y in range(0, img.shape[0] - ydim_face_img, 30):\n",
    "        for x in range(0, img.shape[1] - xdim_face_img, 30):\n",
    "\n",
    "            for face_box in faces_of_image:\n",
    "\n",
    "                iou = intersection_over_union(face_box, (x, y, x + xdim_face_img, y + ydim_face_img))\n",
    "                # print(iou)\n",
    "                crop_img = img[y:y + ydim_face_img, x:x + xdim_face_img]\n",
    "\n",
    "                features = hog(crop_img,\n",
    "                           pixels_per_cell=(dim_hog_cell, dim_hog_cell),\n",
    "                           cells_per_block=(2, 2),\n",
    "                           # visualize=True,\n",
    "                           feature_vector=True)\n",
    "                # flip_features  = hog(np.fliplr(crop_img),\n",
    "                #                      pixels_per_cell=(dim_hog_cell, dim_hog_cell),\n",
    "                #                      cells_per_block=(2, 2),\n",
    "                #                      feature_vector=True)\n",
    "                # print(len(features))\n",
    "                if iou > 0.5:\n",
    "                    # cv.imshow(\"imghog\", img_hog)\n",
    "                    # cv.imshow(\"original\", crop_img)\n",
    "                    # cv.waitKey(0)\n",
    "                    # cv.destroyAllWindows()\n",
    "                    pos_descriptors.append(features)\n",
    "                    # pos_descriptors.append(flip_features)\n",
    "                else:\n",
    "                    # cv.imshow(\"original\", crop_img)\n",
    "                    # cv.waitKey(0)\n",
    "                    # cv.destroyAllWindows()\n",
    "                    neg_descriptors.append(features)\n",
    "                    # neg_descriptors.append(flip_features)\n",
    "    return pos_descriptors, neg_descriptors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "# folosind fereastra glisanta, trecem peste fiecare imagine de la stanga la dreapta de sus in jos si cu ajutorul iou, clasificam daca fereastra contine o fata sau nu asfel adaugam un descriptor pozitiv sau negativ\n",
    "# intai creez un vector cu pozitiile fetelor dintr-o imagine, iar in momentul in care o imagine nu mai are fete caut descriptorii\n",
    "def get_descriptors(nume_personaj):\n",
    "    positive_descriptors = []\n",
    "    negative_descriptors = []\n",
    "    path = \"resources/antrenare/\" + nume_personaj + \"/\"\n",
    "    f = open(\"resources/antrenare/\" + nume_personaj + \"_annotations.txt\")\n",
    "    lines = f.readlines()\n",
    "    nume_imagine_anterioara = lines[0].split(\" \")[0]\n",
    "    faces_of_image = []\n",
    "    time_start = time.time()\n",
    "    lines = lines\n",
    "    lines.append(\"end0 1 2 3 4 end5\\n\")\n",
    "    print(nume_imagine_anterioara)\n",
    "    for line in lines:\n",
    "        nume_imagine, xmin, ymin, xmax, ymax, nume_personaj = line_info(line)\n",
    "        if nume_imagine != nume_imagine_anterioara:\n",
    "\n",
    "            positive_descriptors_of_image, negative_descriptors_of_image = get_descriptors_of_image(nume_imagine_anterioara, faces_of_image, path)\n",
    "            positive_descriptors.extend(positive_descriptors_of_image)\n",
    "\n",
    "            if len(negative_descriptors) < 1000:\n",
    "                negative_descriptors.extend(negative_descriptors_of_image)\n",
    "\n",
    "            print(f\"time for img{nume_imagine_anterioara} -> {time.time() - time_start}\")\n",
    "            time_start = time.time()\n",
    "\n",
    "            nume_imagine_anterioara = nume_imagine\n",
    "            faces_of_image = [[xmin, ymin, xmax, ymax]]\n",
    "        else:\n",
    "            faces_of_image.append((xmin, ymin, xmax, ymax))\n",
    "\n",
    "        print(f\"imagini pozitive = {len(positive_descriptors)}\")\n",
    "        print(f\"imagini negative = {len(negative_descriptors)}\")\n",
    "\n",
    "    positive_descriptors = np.array(positive_descriptors)\n",
    "    negative_descriptors = np.array(negative_descriptors)\n",
    "\n",
    "    return positive_descriptors, negative_descriptors\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_classifier(params, training_examples, train_labels):\n",
    "    svm_file_name = os.path.join(params.dir_save_files, 'best_model_%d_%d_%d' %\n",
    "                                 (params.dim_hog_cell, params.number_negative_examples,\n",
    "                                  params.number_positive_examples))\n",
    "    if os.path.exists(svm_file_name):\n",
    "        best_model = pickle.load(open(svm_file_name, 'rb'))\n",
    "        return\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_c = 0\n",
    "    best_model = None\n",
    "    Cs = [10 ** -5, 10 ** -4,  10 ** -3,  10 ** -2, 10 ** -1, 10 ** 0]\n",
    "    for c in Cs:\n",
    "        print('Antrenam un clasificator pentru c=%f' % c)\n",
    "        model = LinearSVC(C=c)\n",
    "        model.fit(training_examples, train_labels)\n",
    "        acc = model.score(training_examples, train_labels)\n",
    "        print(acc)\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_c = c\n",
    "            best_model = deepcopy(model)\n",
    "\n",
    "    print('Performanta clasificatorului optim pt c = %f' % best_c)\n",
    "    # salveaza clasificatorul\n",
    "    pickle.dump(best_model, open(svm_file_name, 'wb'))\n",
    "\n",
    "    # vizualizeaza cat de bine sunt separate exemplele pozitive de cele negative dupa antrenare\n",
    "    # ideal ar fi ca exemplele pozitive sa primeasca scoruri > 0, iar exemplele negative sa primeasca scoruri < 0\n",
    "    scores = best_model.decision_function(training_examples)\n",
    "    best_model = best_model\n",
    "    positive_scores = scores[train_labels > 0]\n",
    "    negative_scores = scores[train_labels <= 0]\n",
    "\n",
    "\n",
    "    plt.plot(np.sort(positive_scores))\n",
    "    plt.plot(np.zeros(len(negative_scores)))\n",
    "    plt.plot(np.sort(negative_scores))\n",
    "    plt.xlabel('Nr example antrenare')\n",
    "    plt.ylabel('Scor clasificator')\n",
    "    plt.title('Distributia scorurilor clasificatorului pe exemplele de antrenare')\n",
    "    plt.legend(['Scoruri exemple pozitive', '0', 'Scoruri exemple negative'])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construim descriptorii pentru exemplele pozitive si negative:\n",
      "0001.jpg\n",
      "imagini pozitive = 0\n",
      "imagini negative = 0\n",
      "time for img0001.jpg -> 0.7399978637695312\n",
      "imagini pozitive = 0\n",
      "imagini negative = 88\n",
      "imagini pozitive = 0\n",
      "imagini negative = 88\n",
      "time for img0002.jpg -> 1.9380056858062744\n",
      "imagini pozitive = 5\n",
      "imagini negative = 259\n",
      "time for img0003.jpg -> 0.7250251770019531\n",
      "imagini pozitive = 5\n",
      "imagini negative = 347\n",
      "time for img0004.jpg -> 0.6469683647155762\n",
      "imagini pozitive = 10\n",
      "imagini negative = 430\n",
      "time for img0005.jpg -> 0.7060015201568604\n",
      "imagini pozitive = 16\n",
      "imagini negative = 512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [9], line 26\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mConstruim descriptorii pentru exemplele pozitive si negative:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 26\u001B[0m     positive_descriptors, negative_descriptors \u001B[38;5;241m=\u001B[39m \u001B[43mget_descriptors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnume_personaj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     np\u001B[38;5;241m.\u001B[39msave(positive_descriptors_path, positive_descriptors)\n\u001B[0;32m     28\u001B[0m     np\u001B[38;5;241m.\u001B[39msave(negative_descriptors_path, negative_descriptors)\n",
      "Cell \u001B[1;32mIn [7], line 19\u001B[0m, in \u001B[0;36mget_descriptors\u001B[1;34m(nume_personaj)\u001B[0m\n\u001B[0;32m     16\u001B[0m nume_imagine, xmin, ymin, xmax, ymax, nume_personaj \u001B[38;5;241m=\u001B[39m line_info(line)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nume_imagine \u001B[38;5;241m!=\u001B[39m nume_imagine_anterioara:\n\u001B[1;32m---> 19\u001B[0m     positive_descriptors_of_image, negative_descriptors_of_image \u001B[38;5;241m=\u001B[39m \u001B[43mget_descriptors_of_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnume_imagine_anterioara\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfaces_of_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m     positive_descriptors\u001B[38;5;241m.\u001B[39mextend(positive_descriptors_of_image)\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(negative_descriptors) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1000\u001B[39m:\n",
      "Cell \u001B[1;32mIn [6], line 16\u001B[0m, in \u001B[0;36mget_descriptors_of_image\u001B[1;34m(nume_imagine_anterioara, faces_of_image, path)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# print(iou)\u001B[39;00m\n\u001B[0;32m     14\u001B[0m crop_img \u001B[38;5;241m=\u001B[39m img[y:y \u001B[38;5;241m+\u001B[39m ydim_face_img, x:x \u001B[38;5;241m+\u001B[39m xdim_face_img]\n\u001B[1;32m---> 16\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[43mhog\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcrop_img\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m           \u001B[49m\u001B[43mpixels_per_cell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdim_hog_cell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_hog_cell\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m           \u001B[49m\u001B[43mcells_per_block\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m           \u001B[49m\u001B[38;5;66;43;03m# visualize=True,\u001B[39;49;00m\n\u001B[0;32m     20\u001B[0m \u001B[43m           \u001B[49m\u001B[43mfeature_vector\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# flip_features  = hog(np.fliplr(crop_img),\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m#                      pixels_per_cell=(dim_hog_cell, dim_hog_cell),\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m#                      cells_per_block=(2, 2),\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m#                      feature_vector=True)\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# print(len(features))\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m iou \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.5\u001B[39m:\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;66;03m# cv.imshow(\"imghog\", img_hog)\u001B[39;00m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;66;03m# cv.imshow(\"original\", crop_img)\u001B[39;00m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;66;03m# cv.waitKey(0)\u001B[39;00m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;66;03m# cv.destroyAllWindows()\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skimage\\_shared\\utils.py:394\u001B[0m, in \u001B[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    391\u001B[0m channel_axis \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchannel_axis\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m channel_axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 394\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    396\u001B[0m \u001B[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001B[39;00m\n\u001B[0;32m    397\u001B[0m \u001B[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001B[39;00m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001B[39;00m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(channel_axis):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skimage\\_shared\\utils.py:348\u001B[0m, in \u001B[0;36mdeprecate_multichannel_kwarg.__call__.<locals>.fixed_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    345\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchannel_axis\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m convert[kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmultichannel\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[0;32m    347\u001B[0m \u001B[38;5;66;03m# Call the function with the fixed arguments\u001B[39;00m\n\u001B[1;32m--> 348\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skimage\\feature\\_hog.py:292\u001B[0m, in \u001B[0;36mhog\u001B[1;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, multichannel, channel_axis)\u001B[0m\n\u001B[0;32m    290\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_blocks_col):\n\u001B[0;32m    291\u001B[0m         block \u001B[38;5;241m=\u001B[39m orientation_histogram[r:r \u001B[38;5;241m+\u001B[39m b_row, c:c \u001B[38;5;241m+\u001B[39m b_col, :]\n\u001B[1;32m--> 292\u001B[0m         \u001B[43mnormalized_blocks\u001B[49m\u001B[43m[\u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m \\\n\u001B[0;32m    293\u001B[0m             _hog_normalize_block(block, method\u001B[38;5;241m=\u001B[39mblock_norm)\n\u001B[0;32m    295\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    296\u001B[0m \u001B[38;5;124;03mThe final step collects the HOG descriptors from all blocks of a dense\u001B[39;00m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;124;03moverlapping grid of blocks covering the detection window into a combined\u001B[39;00m\n\u001B[0;32m    298\u001B[0m \u001B[38;5;124;03mfeature vector for use in the window classifier.\u001B[39;00m\n\u001B[0;32m    299\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m feature_vector:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# dimensiunea ferestrei\n",
    "params: Parameters = Parameters()\n",
    "xdim_face_img = 160 # exemplele pozitive (fetele de oameni cropate) cu 160x120 pixeli\n",
    "ydim_face_img = 120\n",
    "dim_hog_cell = 8 # dimensiunea celului\n",
    "positive_descriptors = np.array([])\n",
    "negative_descriptors = np.array([])\n",
    "\n",
    "# Pasul 1,2,3 -> Incarcam exemplele pozitive si exemplele negative\n",
    "# Verificam daca acestea sunt existente, daca nu for fi create\n",
    "# nume_personaje = [\"andy\", \"louie\", \"ora\", \"tommy\"]\n",
    "nume_personaje = [\"louie\"]\n",
    "for nume_personaj in nume_personaje:\n",
    "    dir_save_files = \"resources\\salveazaFisiere\"\n",
    "    positive_descriptors_path = os.path.join(dir_save_files, 'descriptoriExemplePozitive_' + nume_personaj +'_'+\n",
    "                                             str(dim_hog_cell) + '_' + '.npy')\n",
    "    negative_descriptors_path = os.path.join(dir_save_files, 'descriptoriExempleNegative_' + nume_personaj +'_'+\n",
    "                                             str(dim_hog_cell) + '_' + '.npy')\n",
    "\n",
    "    if os.path.exists(positive_descriptors_path) and os.path.exists(negative_descriptors_path):\n",
    "        positive_descriptors = np.load(positive_descriptors_path)\n",
    "        negative_descriptors = np.load(negative_descriptors_path)\n",
    "        print(f'Am incarcat descriptorii pentru exemplele pozitive si negative pentru {nume_personaj}')\n",
    "    else:\n",
    "        print('Construim descriptorii pentru exemplele pozitive si negative:')\n",
    "        positive_descriptors, negative_descriptors = get_descriptors(nume_personaj)\n",
    "        np.save(positive_descriptors_path, positive_descriptors)\n",
    "        np.save(negative_descriptors_path, negative_descriptors)\n",
    "        print('Am salvat descriptorii pentru exemplele pozitive in fisierul %s' % positive_descriptors_path)\n",
    "        print('Am salvat descriptorii pentru exemplele negative in fisierul %s' % negative_descriptors_path)\n",
    "\n",
    "# Pasul 4 - > Invatam clasificatorul liniar\n",
    "\n",
    "number_positive_examples = len(positive_descriptors)\n",
    "number_negative_examples = len(negative_descriptors)\n",
    "\n",
    "print(f\"numarul de imagini pozitive -> {number_positive_examples}\")\n",
    "print(f\"numarul de imagini negative -> {number_negative_examples}\")\n",
    "\n",
    "training_examples = np.concatenate((np.squeeze(positive_descriptors), np.squeeze(negative_descriptors)), axis=0)\n",
    "train_labels = np.concatenate((np.ones(number_positive_examples), np.zeros(number_negative_examples)))\n",
    "train_classifier(params, training_examples, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TESTAREEEEEEEEEEEE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "img_originala = cv.imread(\"resources/antrenare/louie/0001.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "for j in range(90, 60, -5):\n",
    "    img = cv.resize(img_originala, (0, 0), fx=j / 100, fy=j / 100)\n",
    "    cv.imshow(\"test\", img)\n",
    "    cv.waitKey(0)\n",
    "cv.imshow(\"test\", img_originala)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "# for j in range(1, 4, 1):q\n",
    "#     img = cv.resize(img_originala, (0, 0), fx=j, fy=j)\n",
    "#     cv.imshow(\"test\", img)\n",
    "#     cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "# features, hog_img  = hog(img,\n",
    "#                pixels_per_cell=(8, 8),\n",
    "#                cells_per_block=(2, 2),\n",
    "#                feature_vector=True,\n",
    "#                 visualize=True)\n",
    "# cv.imshow(\"imghog\", hog_img)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory created: ../resources\\salveazaFisiere \n"
     ]
    }
   ],
   "source": [
    "params : Parameters = Parameters()\n",
    "img = cv.imread(\"resources/antrenare/louie/0001.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "faces_of_image = [[168,160,283,233]]\n",
    "pos_descriptors = []\n",
    "neg_descriptors = []\n",
    "\n",
    "\n",
    "\n",
    "for y in range(0, img.shape[0] - params.dim_window_y, params.crop_distance):\n",
    "    for x in range(0, img.shape[1] - params.dim_window_x, params.crop_distance):\n",
    "\n",
    "        max_iou = 0\n",
    "        for face_box in faces_of_image:\n",
    "\n",
    "            iou = intersection_over_union(face_box,\n",
    "                                               (x, y, x + params.dim_window_x,\n",
    "                                                y + params.dim_window_y))\n",
    "            # print(iou)\n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "        crop_img = img[y:y + params.dim_window_y, x:x + params.dim_window_x]\n",
    "        cv.imshow(\"test\", crop_img)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
