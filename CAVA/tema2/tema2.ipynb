{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.dir_save_files = \"resources/salveazaFisiere\"\n",
    "        self.dim_hog_cell = 8\n",
    "        self.number_negative_examples = 268\n",
    "        self.number_positive_examples = 1492"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functii luate de la laborator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "def intersection_over_union(bbox_a, bbox_b):\n",
    "    x_a = max(bbox_a[0], bbox_b[0])\n",
    "    y_a = max(bbox_a[1], bbox_b[1])\n",
    "    x_b = min(bbox_a[2], bbox_b[2])\n",
    "    y_b = min(bbox_a[3], bbox_b[3])\n",
    "\n",
    "    inter_area = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
    "\n",
    "    box_a_area = (bbox_a[2] - bbox_a[0] + 1) * (bbox_a[3] - bbox_a[1] + 1)\n",
    "    box_b_area = (bbox_b[2] - bbox_b[0] + 1) * (bbox_b[3] - bbox_b[1] + 1)\n",
    "\n",
    "    iou = inter_area / float(box_a_area + box_b_area - inter_area)\n",
    "\n",
    "    return iou"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Redimensionez fetele din imaginile de antrenare la aceeasi dimensiune si le transform in tonuri gri pentru a putea antrena clasificatorul liniar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "# ### Am cautat o medie de w si h in setul de date al lui louie pentru a sti la ce masura sa redimensionez fete fara sa pierd foarte mult continut si o sa iau dimensiunea unui patrat scalat la ratia 4:3\n",
    "#\n",
    "# path = \"resources/antrenare/louie/\"\n",
    "# f = open(\"resources/antrenare/louie_annotations.txt\")\n",
    "# lines = f.readlines()\n",
    "#\n",
    "# vector_w_fete = []\n",
    "# vector_h_fete = []\n",
    "#\n",
    "# for line in lines:\n",
    "#     info = line.split(\" \")\n",
    "#     nume_imagine = info[0]\n",
    "#     xmin = int(info[1])\n",
    "#     ymin = int(info[2])\n",
    "#     xmax = int(info[3])\n",
    "#     ymax = int(info[4])\n",
    "#     nume_personaj = info[5][:-1]\n",
    "#\n",
    "#     img = cv.imread(path + nume_imagine)\n",
    "#     if nume_personaj == \"louie\":\n",
    "#         w = xmax - xmin\n",
    "#         h = ymax - ymin\n",
    "#\n",
    "#         vector_w_fete.append(w)\n",
    "#         vector_h_fete.append(h)\n",
    "#\n",
    "# vector_w_fete = np.array(vector_w_fete)\n",
    "# print(f\"medie{vector_w_fete.mean()}\\n\"\n",
    "#       f\"min{vector_w_fete.min()}\\n\"\n",
    "#       f\"max{vector_w_fete.max()}\")\n",
    "#\n",
    "# vector_h_fete = np.array(vector_h_fete)\n",
    "# print(f\"medie{vector_h_fete.mean()}\\n\"\n",
    "#       f\"min{vector_h_fete.min()}\\n\"\n",
    "#       f\"max{vector_h_fete.max()}\")\n",
    "#\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculez descriptorii pt imaginile pozitive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "def line_info(line):\n",
    "    info = line.split(\" \")\n",
    "    nume_imagine = info[0]\n",
    "    xmin = int(info[1])\n",
    "    ymin = int(info[2])\n",
    "    xmax = int(info[3])\n",
    "    ymax = int(info[4])\n",
    "    nume_personaj = info[5][:-1]\n",
    "    return nume_imagine, xmin, ymin, xmax, ymax, nume_personaj"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "\n",
    "def get_descriptors_of_image(nume_imagine_anterioara, faces_of_image, path):\n",
    "    img = cv.imread(path + nume_imagine_anterioara, cv.IMREAD_GRAYSCALE)\n",
    "    pos_descriptors = []\n",
    "    neg_descriptors = []\n",
    "    pos_counter = 0\n",
    "    neg_counter = 0\n",
    "    print(nume_imagine_anterioara)\n",
    "    print(faces_of_image)\n",
    "    for y in range(0, img.shape[0] - ydim_face_img, 30):\n",
    "        for x in range(0, img.shape[1] - xdim_face_img, 30):\n",
    "\n",
    "            for face_box in faces_of_image:\n",
    "\n",
    "                iou = intersection_over_union(face_box, (x, y, x + xdim_face_img, y + ydim_face_img))\n",
    "                # print(iou)\n",
    "                crop_img = img[y:y + ydim_face_img, x:x + xdim_face_img]\n",
    "\n",
    "                features = hog(crop_img,\n",
    "                           pixels_per_cell=(dim_hog_cell, dim_hog_cell),\n",
    "                           cells_per_block=(2, 2),\n",
    "                           # visualize=True,\n",
    "                           feature_vector=True)\n",
    "                flip_features  = hog(np.fliplr(crop_img),\n",
    "                                     pixels_per_cell=(dim_hog_cell, dim_hog_cell),\n",
    "                                     cells_per_block=(2, 2),\n",
    "                                     feature_vector=True)\n",
    "\n",
    "                if iou > 0.3:\n",
    "                    # cv.imshow(\"imghog\", img_hog)\n",
    "                    # cv.imshow(\"original\", crop_img)\n",
    "                    # cv.waitKey(0)\n",
    "                    # cv.destroyAllWindows()\n",
    "                    pos_descriptors.append(features)\n",
    "                    pos_descriptors.append(flip_features)\n",
    "                    pos_counter += 2\n",
    "                else:\n",
    "                    # cv.imshow(\"original\", crop_img)\n",
    "                    # cv.waitKey(0)\n",
    "                    # cv.destroyAllWindows()\n",
    "                    neg_descriptors.append(features)\n",
    "                    neg_descriptors.append(flip_features)\n",
    "                    neg_counter += 2\n",
    "    print(f\"pos counter - {pos_counter}\")\n",
    "    return np.array(pos_descriptors), np.array(neg_descriptors), pos_counter, neg_counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "\n",
    "# folosind fereastra glisanta, trecem peste fiecare imagine de la stanga la dreapta de sus in jos si cu ajutorul iou, clasificam daca fereastra contine o fata sau nu asfel adaugam un descriptor pozitiv sau negativ\n",
    "# intai creez un vector cu pozitiile fetelor dintr-o imagine, iar in momentul in care o imagine nu mai are fete caut descriptorii\n",
    "def get_descriptors(nume_personaj):\n",
    "    number_positive_examples = 0\n",
    "    number_negative_examples = 0\n",
    "    positive_descriptors = np.array([])\n",
    "    negative_descriptors = np.array([])\n",
    "    path = \"resources/antrenare/\" + nume_personaj + \"/\"\n",
    "    f = open(\"resources/antrenare/\" + nume_personaj + \"_annotations.txt\")\n",
    "    lines = f.readlines()\n",
    "    nume_imagine_anterioara = lines[0].split(\" \")[0]\n",
    "    faces_of_image = []\n",
    "    time_start = time.time()\n",
    "    lines = lines[:10]\n",
    "    lines.append(\"end1 2 3 4 5 end6\\n\")\n",
    "    print(nume_imagine_anterioara)\n",
    "    for line in lines:\n",
    "        nume_imagine, xmin, ymin, xmax, ymax, nume_personaj = line_info(line)\n",
    "        if nume_imagine != nume_imagine_anterioara:\n",
    "\n",
    "            positive_descriptors_of_image, negative_descriptors_of_image, pos_counter, neg_counter = get_descriptors_of_image(nume_imagine_anterioara, faces_of_image, path)\n",
    "            positive_descriptors = np.append(positive_descriptors, positive_descriptors_of_image)\n",
    "            negative_descriptors = np.append(negative_descriptors, negative_descriptors_of_image)\n",
    "            number_positive_examples += pos_counter\n",
    "            number_negative_examples += neg_counter\n",
    "\n",
    "            print(f\"time for img{nume_imagine_anterioara} -> {time.time() - time_start}\")\n",
    "            time_start = time.time()\n",
    "\n",
    "            nume_imagine_anterioara = nume_imagine\n",
    "            faces_of_image = [[xmin, ymin, xmax, ymax]]\n",
    "        else:\n",
    "            faces_of_image.append((xmin, ymin, xmax, ymax))\n",
    "\n",
    "\n",
    "    # print(type(positive_descriptors))\n",
    "    # print(positive_descriptors.shape)\n",
    "    # print(f\"pos number counter - {number_positive_examples}\")\n",
    "    return positive_descriptors, negative_descriptors, number_positive_examples, number_negative_examples\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "def train_classifier(params, training_examples, train_labels):\n",
    "    svm_file_name = os.path.join(params.dir_save_files, 'best_model_%d_%d_%d' %\n",
    "                                 (params.dim_hog_cell, params.number_negative_examples,\n",
    "                                  params.number_positive_examples))\n",
    "    if os.path.exists(svm_file_name):\n",
    "        best_model = pickle.load(open(svm_file_name, 'rb'))\n",
    "        return\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_c = 0\n",
    "    best_model = None\n",
    "    Cs = [10 ** -5, 10 ** -4,  10 ** -3,  10 ** -2, 10 ** -1, 10 ** 0]\n",
    "    for c in Cs:\n",
    "        print('Antrenam un clasificator pentru c=%f' % c)\n",
    "        model = LinearSVC(C=c)\n",
    "        model.fit(training_examples, train_labels)\n",
    "        acc = model.score(training_examples, train_labels)\n",
    "        print(acc)\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_c = c\n",
    "            best_model = deepcopy(model)\n",
    "\n",
    "    print('Performanta clasificatorului optim pt c = %f' % best_c)\n",
    "    # salveaza clasificatorul\n",
    "    pickle.dump(best_model, open(svm_file_name, 'wb'))\n",
    "\n",
    "    # vizualizeaza cat de bine sunt separate exemplele pozitive de cele negative dupa antrenare\n",
    "    # ideal ar fi ca exemplele pozitive sa primeasca scoruri > 0, iar exemplele negative sa primeasca scoruri < 0\n",
    "    scores = best_model.decision_function(training_examples)\n",
    "    best_model = best_model\n",
    "    positive_scores = scores[train_labels > 0]\n",
    "    negative_scores = scores[train_labels <= 0]\n",
    "\n",
    "\n",
    "    plt.plot(np.sort(positive_scores))\n",
    "    plt.plot(np.zeros(len(positive_scores)))\n",
    "    plt.plot(np.sort(negative_scores))\n",
    "    plt.xlabel('Nr example antrenare')\n",
    "    plt.ylabel('Scor clasificator')\n",
    "    plt.title('Distributia scorurilor clasificatorului pe exemplele de antrenare')\n",
    "    plt.legend(['Scoruri exemple pozitive', '0', 'Scoruri exemple negative'])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construim descriptorii pentru exemplele pozitive si negative:\n",
      "0001.jpg\n",
      "0001.jpg\n",
      "[(168, 160, 283, 233)]\n",
      "pos counter - 12\n",
      "time for img0001.jpg -> 1.5369987487792969\n",
      "0002.jpg\n",
      "[[338, 91, 463, 165], (129, 214, 316, 308)]\n",
      "pos counter - 36\n",
      "time for img0002.jpg -> 2.7390294075012207\n",
      "0003.jpg\n",
      "[[131, 161, 238, 250]]\n",
      "pos counter - 20\n",
      "time for img0003.jpg -> 1.2129685878753662\n",
      "0004.jpg\n",
      "[[58, 158, 203, 277]]\n",
      "pos counter - 30\n",
      "time for img0004.jpg -> 1.1870026588439941\n",
      "0005.jpg\n",
      "[[156, 168, 333, 294]]\n",
      "pos counter - 34\n",
      "time for img0005.jpg -> 1.204000473022461\n",
      "0006.jpg\n",
      "[[127, 92, 331, 250]]\n",
      "pos counter - 36\n",
      "time for img0006.jpg -> 1.2309999465942383\n",
      "0007.jpg\n",
      "[[119, 76, 268, 186]]\n",
      "pos counter - 30\n",
      "time for img0007.jpg -> 1.1949965953826904\n",
      "0008.jpg\n",
      "[[165, 121, 354, 249]]\n",
      "pos counter - 38\n",
      "time for img0008.jpg -> 1.2729997634887695\n",
      "0009.jpg\n",
      "[[148, 105, 316, 238]]\n",
      "pos counter - 32\n",
      "time for img0009.jpg -> 1.2530040740966797\n",
      "Am salvat descriptorii pentru exemplele pozitive in fisierul resources\\salveazaFisiere\\descriptoriExemplePozitive_louie_8_.npy\n",
      "Am salvat descriptorii pentru exemplele negative in fisierul resources\\salveazaFisiere\\descriptoriExempleNegative_louie_8_.npy\n",
      "numarul de imagini pozitive -> 268\n",
      "numarul de imagini negative -> 1492\n",
      "len pos_desc = 2566368\n",
      "Antrenam un clasificator pentru c=0.000010\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.2623535  0.03957657 0.00813868 ... 0.27416766 0.03487868 0.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [269], line 37\u001B[0m\n\u001B[0;32m     35\u001B[0m training_examples \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate((np\u001B[38;5;241m.\u001B[39msqueeze(positive_descriptors), np\u001B[38;5;241m.\u001B[39msqueeze(negative_descriptors)), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     36\u001B[0m train_labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate((np\u001B[38;5;241m.\u001B[39mones(number_positive_examples), np\u001B[38;5;241m.\u001B[39mzeros(number_negative_examples)))\n\u001B[1;32m---> 37\u001B[0m \u001B[43mtrain_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_examples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [267], line 16\u001B[0m, in \u001B[0;36mtrain_classifier\u001B[1;34m(params, training_examples, train_labels)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAntrenam un clasificator pentru c=\u001B[39m\u001B[38;5;132;01m%f\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m c)\n\u001B[0;32m     15\u001B[0m model \u001B[38;5;241m=\u001B[39m LinearSVC(C\u001B[38;5;241m=\u001B[39mc)\n\u001B[1;32m---> 16\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_examples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m acc \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mscore(training_examples, train_labels)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(acc)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py:263\u001B[0m, in \u001B[0;36mLinearSVC.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;124;03m\"\"\"Fit the model according to the given training data.\u001B[39;00m\n\u001B[0;32m    239\u001B[0m \n\u001B[0;32m    240\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;124;03m    An instance of the estimator.\u001B[39;00m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    261\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m--> 263\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    265\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    266\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat64\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    271\u001B[0m check_classification_targets(y)\n\u001B[0;32m    272\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:554\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    552\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    553\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 554\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    555\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1104\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1099\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1100\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1102\u001B[0m     )\n\u001B[1;32m-> 1104\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1106\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1107\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1109\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1120\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1122\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:900\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    898\u001B[0m     \u001B[38;5;66;03m# If input is 1D raise error\u001B[39;00m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 900\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    901\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124marray=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    902\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    903\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    904\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif it contains a single sample.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m    905\u001B[0m         )\n\u001B[0;32m    907\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype_numeric \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSV\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    908\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    909\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    911\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[0.2623535  0.03957657 0.00813868 ... 0.27416766 0.03487868 0.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# dimensiunea ferestrei\n",
    "params: Parameters = Parameters()\n",
    "xdim_face_img = 160 # exemplele pozitive (fetele de oameni cropate) cu 160x120 pixeli\n",
    "ydim_face_img = 120\n",
    "dim_hog_cell = 8 # dimensiunea celului\n",
    "\n",
    "# Pasul 1,2,3 -> Incarcam exemplele pozitive si exemplele negative\n",
    "# Verificam daca acestea sunt existente, daca nu for fi create\n",
    "# nume_personaje = [\"andy\", \"louie\", \"ora\", \"tommy\"]\n",
    "nume_personaje = [\"louie\"]\n",
    "for nume_personaj in nume_personaje:\n",
    "    dir_save_files = \"resources\\salveazaFisiere\"\n",
    "    positive_descriptors_path = os.path.join(dir_save_files, 'descriptoriExemplePozitive_' + nume_personaj +'_'+\n",
    "                                             str(dim_hog_cell) + '_' + '.npy')\n",
    "    negative_descriptors_path = os.path.join(dir_save_files, 'descriptoriExempleNegative_' + nume_personaj +'_'+\n",
    "                                             str(dim_hog_cell) + '_' + '.npy')\n",
    "\n",
    "    if os.path.exists(positive_descriptors_path) and os.path.exists(negative_descriptors_path):\n",
    "        positive_descriptors = np.load(positive_descriptors_path)\n",
    "        negative_descriptors = np.load(negative_descriptors_path)\n",
    "        print(f'Am incarcat descriptorii pentru exemplele pozitive si negative pentru {nume_personaj}')\n",
    "    else:\n",
    "        print('Construim descriptorii pentru exemplele pozitive si negative:')\n",
    "        positive_descriptors, negative_descriptors, number_positive_examples, number_negative_examples = get_descriptors(\"louie\")\n",
    "        # np.save(positive_descriptors_path, positive_descriptors)\n",
    "        # np.save(negative_descriptors_path, negative_descriptors)\n",
    "        print('Am salvat descriptorii pentru exemplele pozitive in fisierul %s' % positive_descriptors_path)\n",
    "        print('Am salvat descriptorii pentru exemplele negative in fisierul %s' % negative_descriptors_path)\n",
    "\n",
    "# Pasul 4 - > Invatam clasificatorul liniar\n",
    "print(f\"numarul de imagini pozitive -> {number_positive_examples}\")\n",
    "print(f\"numarul de imagini negative -> {number_negative_examples}\")\n",
    "print(f\"len pos_desc = {len(positive_descriptors)}\")\n",
    "\n",
    "training_examples = np.concatenate((np.squeeze(positive_descriptors), np.squeeze(negative_descriptors)), axis=0)\n",
    "train_labels = np.concatenate((np.ones(number_positive_examples), np.zeros(number_negative_examples)))\n",
    "train_classifier(params, training_examples, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# img = cv.imread(\"resources/antrenare/louie/0001.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "# features, hog_img  = hog(img,\n",
    "#                pixels_per_cell=(8, 8),\n",
    "#                cells_per_block=(2, 2),\n",
    "#                feature_vector=True,\n",
    "#                 visualize=True)\n",
    "# cv.imshow(\"imghog\", hog_img)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
