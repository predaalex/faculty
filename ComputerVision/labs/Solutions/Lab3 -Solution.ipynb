{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd31ce9",
   "metadata": {},
   "source": [
    "## Grabcat - Foreground/background segmentation of cats in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451b8cf7",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.io\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d115c55",
   "metadata": {},
   "source": [
    "def show_images(image_1, image_2=None, image_3=None, name_1='image_1', name_2='image_2', name_3='image_3', time_out=0):\n",
    "    \"\"\"\n",
    "    Show images received as parameters.\n",
    "    \"\"\"\n",
    "    cv.imshow(name_1, image_1)\n",
    "    if image_2 is not None:\n",
    "        cv.imshow(name_2, image_2)\n",
    "    if image_3 is not None:\n",
    "        cv.imshow(name_3, image_3)\n",
    "    cv.waitKey(time_out)\n",
    "    cv.destroyAllWindows()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf252e0",
   "metadata": {},
   "source": [
    "def measure_performance(result,gt):\n",
    "    \"\"\"\n",
    "    result : segmentation obtained\n",
    "    gt: ground-truth segmentation \n",
    "    returns precision and recall\n",
    "    \"\"\"\n",
    "    result_converted=np.asarray(result)\n",
    "    result_converted[result_converted<200]=0\n",
    "    result_converted[result_converted>200]=1\n",
    "    result_converted=result_converted.flatten()\n",
    "    gt_converted=np.asarray(gt)\n",
    "    gt_converted[gt_converted<200]=0\n",
    "    gt_converted[gt_converted>200]=1\n",
    "    gt_converted=gt_converted.flatten()\n",
    "    return precision_score(gt_converted,result_converted),recall_score(gt_converted,result_converted)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbca6124",
   "metadata": {},
   "source": [
    "def get_regions(image):\n",
    "    \"\"\"\n",
    "    image: image for segmentation\n",
    "    -select the ROI\n",
    "    -create list with background pixels\n",
    "    -create list with foreground pixels\n",
    "    returns the coordinates of region of interest, cropped_image, background and foreground pixels\n",
    "    \"\"\"\n",
    "    r = cv.selectROI(\"select the area\", image)\n",
    "    cropped_image = image[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n",
    "    show_images(cropped_image)\n",
    "    background=[]\n",
    "    #left\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(0,r[0]):\n",
    "            background.append(image[i,j,:])\n",
    "    #right\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(r[2]+r[0],image.shape[1]):\n",
    "\n",
    "            background.append(image[i,j,:])\n",
    "    #up\n",
    "    for i in range(0,r[1]):\n",
    "        for j in range(r[0],r[0]+r[2]):\n",
    "\n",
    "            background.append(image[i,j,:])    \n",
    "    #down\n",
    "    for i in range(r[1]+r[3],image.shape[0]):\n",
    "        for j in range(r[0],r[0]+r[2]):\n",
    "            background.append(image[i,j,:])  \n",
    "    b=np.array(background)\n",
    "    fb=cropped_image.reshape((-1, 3))\n",
    "    return r,b,fb,cropped_image"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "478eff86",
   "metadata": {},
   "source": [
    "def get_kmean_centroids(data,k):\n",
    "    \"\"\"\n",
    "    data: data to be clustered\n",
    "    k: number of clusters\n",
    "    returns the center of clusters\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(init=\"random\", n_clusters=k, n_init=10, max_iter=300, random_state=42)\n",
    "    kmeans.fit(np.float64(data))\n",
    "    return kmeans.cluster_centers_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3686a0bb",
   "metadata": {},
   "source": [
    "def segment_image(cropped_image,iterations,centroids_b,centroids_f,b_orig,fb_orig,img_name):\n",
    "    \"\"\"\n",
    "    cropped_image: region to be segmented\n",
    "    iterations: number of iterations\n",
    "    centroids_b: number of centroids for background\n",
    "    centroids_f: number of centroids for foreground\n",
    "    b_orig: original pixels for background\n",
    "    fb_orig: original pixels from foreground and background region\n",
    "    img_name: image name for segmented image\n",
    "    -cluster background pixels\n",
    "    -cluster pixels from foreground and background region\n",
    "    -compute euclidean distance between pixels from cropped image and cluster centers\n",
    "    -assign pixels to background if minimum distance is found between a cluster from backgound\n",
    "    \"\"\"\n",
    "    b=b_orig.copy()\n",
    "    fb=fb_orig.copy()\n",
    "    for cnt in range(iterations):\n",
    "        kmeans_b=get_kmean_centroids(b,centroids_b)\n",
    "        kmeans_fb=get_kmean_centroids(fb,centroids_f)\n",
    "        img_mask=np.zeros((cropped_image.shape[0],cropped_image.shape[1]))\n",
    "        img_mask.fill(255)\n",
    "        b=b_orig.copy()\n",
    "        fb=fb_orig.copy()\n",
    "        for i in range(cropped_image.shape[0]):\n",
    "            for j in range(cropped_image.shape[1]):\n",
    "                distances_b=[]\n",
    "                distances_fb=[]\n",
    "                for c in kmeans_b:\n",
    "                    distances_b.append(math.dist(cropped_image[i,j,:], c))\n",
    "                for c in kmeans_fb:\n",
    "                    distances_fb.append(math.dist(cropped_image[i,j,:], c))\n",
    "                min_b=min(distances_b)\n",
    "                min_fb=min(distances_fb)\n",
    "                if min_b<min_fb:\n",
    "                    b=np.append(b,[cropped_image[i,j,:]],axis=0)\n",
    "                    fb=np.delete(fb, np.where(fb == [cropped_image[i,j,:]])[0][0],axis=0)\n",
    "                    img_mask[i,j]=0\n",
    "        #show_images(img_mask)\n",
    "        cv.imwrite(\"segmentations/\"+img_name+'_'+str(cnt)+'.jpg', img_mask)\n",
    "    return img_mask"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df36c5ba",
   "metadata": {},
   "source": [
    "image_path='07.jpg'\n",
    "gt_image_path='07.png'\n",
    "gt_image=cv.imread('ground_truth/'+gt_image_path,cv.IMREAD_GRAYSCALE)\n",
    "img_name=image_path.split('.')[0]\n",
    "image = cv.imread('images/'+image_path)\n",
    "r,b_orig,fb_orig,cropped_image=get_regions(image)\n",
    "mask=segment_image(cropped_image,5,10,7,b_orig,fb_orig,img_name)\n",
    "full_image=np.zeros((image.shape[0],image.shape[1],1))\n",
    "full_image[r[1]:r[1]+r[3],r[0]:r[0]+r[2]]=1\n",
    "full_image[r[1]:r[1]+r[3],r[0]:r[0]+r[2]]=full_image[r[1]:r[1]+r[3],r[0]:r[0]+r[2]] * mask[:, :, np.newaxis]\n",
    "show_images(full_image)\n",
    "cv.imwrite(\"segmentations/\"+img_name+'_classic'+'.jpg', full_image)\n",
    "print(measure_performance(full_image.copy(),gt_image.copy()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17736395",
   "metadata": {},
   "source": [
    "# https://www.docs.opencv.org/master/d8/d83/tutorial_py_grabcut.html\n",
    "def run_grabcut(img):\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    bgdModel = np.zeros((1,65), np.float64)\n",
    "    fgdModel = np.zeros((1,65), np.float64)\n",
    "    rect = cv.selectROI(img)\n",
    "    cv.destroyAllWindows()\n",
    "    cv.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv.GC_INIT_WITH_RECT)\n",
    "    \n",
    "    mask2 = np.where((mask == 2)|(mask == 0),0,255).astype('uint8')\n",
    "    return mask2\n",
    "image_path='07.jpg'    \n",
    "img = cv.imread('images/07.jpg')\n",
    "img_name=image_path.split('.')[0]\n",
    "gt_image_path='07.png'\n",
    "gt_image=cv.imread('ground_truth/'+gt_image_path,cv.IMREAD_GRAYSCALE)\n",
    "mask = run_grabcut(img)\n",
    "show_images(image_1=mask, name_1='img_grabcut') \n",
    "cv.imwrite(\"segmentations/\"+img_name+'_grabcut'+'.jpg', mask)\n",
    "print(measure_performance(mask,gt_image))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed9e6f1",
   "metadata": {},
   "source": [
    "NUMBER_DIFFERENT_COLORS = 50\n",
    "random_colors = np.uint8(np.random.randint(255, size=(NUMBER_DIFFERENT_COLORS, 3)))\n",
    "\n",
    "def label_to_rgb(img_label, colors=random_colors):\n",
    "    \"\"\"\n",
    "    It colors the image based on the label number.\n",
    "    :param img_label. The 'image' containing a label for each patch/portion of the image.\n",
    "    :param colors\n",
    "    :return the colored image.\n",
    "    \"\"\"\n",
    "    h, w = img_label.shape\n",
    "    fake_colored_label_image = np.uint8(np.zeros((h, w, 3))) \n",
    "    \n",
    "    number_labels = img_label.max() + 1\n",
    "    number_different_colors = colors.shape[0] \n",
    "    \n",
    "    for label in range(number_labels):\n",
    "        rows, columns = np.where(img_label == label)\n",
    "        fake_colored_label_image[rows, columns, :] = colors[label % number_different_colors]\n",
    "    return fake_colored_label_image"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e0152b",
   "metadata": {},
   "source": [
    "def apply_slic(image, show_images_=False):\n",
    "    \"\"\"\n",
    "    Apply the SLIC algorithm on the image received as paramters.\n",
    "    :param image.\n",
    "    :show_images_. If True the result of the algorithm is shown.\n",
    "    :return The superpixels obtained by running the SLIC algorithm.\n",
    "    \"\"\"\n",
    "    segments_slic = slic(image, n_segments=250, compactness=10, start_label=1)  \n",
    "    if show_images_:\n",
    "        colored_segments = label_to_rgb(segments_slic)\n",
    "        show_images(image_1=image, image_2=colored_segments, name_1='image', name_2='splic_segmentation',\n",
    "                    image_3=mark_boundaries(image, segments_slic), name_3='boundaries')\n",
    "    return segments_slic"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18831402",
   "metadata": {},
   "source": [
    "def get_regions_super(image,S):\n",
    "    \"\"\"\n",
    "    image: image for segmentation\n",
    "    -select the ROI\n",
    "    -create list with background pixels\n",
    "    -create list with foreground pixels\n",
    "    returns the coordinates of region of interest, cropped_image, background and foreground pixels\n",
    "    \"\"\"\n",
    "    r = cv.selectROI(\"select the area\", image)\n",
    "    cropped_image = image[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n",
    "    \n",
    "    show_images(cropped_image)\n",
    "    \n",
    "    cropped_image_super=S[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n",
    "    \n",
    "    number_labels = S.max() + 1\n",
    "    fb=[]\n",
    "    b=[]\n",
    "    for i in range(1, number_labels):\n",
    "        if i in  cropped_image_super:\n",
    "            fb.append(i)\n",
    "    for i in range(1, number_labels):\n",
    "        if i not in fb:\n",
    "            b.append(i)\n",
    "    return r,b,fb,cropped_image\n",
    "   "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a672f3fc",
   "metadata": {},
   "source": [
    "def get_mean_color_superpixel_response(image,S, label):    \n",
    "    rows, columns = np.where(S == label )\n",
    "    superpixel_colors = image[rows, columns,:]\n",
    "    superpixel_mean_color= np.mean(superpixel_colors, axis=0)         \n",
    "    return superpixel_mean_color"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95b49a2",
   "metadata": {},
   "source": [
    "def segment_image_super_pixels(S,iterations,centroids_b,centroids_f,b_orig,fb_orig,img_name):\n",
    "    \"\"\"\n",
    "    S: superpixels image\n",
    "    iterations: number of iterations\n",
    "    centroids_b: number of centroids for background\n",
    "    centroids_f: number of centroids for foreground\n",
    "    b_orig: original superpixels for background\n",
    "    fb_orig: original superpixels from foreground and background region\n",
    "    img_name: image name for segmented image\n",
    "    -cluster background pixels\n",
    "    -cluster pixels from foreground and background region\n",
    "    -compute euclidean distance between pixels from cropped image and cluster centers\n",
    "    -assign pixels to background if minimum distance is found between a cluster from background\n",
    "    \"\"\"\n",
    "    features_fb_orig=[]\n",
    "    for x in fb_orig:\n",
    "        features_fb_orig.append(get_mean_color_superpixel_response(image,S, x))\n",
    "    b=b_orig.copy()\n",
    "    fb=fb_orig.copy()\n",
    "    for cnt in range(iterations):\n",
    "        features_b=[]\n",
    "        features_fb=[]\n",
    "        for x in b:\n",
    "            features_b.append(get_mean_color_superpixel_response(image,S, x))\n",
    "        for x in fb:\n",
    "            features_fb.append(get_mean_color_superpixel_response(image,S, x))\n",
    "        h, w = S.shape\n",
    "        rez_mask = np.uint8(np.zeros((h, w, 1)))     \n",
    "        rez_mask.fill(0)\n",
    "        kmeans_b=get_kmean_centroids(features_b,centroids_b)\n",
    "        kmeans_fb=get_kmean_centroids(features_fb,centroids_f)\n",
    "        b=b_orig.copy()\n",
    "        fb=fb_orig.copy()\n",
    "        for i in range(0,len(fb_orig)):\n",
    "                distances_b=[]\n",
    "                distances_fb=[]\n",
    "                for c in kmeans_b:\n",
    "                    distances_b.append(math.dist(features_fb_orig[i], c))\n",
    "                for c in kmeans_fb:\n",
    "                    distances_fb.append(math.dist(features_fb_orig[i], c))\n",
    "                min_b=min(distances_b)\n",
    "                min_fb=min(distances_fb)\n",
    "                if min_b<min_fb:\n",
    "                    b.append(fb_orig[i])\n",
    "                    fb.remove(fb_orig[i])\n",
    "        for label in fb:\n",
    "            rows, columns = np.where(S == label)\n",
    "            rez_mask[rows, columns, :] = 255\n",
    "        cv.imwrite(\"segmentations/\"+img_name+'_super_'+str(cnt)+'.jpg', rez_mask)\n",
    "    return rez_mask"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38dc0c6a",
   "metadata": {},
   "source": [
    "image_path='05.jpg'\n",
    "gt_image_path='05.png'\n",
    "gt_image=cv.imread('ground_truth/'+gt_image_path,cv.IMREAD_GRAYSCALE)\n",
    "img_name=image_path.split('.')[0]\n",
    "image = cv.imread('images/'+image_path)\n",
    "S=apply_slic(image, show_images_=False)\n",
    "r,b,fb,cropped_image=get_regions_super(image,S)\n",
    "mask=segment_image_super_pixels(S,50,5,5,b,fb,img_name)\n",
    "print(measure_performance(mask,gt_image))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac648707",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
